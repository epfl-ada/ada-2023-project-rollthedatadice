{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastcoref import FCoref\n",
    "\n",
    "import pandas as pd\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all the unique names and store them in a list\n",
    "character_metadata = pd.read_csv('../data/character.metadata.tsv', sep='\\t', header=None)\n",
    "character_metadata.columns = [\n",
    "    'wikipedia_movie_id',\n",
    "    'freebase_movie_id',\n",
    "    'movie_release_date',\n",
    "    'character_name',\n",
    "    'actor_dob',\n",
    "    'actor_gender',\n",
    "    'actor_height',\n",
    "    'actor_ethnicity',\n",
    "    'actor_name',\n",
    "    'actor_age',\n",
    "    'freebase_character_map_1',\n",
    "    'freebase_character_map_2',\n",
    "    'freebase_character_map_3'\n",
    "]\n",
    "characters = character_metadata['character_name'].unique().tolist()\n",
    "characters = [name for name in characters if type(name) == str]\n",
    "characters = ' '.join(characters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12/15/2023 14:20:35 - INFO - \t missing_keys: []\n",
      "12/15/2023 14:20:35 - INFO - \t unexpected_keys: []\n",
      "12/15/2023 14:20:35 - INFO - \t mismatched_keys: []\n",
      "12/15/2023 14:20:35 - INFO - \t error_msgs: []\n",
      "12/15/2023 14:20:35 - INFO - \t Model Parameters: 90.5M, Transformer: 82.1M, Coref head: 8.4M\n",
      "12/15/2023 14:20:35 - INFO - \t Tokenize 1 inputs...\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 54.33 examples/s]\n",
      "12/15/2023 14:20:36 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00,  3.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "she -> Katniss\n",
      "She -> Katniss\n",
      "she -> Katniss\n",
      "her -> Katniss\n",
      "her -> Katniss\n",
      "she -> Katniss\n",
      "she -> Katniss\n",
      "her -> Katniss\n",
      "She -> Katniss\n",
      "she -> Katniss\n",
      "She -> Katniss\n",
      "she -> Katniss\n",
      "She -> Katniss\n",
      "her -> Katniss\n",
      "she -> Katniss\n",
      "her -> Katniss\n",
      "her -> Katniss\n",
      "her -> Katniss\n",
      "she -> Katniss\n",
      "her -> Katniss\n",
      "She -> Katniss\n",
      "his -> Peeta\n",
      "he -> Peeta\n",
      "him -> Peeta\n",
      "him -> Peeta\n",
      "him -> Peeta\n",
      "he -> Peeta\n",
      "she -> Peeta\n",
      "his -> President Snow\n",
      "him -> Cato\n",
      "him -> Cato\n",
      "him -> Cato\n",
      "The nation of Panem consists of a wealthy Capitol and twelve poorer districts. As punishment for a past rebellion, each district must provide a boy and girl between the ages of 12 and 18 selected by lottery for the annual Hunger Games. The tributes must fight to the death in an arena; the sole survivor is rewarded with fame and wealth. In her first Reaping, 12-year-old Primrose Everdeen is chosen from District 12. Her older sister Katniss volunteers to take her place. Peeta Mellark, a baker's son who once gave Katniss bread when Katniss was starving, is the other District 12 tribute. Katniss and Peeta are taken to the Capitol, accompanied by their frequently drunk mentor, past victor Haymitch Abernathy. He warns them about the \"Career\" tributes who train intensively at special academies and almost always win. During a TV interview with Caesar Flickerman, Peeta unexpectedly reveals Peeta love for Katniss. Katniss is outraged, believing it to be a ploy to gain audience support, as \"sponsors\" may provide in-Games gifts of food, medicine, and tools. However, Katniss discovers Peeta meant what Peeta said. The televised Games begin with half of the tributes killed in the first few minutes; Katniss barely survives ignoring Haymitch's advice to run away from the melee over the tempting supplies and weapons strewn in front of a structure called the Cornucopia. Peeta forms an uneasy alliance with the four Careers. They later find Katniss and corner Katniss up a tree. Rue, hiding in a nearby tree, draws her attention to a poisonous tracker jacker nest hanging from a branch. Katniss drops it on Katniss sleeping besiegers. They all scatter, except for Glimmer, who is killed by the insects. Hallucinating due to tracker jacker venom, Katniss is warned to run away by Peeta. Rue cares for Katniss for a couple of days until Katniss recovers. Meanwhile, the alliance has gathered all the supplies into a pile. Katniss has Rue draw them off, then destroys the stockpile by setting off the mines planted around it. Furious, Cato kills the boy assigned to guard it. As Katniss runs from the scene, Katniss hears Rue calling Katniss name. Katniss finds Rue trapped and releases her. Marvel, a tribute from District 1, throws a spear at Katniss, but Katniss dodges the spear, causing it to stab Rue in the stomach instead. Katniss shoots him dead with an arrow. Katniss then comforts the dying Rue with a song. Afterward, Katniss gathers and arranges flowers around Rue's body. When this is televised, it sparks a riot in Rue's District 11. President Snow summons Seneca Crane, the Gamemaker, to express President Snow displeasure at the way the Games are turning out. Since Katniss and Peeta have been presented to the public as \"star-crossed lovers\", Haymitch is able to convince Crane to make a rule change to avoid inciting further riots. It is announced that tributes from the same district can win as a pair. Upon hearing this, Katniss searches for Peeta and finds Peeta with an infected sword wound in the leg. Katniss portrays herself as deeply in love with Peeta and gains a sponsor's gift of soup. An announcer proclaims a feast, where the thing each survivor needs most will be provided. Peeta begs Katniss not to risk getting Peeta medicine. Katniss promises not to go, but after Peeta falls asleep, Katniss heads to the feast. Clove ambushes Katniss and pins Katniss down. As Clove gloats, Thresh, the other District 11 tribute, kills Clove after overhearing Katniss tormenting Katniss about killing Rue. He spares Katniss \"just this time...for Rue\". The medicine works, keeping Peeta mobile. Foxface, the girl from District 5, dies from eating nightlock berries she stole from Peeta; neither knew they are highly poisonous. Crane changes the time of day in the arena to late at night and unleashes a pack of hound-like creatures to speed things up. They kill Thresh and force Katniss and Peeta to flee to the roof of the Cornucopia, where they encounter Cato. After a battle, Katniss wounds Cato with an arrow and Peeta hurls Cato to the creatures below. Katniss shoots Cato to spare Cato a prolonged death. With Peeta and Katniss apparently victorious, the rule change allowing two winners is suddenly revoked. Peeta tells Katniss to shoot him. Instead, Peeta gives Cato half of the nightlock. However, before they can commit suicide, they are hastily proclaimed the victors of the 74th Hunger Games. Haymitch warns Katniss that Katniss has made powerful enemies after Katniss display of defiance. Katniss and Peeta return to District 12, while Crane is locked in a room with a bowl of nightlock berries, and President Snow considers the situation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# test text\n",
    "\n",
    "text = \"\"\"The nation of Panem consists of a wealthy Capitol and twelve poorer districts. As punishment for a past rebellion, each district must provide a boy and girl  between the ages of 12 and 18 selected by lottery  for the annual Hunger Games. The tributes must fight to the death in an arena; the sole survivor is rewarded with fame and wealth. In her first Reaping, 12-year-old Primrose Everdeen is chosen from District 12. Her older sister Katniss volunteers to take her place. Peeta Mellark, a baker's son who once gave Katniss bread when she was starving, is the other District 12 tribute. Katniss and Peeta are taken to the Capitol, accompanied by their frequently drunk mentor, past victor Haymitch Abernathy. He warns them about the \"Career\" tributes who train intensively at special academies and almost always win. During a TV interview with Caesar Flickerman, Peeta unexpectedly reveals his love for Katniss. She is outraged, believing it to be a ploy to gain audience support, as \"sponsors\" may provide in-Games gifts of food, medicine, and tools. However, she discovers Peeta meant what he said. The televised Games begin with half of the tributes killed in the first few minutes; Katniss barely survives ignoring Haymitch's advice to run away from the melee over the tempting supplies and weapons strewn in front of a structure called the Cornucopia. Peeta forms an uneasy alliance with the four Careers. They later find Katniss and corner her up a tree. Rue, hiding in a nearby tree, draws her attention to a poisonous tracker jacker nest hanging from a branch. Katniss drops it on her sleeping besiegers. They all scatter, except for Glimmer, who is killed by the insects. Hallucinating due to tracker jacker venom, Katniss is warned to run away by Peeta. Rue cares for Katniss for a couple of days until she recovers. Meanwhile, the alliance has gathered all the supplies into a pile. Katniss has Rue draw them off, then destroys the stockpile by setting off the mines planted around it. Furious, Cato kills the boy assigned to guard it. As Katniss runs from the scene, she hears Rue calling her name. She finds Rue trapped and releases her. Marvel, a tribute from District 1, throws a spear at Katniss, but she dodges the spear, causing it to stab Rue in the stomach instead. Katniss shoots him dead with an arrow. She then comforts the dying Rue with a song. Afterward, she gathers and arranges flowers around Rue's body. When this is televised, it sparks a riot in Rue's District 11. President Snow summons Seneca Crane, the Gamemaker, to express his displeasure at the way the Games are turning out. Since Katniss and Peeta have been presented to the public as \"star-crossed lovers\", Haymitch is able to convince Crane to make a rule change to avoid inciting further riots. It is announced that tributes from the same district can win as a pair. Upon hearing this, Katniss searches for Peeta and finds him with an infected sword wound in the leg. She portrays herself as deeply in love with him and gains a sponsor's gift of soup. An announcer proclaims a feast, where the thing each survivor needs most will be provided. Peeta begs her not to risk getting him medicine. Katniss promises not to go, but after he falls asleep, she heads to the feast. Clove ambushes her and pins her down. As Clove gloats, Thresh, the other District 11 tribute, kills Clove after overhearing her tormenting Katniss about killing Rue. He spares Katniss \"just this time...for Rue\". The medicine works, keeping Peeta mobile. Foxface, the girl from District 5, dies from eating nightlock berries she stole from Peeta; neither knew they are highly poisonous. Crane changes the time of day in the arena to late at night and unleashes a pack of hound-like creatures to speed things up. They kill Thresh and force Katniss and Peeta to flee to the roof of the Cornucopia, where they encounter Cato. After a battle, Katniss wounds Cato with an arrow and Peeta hurls him to the creatures below. Katniss shoots Cato to spare him a prolonged death. With Peeta and Katniss apparently victorious, the rule change allowing two winners is suddenly revoked. Peeta tells Katniss to shoot him. Instead, she gives him half of the nightlock. However, before they can commit suicide, they are hastily proclaimed the victors of the 74th Hunger Games. Haymitch warns Katniss that she has made powerful enemies after her display of defiance. She and Peeta return to District 12, while Crane is locked in a room with a bowl of nightlock berries, and President Snow considers the situation.\"\"\"\n",
    "text_split = text.split()\n",
    "model = FCoref(device='cuda:0')\n",
    "\n",
    "preds = model.predict(\n",
    "    texts=text.split(),\n",
    "    is_split_into_words=True\n",
    ")\n",
    "clusters = preds.get_clusters(as_strings=False)\n",
    "\n",
    "# get the token id, start offset map\n",
    "resolved_text = text.split()\n",
    "\n",
    "for cluster in clusters:\n",
    "    character_name = None\n",
    "    for token_offset in cluster:\n",
    "        token = ' '.join(text_split[token_offset[0]:token_offset[1]])\n",
    "        if token in characters and token.lower() not in [\"he\", \"him\", \"his\", \"she\", \"her\", \"hers\", \"they\", \"them\", \"their\"]:\n",
    "            character_name = token\n",
    "        elif token.lower() in [\"he\", \"him\", \"his\", \"she\", \"her\", \"hers\", \"they\", \"them\", \"their\"] and character_name!=None:\n",
    "            print(token, '->', character_name)\n",
    "            resolved_text[token_offset[0]] = character_name\n",
    "\n",
    "print(' '.join(resolved_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wiki_id</th>\n",
       "      <th>plot</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23890098</td>\n",
       "      <td>Shlykov, a hard-working taxi driver and Lyosha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31186339</td>\n",
       "      <td>The nation of Panem consists of a wealthy Capi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20663735</td>\n",
       "      <td>Poovalli Induchoodan  is sentenced for six yea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2231378</td>\n",
       "      <td>The Lemon Drop Kid , a New York City swindler,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>595909</td>\n",
       "      <td>Seventh-day Adventist Church pastor Michael Ch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42298</th>\n",
       "      <td>34808485</td>\n",
       "      <td>The story is about Reema , a young Muslim scho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42299</th>\n",
       "      <td>1096473</td>\n",
       "      <td>In 1928 Hollywood, director Leo Andreyev  look...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42300</th>\n",
       "      <td>35102018</td>\n",
       "      <td>American Luthier focuses on Randy Parsons’ tra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42301</th>\n",
       "      <td>8628195</td>\n",
       "      <td>Abdur Rehman Khan , a middle-aged dry fruit se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42302</th>\n",
       "      <td>6040782</td>\n",
       "      <td>1940 - Operation Dynamo has just taken place. ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>42303 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        wiki_id                                               plot\n",
       "0      23890098  Shlykov, a hard-working taxi driver and Lyosha...\n",
       "1      31186339  The nation of Panem consists of a wealthy Capi...\n",
       "2      20663735  Poovalli Induchoodan  is sentenced for six yea...\n",
       "3       2231378  The Lemon Drop Kid , a New York City swindler,...\n",
       "4        595909  Seventh-day Adventist Church pastor Michael Ch...\n",
       "...         ...                                                ...\n",
       "42298  34808485  The story is about Reema , a young Muslim scho...\n",
       "42299   1096473  In 1928 Hollywood, director Leo Andreyev  look...\n",
       "42300  35102018  American Luthier focuses on Randy Parsons’ tra...\n",
       "42301   8628195  Abdur Rehman Khan , a middle-aged dry fruit se...\n",
       "42302   6040782  1940 - Operation Dynamo has just taken place. ...\n",
       "\n",
       "[42303 rows x 2 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PLOT_SUMMARY_PATH = \"../data/plot_summaries.txt\"\n",
    "\n",
    "plot_summaries = pd.read_csv(PLOT_SUMMARY_PATH, sep='\\t', header=None)\n",
    "plot_summaries.columns = ['wiki_id', 'plot']\n",
    "plot_summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12/15/2023 14:21:23 - INFO - \t Tokenize 1 inputs...\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 63.68 examples/s]\n",
      "12/15/2023 14:21:23 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00,  1.10it/s]\n",
      "12/15/2023 14:21:24 - INFO - \t Tokenize 1 inputs...\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 43.63 examples/s]\n",
      "12/15/2023 14:21:24 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00,  3.33it/s]\n",
      "12/15/2023 14:21:25 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "she -> Katniss\n",
      "She -> Katniss\n",
      "she -> Katniss\n",
      "her -> Katniss\n",
      "her -> Katniss\n",
      "she -> Katniss\n",
      "she -> Katniss\n",
      "her -> Katniss\n",
      "She -> Katniss\n",
      "she -> Katniss\n",
      "She -> Katniss\n",
      "she -> Katniss\n",
      "She -> Katniss\n",
      "her -> Katniss\n",
      "she -> Katniss\n",
      "her -> Katniss\n",
      "her -> Katniss\n",
      "her -> Katniss\n",
      "she -> Katniss\n",
      "her -> Katniss\n",
      "She -> Katniss\n",
      "his -> Peeta\n",
      "he -> Peeta\n",
      "him -> Peeta\n",
      "him -> Peeta\n",
      "him -> Peeta\n",
      "he -> Peeta\n",
      "she -> Peeta\n",
      "his -> President Snow\n",
      "him -> Cato\n",
      "him -> Cato\n",
      "him -> Cato\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 111.12 examples/s]\n",
      "12/15/2023 14:21:25 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.94it/s]\n",
      "12/15/2023 14:21:25 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "his -> Induchoodan\n",
      "he -> Induchoodan\n",
      "his -> Induchoodan\n",
      "his -> Induchoodan\n",
      "his -> Induchoodan\n",
      "his -> Induchoodan\n",
      "his -> Induchoodan\n",
      "his -> Induchoodan\n",
      "his -> Menon\n",
      "he -> Pavithran\n",
      "his -> Pavithran\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 56.78 examples/s]\n",
      "12/15/2023 14:21:25 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.56it/s]\n",
      "12/15/2023 14:21:25 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "He -> The Kid\n",
      "his -> The Kid\n",
      "He -> the Kid\n",
      "he -> the Kid\n",
      "he -> the Kid\n",
      "he -> the Kid\n",
      "his -> the Kid\n",
      "he -> The Kid\n",
      "his -> the Kid\n",
      "him -> the Kid\n",
      "He -> the Kid\n",
      "his -> the Kid\n",
      "he -> the Kid\n",
      "he -> The kid\n",
      "his -> the Kid\n",
      "he -> The Kid\n",
      "his -> the Kid\n",
      "him -> the Kid\n",
      "his -> the Kid\n",
      "He -> the Kid\n",
      "He -> the Kid\n",
      "his -> the Kid\n",
      "his -> The Kid\n",
      "him -> The Kid\n",
      "his -> The Kid\n",
      "his -> Santa Claus\n",
      "her -> Brainy\n",
      "her -> Brainy\n",
      "her -> Brainy\n",
      "his -> Charley\n",
      "his -> Charley\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 101.26 examples/s]\n",
      "12/15/2023 14:21:25 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.35it/s]\n",
      "12/15/2023 14:21:25 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "his -> Michael\n",
      "his -> Michael's\n",
      "his -> Michael's\n",
      "his -> Michael's\n",
      "he -> Michael's\n",
      "his -> Michael's\n",
      "he -> Michael's\n",
      "her -> her,\n",
      "their -> the family\n",
      "she -> Lindy\n",
      "she -> Lindy\n",
      "she -> Lindy\n",
      "her -> Lindy\n",
      "her -> Lindy\n",
      "she -> Lindy\n",
      "her -> Lindy\n",
      "she -> Lindy\n",
      "she -> Lindy\n",
      "She -> Lindy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 66.74 examples/s]\n",
      "12/15/2023 14:21:25 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.40it/s]\n",
      "12/15/2023 14:21:25 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "him -> Alex\n",
      "his -> Alex\n",
      "He -> Thomas\n",
      "his -> Thomas\n",
      "his -> Thomas\n",
      "he -> Thomas\n",
      "He -> Thomas\n",
      "he -> Thomas\n",
      "him -> Stevens\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 64.23 examples/s]\n",
      "12/15/2023 14:21:25 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.66it/s]\n",
      "12/15/2023 14:21:26 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "his -> Kyle\n",
      "he -> Kyle\n",
      "He -> Kyle\n",
      "his -> Kyle\n",
      "his -> Kyle\n",
      "his -> Kyle\n",
      "she -> Cecilia\n",
      "she -> Cecilia\n",
      "she -> Cecilia\n",
      "her -> Cecilia\n",
      "she -> Cecilia\n",
      "her -> Cecilia\n",
      "her -> Cecilia\n",
      "her -> Cecilia\n",
      "her -> Cecilia\n",
      "her -> Cecilia\n",
      "her -> Cecilia\n",
      "her -> Cecilia\n",
      "her -> Cecilia\n",
      "her -> Cecilia\n",
      "her -> Cecilia\n",
      "She -> Dahlia\n",
      "He -> Veeck\n",
      "he -> Veeck\n",
      "she -> Natasha's\n",
      "her -> Natasha's\n",
      "her -> the girl\n",
      "her -> The girl\n",
      "she -> Dahlia\n",
      "her -> Dahlia\n",
      "her -> Dahlia\n",
      "she -> Dahlia\n",
      "Her -> Dahlia\n",
      "they -> police\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 83.49 examples/s]\n",
      "12/15/2023 14:21:26 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 15.01it/s]\n",
      "12/15/2023 14:21:26 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "her -> Hannah\n",
      "her -> Hannah\n",
      "her -> Miss Lombardo\n",
      "she -> Miss Lombardo\n",
      "her -> Miss Lombardo\n",
      "her -> Miss Lombardo\n",
      "his -> a young man\n",
      "his -> a young man\n",
      "he -> a young man\n",
      "his -> a young man\n",
      "him -> a young man\n",
      "his -> Dominic\n",
      "he -> Dominic\n",
      "He -> Dominic\n",
      "his -> Dominic\n",
      "his -> Dominic\n",
      "he -> Dominic\n",
      "He -> Dominic\n",
      "his -> Dominic\n",
      "them -> its\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 66.45 examples/s]\n",
      "12/15/2023 14:21:26 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.07it/s]\n",
      "12/15/2023 14:21:26 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "she -> Ann Mitchell\n",
      "his -> Mitchell\n",
      "he -> Doe\n",
      "he -> John Doe\n",
      "he -> John Doe\n",
      "his -> John Doe\n",
      "his -> John Doe\n",
      "his -> John Doe\n",
      "him -> John Doe\n",
      "his -> John Doe\n",
      "his -> Willoughby\n",
      "his -> Norton\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 164.68 examples/s]\n",
      "12/15/2023 14:21:26 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 29.15it/s]\n",
      "12/15/2023 14:21:26 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "his -> Buzz\n",
      "he -> Buzz\n",
      "he -> Woody\n",
      "him -> he's\n",
      "he -> Woody\n",
      "he -> Woody\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 358.79 examples/s]\n",
      "12/15/2023 14:21:26 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 22.61it/s]\n",
      "12/15/2023 14:21:26 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "her -> Lola\n",
      "her -> Lola\n",
      "her -> Lola's\n",
      "her -> Lola\n",
      "she -> her,\n",
      "her -> her,\n",
      "She -> her,\n",
      "her -> her,\n",
      "his -> Bo\n",
      "he -> Bo\n",
      "she -> Simona\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 124.66 examples/s]\n",
      "12/15/2023 14:21:26 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 66.33it/s]\n",
      "12/15/2023 14:21:26 - INFO - \t Tokenize 1 inputs...\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 129.51 examples/s]\n",
      "12/15/2023 14:21:26 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 38.93it/s]\n",
      "12/15/2023 14:21:26 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "him -> he's\n",
      "his -> Sellers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 60.54 examples/s]\n",
      "12/15/2023 14:21:26 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 10.16it/s]\n",
      "12/15/2023 14:21:27 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "He -> Ari\n",
      "his -> Ari\n",
      "his -> Ari\n",
      "he -> Ari\n",
      "her -> Karen\n",
      "her -> Karen\n",
      "she -> Karen\n",
      "her -> Karen\n",
      "he -> Dov\n",
      "he -> Dov\n",
      "he -> the boy\n",
      "he -> the boy\n",
      "his -> the boy\n",
      "his -> Dov\n",
      "He -> Akiva\n",
      "his -> Akiva\n",
      "his -> Taha\n",
      "his -> Taha\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 31.68 examples/s]\n",
      "12/15/2023 14:21:27 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.13it/s]\n",
      "12/15/2023 14:21:27 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "he -> Kid\n",
      "they -> Kid\n",
      "he -> Kid\n",
      "his -> Kid\n",
      "he -> Kid's\n",
      "he -> Kid's\n",
      "him -> Kid's\n",
      "his -> Kid\n",
      "him -> Kid\n",
      "his -> Kid\n",
      "him -> Kid's\n",
      "his -> Kid's\n",
      "he -> Kid\n",
      "his -> Kid\n",
      "him -> Kid\n",
      "he -> Kid\n",
      "he -> Kid\n",
      "he -> Kid\n",
      "his -> Kid\n",
      "him -> Kid\n",
      "his -> Kid\n",
      "he -> Kid\n",
      "him -> Kid\n",
      "him -> Kid\n",
      "his -> Kid\n",
      "his -> Kid\n",
      "his -> Kid\n",
      "him -> Kid\n",
      "him -> Kid\n",
      "He -> Kid\n",
      "his -> Kid\n",
      "he -> Kid\n",
      "he -> Kid\n",
      "his -> Kid\n",
      "his -> Kid\n",
      "he -> Kid\n",
      "him -> Kid\n",
      "he -> Kid\n",
      "his -> Kid\n",
      "He -> Kid\n",
      "him -> Kid\n",
      "He -> Play\n",
      "he -> Play\n",
      "him -> Play\n",
      "He -> Play\n",
      "He -> Play\n",
      "her -> Sydney\n",
      "her -> Sydney\n",
      "her -> Sydney\n",
      "she -> Sydney\n",
      "he -> Miles\n",
      "him -> Miles\n",
      "his -> Miles\n",
      "he -> Miles\n",
      "he -> Rick\n",
      "his -> Rick\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 125.06 examples/s]\n",
      "12/15/2023 14:21:27 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 38.64it/s]\n",
      "12/15/2023 14:21:27 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "she -> Lucy's\n",
      "her -> Lucy's\n",
      "her -> Lucy's\n",
      "she -> Lucy's\n",
      "her -> Lucy's\n",
      "her -> Lucy's\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 120.53 examples/s]\n",
      "12/15/2023 14:21:27 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 36.43it/s]\n",
      "12/15/2023 14:21:27 - INFO - \t Tokenize 1 inputs...\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 134.26 examples/s]\n",
      "12/15/2023 14:21:27 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 36.21it/s]\n",
      "12/15/2023 14:21:27 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "her -> Debbie's\n",
      "her -> Debbie\n",
      "she -> Debbie\n",
      "her -> Debbie\n",
      "he -> Chris\n",
      "his -> Chris\n",
      "he -> Chris\n",
      "him -> Chris\n",
      "he -> Chris\n",
      "he -> Chris\n",
      "him -> Chris's\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 124.71 examples/s]\n",
      "12/15/2023 14:21:27 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.84it/s]\n",
      "12/15/2023 14:21:27 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "his -> Gabriel\n",
      "him -> Gabriel\n",
      "his -> Gabriel\n",
      "his -> Gabriel\n",
      "him -> Gabriel\n",
      "his -> Gabriel\n",
      "his -> Gabriel\n",
      "she -> Arabella\n",
      "her -> Arabella\n",
      "his -> Enrico\n",
      "his -> Enrico\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 54.68 examples/s]\n",
      "12/15/2023 14:21:27 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 36.42it/s]\n",
      "12/15/2023 14:21:27 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "his -> Tai\n",
      "he -> Minh\n",
      "his -> Minh\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 119.51 examples/s]\n",
      "12/15/2023 14:21:28 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 37.68it/s]\n",
      "12/15/2023 14:21:28 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "he -> Bluey\n",
      "he -> Bluey\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 97.09 examples/s]\n",
      "12/15/2023 14:21:28 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 15.73it/s]\n",
      "12/15/2023 14:21:28 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "his -> Red\n",
      "he -> Red\n",
      "he -> Red\n",
      "he -> Red\n",
      "he -> Lumpy\n",
      "him -> Lumpy\n",
      "his -> Lumpy\n",
      "his -> Lumpy\n",
      "he -> he's\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 99.54 examples/s]\n",
      "12/15/2023 14:21:28 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 55.26it/s]\n",
      "12/15/2023 14:21:28 - INFO - \t Tokenize 1 inputs...\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 121.95 examples/s]\n",
      "12/15/2023 14:21:28 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 61.37it/s]\n",
      "12/15/2023 14:21:28 - INFO - \t Tokenize 1 inputs...\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 175.51 examples/s]\n",
      "12/15/2023 14:21:28 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.37it/s]\n",
      "12/15/2023 14:21:28 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "his -> Zachariah\n",
      "he -> Zachariah\n",
      "his -> Zachariah\n",
      "he -> Zachariah\n",
      "he -> Zachariah\n",
      "his -> Zachariah\n",
      "he -> Zachariah\n",
      "he -> Zachariah\n",
      "he -> Zachariah\n",
      "he -> Zachariah\n",
      "him -> Zachariah\n",
      "his -> Zachariah\n",
      "he -> Zachariah\n",
      "his -> Zachariah\n",
      "He -> Zachariah\n",
      "his -> Zachariah\n",
      "his -> Zachariah\n",
      "his -> Zachariah\n",
      "he -> Zachariah\n",
      "she -> his wife\n",
      "her -> his wife\n",
      "she -> his wife\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 78.44 examples/s]\n",
      "12/15/2023 14:21:28 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 15.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "He -> Madhav\n",
      "his -> Madhav\n",
      "he -> Madhav\n",
      "his -> Madhav\n",
      "his -> Madhav\n",
      "He -> Madhav\n",
      "him -> Madhav\n",
      "he -> Madhav\n",
      "his -> Madhav\n",
      "His -> Madhav\n",
      "He -> Madhav\n",
      "him -> Madhav\n",
      "him -> Madhav\n",
      "his -> Sreenu\n",
      "his -> Sreenu\n",
      "him -> Sreenu\n",
      "her -> Amrutha\n",
      "she -> Amrutha\n",
      "her -> Amrutha\n",
      "her -> Amrutha\n",
      "Her -> Amrutha\n",
      "her -> Amrutha\n",
      "her -> Amrutha\n",
      "her -> Amrutha\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12/15/2023 14:21:28 - INFO - \t Tokenize 1 inputs...\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 35.89 examples/s]\n",
      "12/15/2023 14:21:28 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00,  4.00it/s]\n",
      "12/15/2023 14:21:29 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "his -> Bhagwaan\n",
      "his -> Bhagwaan\n",
      "he -> Bhagwaan\n",
      "his -> Bhagwaan\n",
      "his -> Bhagwaan\n",
      "his -> Bhagwaan\n",
      "He -> Bhagwaan\n",
      "his -> Bhagwaan\n",
      "He -> Bhagwaan\n",
      "she -> Bhagwaan\n",
      "him -> Bhagwaan\n",
      "his -> Bhagwaan\n",
      "him -> Bhagwaan\n",
      "He -> Bhagwaan\n",
      "his -> Bhagwaan\n",
      "his -> Bhagwaan\n",
      "him -> Bhagwaan\n",
      "his -> Bhagwaan\n",
      "he -> Bhagwaan\n",
      "he -> Bhagwaan\n",
      "his -> Bhagwaan\n",
      "he -> Bhagwaan\n",
      "he -> Bhagwaan\n",
      "his -> Bhagwaan\n",
      "his -> Bhagwaan\n",
      "his -> Shambu\n",
      "his -> Shambu\n",
      "He -> Swaroop\n",
      "him -> Swaroop\n",
      "his -> Swaroop\n",
      "he -> Swaroop\n",
      "his -> Swaroop\n",
      "he -> Swaroop\n",
      "her -> her,\n",
      "she -> Bijli\n",
      "her -> Bijli\n",
      "she -> Bijli\n",
      "her -> Bijli\n",
      "she -> Bijli\n",
      "his -> Bijli\n",
      "her -> Bijli\n",
      "she -> Bijli\n",
      "she -> Bijli\n",
      "She -> Bijli\n",
      "she -> Bijli\n",
      "her -> Bijli\n",
      "her -> Bijli\n",
      "she -> Bijli\n",
      "her -> Bijli\n",
      "her -> Bijli\n",
      "he -> Govinda\n",
      "his -> Govinda\n",
      "his -> Govinda\n",
      "his -> Govinda\n",
      "his -> Govinda\n",
      "her -> Madhu\n",
      "she -> Madhu\n",
      "she -> her,\n",
      "her -> her,\n",
      "her -> Geeta\n",
      "his -> Shambu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 213.84 examples/s]\n",
      "12/15/2023 14:21:29 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 30.06it/s]\n",
      "12/15/2023 14:21:29 - INFO - \t Tokenize 1 inputs...\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 96.32 examples/s]\n",
      "12/15/2023 14:21:29 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 20.32it/s]\n",
      "12/15/2023 14:21:29 - INFO - \t Tokenize 1 inputs...\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 241.94 examples/s]\n",
      "12/15/2023 14:21:29 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 18.33it/s]\n",
      "12/15/2023 14:21:29 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "she -> Anita\n",
      "her -> Anita\n",
      "her -> Anita\n",
      "her -> Anita\n",
      "her -> Anita\n",
      "her -> Anita\n",
      "her -> Anita\n",
      "her -> Anita\n",
      "her -> Anita\n",
      "her -> Sita\n",
      "he -> Preetam\n",
      "his -> Preetam\n",
      "he -> Preetam\n",
      "him -> Preetam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 262.16 examples/s]\n",
      "12/15/2023 14:21:29 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 15.08it/s]\n",
      "12/15/2023 14:21:29 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "his -> Samson\n",
      "his -> Samson\n",
      "his -> Samson\n",
      "his -> Samson\n",
      "he -> Samson\n",
      "his -> Samson\n",
      "his -> Samson\n",
      "him -> Samson\n",
      "his -> Samson\n",
      "him -> Samson\n",
      "his -> Samson\n",
      "he -> Samson\n",
      "him -> Samson\n",
      "his -> Samson\n",
      "his -> Samson\n",
      "his -> Samson\n",
      "him -> Samson\n",
      "he -> Samson\n",
      "he -> Samson\n",
      "he -> Samson\n",
      "his -> Samson\n",
      "Her -> Delilah\n",
      "she -> Delilah\n",
      "her -> Delilah\n",
      "her -> Delilah\n",
      "She -> Delilah\n",
      "she -> Delilah\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 113.19 examples/s]\n",
      "12/15/2023 14:21:29 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 35.68it/s]\n",
      "12/15/2023 14:21:29 - INFO - \t Tokenize 1 inputs...\n",
      "Map: 100%|██████████| 1/1 [00:00<?, ? examples/s]\n",
      "12/15/2023 14:21:29 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 34.96it/s]\n",
      "12/15/2023 14:21:29 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "She -> Mary\n",
      "she -> Mary\n",
      "She -> Mary's\n",
      "she -> Mary\n",
      "her -> Mary\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 88.46 examples/s]\n",
      "12/15/2023 14:21:29 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 20.56it/s]\n",
      "12/15/2023 14:21:30 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "her -> Beth Cappadora\n",
      "her -> Beth\n",
      "her -> Beth\n",
      "her -> Beth\n",
      "him -> Ben\n",
      "his -> Ben\n",
      "him -> Ben\n",
      "he -> Ben\n",
      "his -> Ben\n",
      "him -> Ben\n",
      "his -> Ben\n",
      "his -> Ben\n",
      "their -> the family\n",
      "their -> the family\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 90.88 examples/s]\n",
      "12/15/2023 14:21:30 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00,  9.38it/s]\n",
      "12/15/2023 14:21:30 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "him -> Timmy\n",
      "He -> Timmy\n",
      "he -> Timmy\n",
      "his -> Timmy\n",
      "he -> Timmy\n",
      "he -> Timmy\n",
      "his -> Timmy\n",
      "She -> his mother\n",
      "her -> The mother\n",
      "she -> The mother\n",
      "her -> The mother\n",
      "her -> Mary\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 149.08 examples/s]\n",
      "12/15/2023 14:21:30 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "him -> Matt\n",
      "his -> Matt\n",
      "his -> Matt\n",
      "he -> Matt\n",
      "he -> Matt's\n",
      "his -> Matt\n",
      "she -> Kay\n",
      "she -> Kay\n",
      "her -> Kay\n",
      "she -> Kay\n",
      "her -> Kay\n",
      "he -> Harry\n",
      "he -> Mark\n",
      "his -> the boy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12/15/2023 14:21:30 - INFO - \t Tokenize 1 inputs...\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 140.32 examples/s]\n",
      "12/15/2023 14:21:30 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 18.33it/s]\n",
      "12/15/2023 14:21:30 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "she -> his wife\n",
      "her -> his wife\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 122.66 examples/s]\n",
      "12/15/2023 14:21:30 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 21.68it/s]\n",
      "12/15/2023 14:21:30 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "him -> Porky Pig\n",
      "him -> Porky Pig\n",
      "his -> Porky Pig\n",
      "he -> Porky\n",
      "his -> Porky\n",
      "his -> Porky\n",
      "his -> Daffy\n",
      "his -> Daffy\n",
      "his -> Daffy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 275.54 examples/s]\n",
      "12/15/2023 14:21:30 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 50.81it/s]\n",
      "12/15/2023 14:21:30 - INFO - \t Tokenize 1 inputs...\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 124.70 examples/s]\n",
      "12/15/2023 14:21:30 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 37.97it/s]\n",
      "12/15/2023 14:21:30 - INFO - \t Tokenize 1 inputs...\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 43.11 examples/s]\n",
      "12/15/2023 14:21:30 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.93it/s]\n",
      "12/15/2023 14:21:31 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "his -> Woo\n",
      "his -> Cao\n",
      "him -> Cao\n",
      "his -> Cao\n",
      "his -> Cao\n",
      "he -> Cao\n",
      "him -> Cao\n",
      "his -> Liu Bei\n",
      "his -> Zhuge\n",
      "his -> Sun Quan\n",
      "his -> Zhou Yu\n",
      "him -> Zhou Yu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 47.76 examples/s]\n",
      "12/15/2023 14:21:31 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 21.11it/s]\n",
      "12/15/2023 14:21:31 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "his -> The Weird\n",
      "he -> The Weird\n",
      "his -> The Bad\n",
      "he -> The Weird\n",
      "he -> The Weird\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 108.51 examples/s]\n",
      "12/15/2023 14:21:31 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "she -> Anna\n",
      "she -> Anna\n",
      "she -> Anna\n",
      "his -> Semyon\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12/15/2023 14:21:31 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "him -> Nikolai's\n",
      "his -> Nikolai\n",
      "his -> Nikolai\n",
      "him -> Kirill\n",
      "him -> Kirill\n",
      "him -> Kirill\n",
      "she -> Anna\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 124.69 examples/s]\n",
      "12/15/2023 14:21:31 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 39.23it/s]\n",
      "12/15/2023 14:21:31 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "her -> Betty Boop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 64.69 examples/s]\n",
      "12/15/2023 14:21:31 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 20.37it/s]\n",
      "12/15/2023 14:21:31 - INFO - \t Tokenize 1 inputs...\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 117.89 examples/s]\n",
      "12/15/2023 14:21:31 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 49.42it/s]\n",
      "12/15/2023 14:21:31 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "he -> Kishen\n",
      "he -> Kishen\n",
      "his -> Kishen\n",
      "He -> Prem\n",
      "he -> Prem\n",
      "his -> Prem\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 108.35 examples/s]\n",
      "12/15/2023 14:21:31 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 19.98it/s]\n",
      "12/15/2023 14:21:32 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "his -> Tahaan\n",
      "He -> Tahaan\n",
      "He -> Tahaan\n",
      "he -> Tahaan\n",
      "he -> Tahaan\n",
      "he -> Tahaan\n",
      "his -> Tahaan\n",
      "his -> Tahaan\n",
      "he -> Tahaan\n",
      "him -> Tahaan\n",
      "his -> Tahaan\n",
      "his -> Tahaan\n",
      "him -> Tahaan\n",
      "he -> Tahaan\n",
      "he -> Tahaan\n",
      "his -> Tahaan\n",
      "He -> Tahaan\n",
      "his -> Tahaan\n",
      "him -> Birbal\n",
      "his -> Subhan\n",
      "his -> Subhan\n",
      "his -> Zafar\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 56.18 examples/s]\n",
      "12/15/2023 14:21:32 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 41.35it/s]\n",
      "12/15/2023 14:21:32 - INFO - \t Tokenize 1 inputs...\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 140.97 examples/s]\n",
      "12/15/2023 14:21:32 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 42.50it/s]\n",
      "12/15/2023 14:21:32 - INFO - \t Tokenize 1 inputs...\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 132.48 examples/s]\n",
      "12/15/2023 14:21:32 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 23.43it/s]\n",
      "12/15/2023 14:21:32 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "his -> Wind\n",
      "his -> Wind\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 92.76 examples/s]\n",
      "12/15/2023 14:21:32 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 44.52it/s]\n",
      "12/15/2023 14:21:32 - INFO - \t Tokenize 1 inputs...\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 168.79 examples/s]\n",
      "12/15/2023 14:21:32 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 53.58it/s]\n",
      "12/15/2023 14:21:32 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "him -> Porky\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 125.35 examples/s]\n",
      "12/15/2023 14:21:32 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 40.36it/s]\n",
      "12/15/2023 14:21:32 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "She -> Odile Deray\n",
      "she -> Odile Deray\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 125.00 examples/s]\n",
      "12/15/2023 14:21:32 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 34.59it/s]\n",
      "12/15/2023 14:21:32 - INFO - \t Tokenize 1 inputs...\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 105.25 examples/s]\n",
      "12/15/2023 14:21:32 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 10.73it/s]\n",
      "12/15/2023 14:21:32 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "him -> you\n",
      "his -> you\n",
      "he -> Chester\n",
      "his -> Chester\n",
      "his -> Chester\n",
      "him -> Chester\n",
      "he -> Chester\n",
      "her -> Helen's\n",
      "she -> Helen's\n",
      "her -> Helen\n",
      "she -> Helen\n",
      "her -> Helen\n",
      "she -> Helen\n",
      "her -> Helen\n",
      "she -> Helen\n",
      "her -> Helen\n",
      "her -> Helen\n",
      "her -> Helen\n",
      "his -> Fyodor\n",
      "he -> Fyodor\n",
      "his -> Fyodor\n",
      "he -> Fyodor\n",
      "his -> Roderick\n",
      "his -> Roderick\n",
      "he -> Roderick\n",
      "he -> Roderick\n",
      "his -> Roderick\n",
      "his -> Roderick\n",
      "his -> Roderick\n",
      "his -> Roderick\n",
      "his -> Roderick\n",
      "him -> Roderick\n",
      "him -> Roderick\n",
      "his -> Roderick\n",
      "his -> Roderick\n",
      "his -> Roderick\n",
      "his -> Roderick\n",
      "she -> Narcissa\n",
      "her -> Narcissa\n",
      "she -> Narcissa\n",
      "her -> Narcissa\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<?, ? examples/s]\n",
      "12/15/2023 14:21:32 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 42.18it/s]\n",
      "12/15/2023 14:21:32 - INFO - \t Tokenize 1 inputs...\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 69.86 examples/s]\n",
      "12/15/2023 14:21:33 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 28.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "him -> Oliver\n",
      "his -> Oliver\n",
      "his -> Dodge\n",
      "him -> Dodge\n",
      "his -> Dodge\n",
      "he -> Dodge\n",
      "his -> Dodge\n",
      "his -> Dodge\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12/15/2023 14:21:33 - INFO - \t Tokenize 1 inputs...\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 96.31 examples/s]\n",
      "12/15/2023 14:21:33 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 16.03it/s]\n",
      "12/15/2023 14:21:33 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "he -> Gordon\n",
      "his -> Gordon\n",
      "him -> Gordon\n",
      "he -> Gordon\n",
      "he -> Gordon\n",
      "He -> Gordon\n",
      "him -> Gordon\n",
      "He -> Gordon\n",
      "his -> Joel\n",
      "her -> Joel\n",
      "him -> Joel\n",
      "his -> Brennan\n",
      "his -> Brennan\n",
      "He -> Brennan\n",
      "he -> Brennan\n",
      "him -> Brennan\n",
      "she -> Karloff\n",
      "her -> Karloff\n",
      "her -> Karloff\n",
      "she -> Carter\n",
      "his -> Nieterstein\n",
      "his -> Nieterstein\n",
      "his -> Nieterstein\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<?, ? examples/s]\n",
      "12/15/2023 14:21:33 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 44.39it/s]\n",
      "12/15/2023 14:21:33 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "her -> Betty\n",
      "She -> Betty\n",
      "she -> Betty\n",
      "him -> Mose\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 52.78 examples/s]\n",
      "12/15/2023 14:21:33 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.58it/s]\n",
      "12/15/2023 14:21:33 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "he -> Michael\n",
      "he -> Michael\n",
      "he -> Michael\n",
      "he -> Michael\n",
      "his -> Lorenzo\n",
      "He -> Lorenzo\n",
      "him -> Lorenzo\n",
      "he -> Lorenzo\n",
      "he -> Lorenzo\n",
      "her -> her,\n",
      "her -> her,\n",
      "her -> her,\n",
      "his -> T-Bone\n",
      "his -> T-Bone\n",
      "he -> Ray\n",
      "his -> Ray\n",
      "his -> Ray\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 124.77 examples/s]\n",
      "12/15/2023 14:21:33 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.99it/s]\n",
      "12/15/2023 14:21:33 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "she -> Miranda\n",
      "she -> Miranda\n",
      "her -> Miranda\n",
      "she -> Miranda\n",
      "she -> Miranda\n",
      "she -> Miranda\n",
      "her -> Miranda\n",
      "her -> her,\n",
      "her -> her,\n",
      "her -> Quincey\n",
      "her -> Quincey\n",
      "she -> Quincey\n",
      "her -> Quincey\n",
      "she -> Quincey\n",
      "her -> Quincey\n",
      "her -> Quincey\n",
      "her -> Quincey\n",
      "her -> Quincey\n",
      "his -> Rawdon\n",
      "he -> Rawdon\n",
      "he -> Rawdon\n",
      "him -> Rawdon\n",
      "his -> Rawdon\n",
      "he -> Rawdon\n",
      "him -> Rawdon\n",
      "his -> Rawdon\n",
      "him -> Rawdon\n",
      "his -> Rawdon\n",
      "He -> Rawdon\n",
      "He -> Rawdon\n",
      "his -> Rawdon\n",
      "He -> Rawdon\n",
      "He -> Rawdon\n",
      "he -> Rawdon\n",
      "him -> Rawdon\n",
      "his -> Rawdon\n",
      "him -> Rawdon\n",
      "his -> Rawdon\n",
      "him -> Rawdon\n",
      "he -> Rawdon\n",
      "he -> Rawdon\n",
      "he -> Rawdon\n",
      "him -> Rawdon\n",
      "He -> her Dad\n",
      "his -> her Dad\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<?, ? examples/s]\n",
      "12/15/2023 14:21:33 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 51.16it/s]\n",
      "12/15/2023 14:21:33 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "her -> Bhavana\n",
      "her -> Sonia\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 88.31 examples/s]\n",
      "12/15/2023 14:21:33 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 39.84it/s]\n",
      "12/15/2023 14:21:33 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "his -> Nirmal\n",
      "him -> Nirmal\n",
      "he -> Nirmal\n",
      "his -> Nirmal\n",
      "her -> Usha\n",
      "she -> Janaki\n",
      "she -> Janaki\n",
      "her -> Janaki\n",
      "her -> Satyavati\n",
      "she -> Satyavati\n",
      "he -> Satyavati\n",
      "her -> Satyavati\n",
      "he -> Satyavati\n",
      "her -> Satyavati\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 55.29 examples/s]\n",
      "12/15/2023 14:21:33 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.24it/s]\n",
      "12/15/2023 14:21:34 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "he -> Wile E.\n",
      "his -> Wile E.\n",
      "He -> Wile E.\n",
      "he -> Wile E.\n",
      "his -> Wile E.\n",
      "his -> Wile E.\n",
      "his -> Wile E.\n",
      "his -> Wile E.\n",
      "his -> Wile E.\n",
      "he -> Wile E.\n",
      "him -> Wile E.\n",
      "his -> Wile E.\n",
      "he -> Wile E.\n",
      "him -> Wile\n",
      "his -> Wile\n",
      "him -> Wile\n",
      "he -> Wile\n",
      "he -> Wile\n",
      "his -> Wile\n",
      "he -> Wile\n",
      "him -> Wile\n",
      "he -> Wile\n",
      "his -> Wile\n",
      "his -> Wile\n",
      "he -> Wile\n",
      "his -> Wile\n",
      "He -> Wile\n",
      "he -> Wile\n",
      "his -> Wile\n",
      "his -> Wile E.\n",
      "his -> Wile E.\n",
      "his -> Wile E.\n",
      "him -> Wile E.\n",
      "his -> Wile E.\n",
      "his -> Wile E.\n",
      "him -> Wile E.\n",
      "he -> Wile\n",
      "his -> Wile\n",
      "He -> Wile\n",
      "his -> the coyote\n",
      "his -> the coyote\n",
      "he -> the coyote\n",
      "his -> the coyote\n",
      "him -> the coyote\n",
      "he -> Wile E. Coyote\n",
      "his -> Wile E. Coyote\n",
      "his -> Wile E. Coyote\n",
      "his -> Wile E. Coyote\n",
      "he -> Wile E. Coyote\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 124.99 examples/s]\n",
      "12/15/2023 14:21:34 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.12it/s]\n",
      "12/15/2023 14:21:34 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "She -> Ellen\n",
      "her -> Ellen\n",
      "she -> Ellen\n",
      "she -> Ellen\n",
      "She -> Ellen\n",
      "She -> Ellen Brody\n",
      "her -> Ellen\n",
      "her -> Ellen\n",
      "he -> Sean\n",
      "his -> Sean\n",
      "him -> Sean\n",
      "his -> Sean\n",
      "he -> Jake\n",
      "he -> Jake\n",
      "her -> Thea\n",
      "her -> Thea\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 41.00 examples/s]\n",
      "12/15/2023 14:21:34 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "him -> Manu\n",
      "her -> Indu\n",
      "her -> Indu\n",
      "her -> Indu\n",
      "her -> Indu\n",
      "his -> Sagar\n",
      "him -> Sagar's\n",
      "his -> Sagar\n",
      "his -> Sagar\n",
      "he -> Sagar\n",
      "he -> Sagar\n",
      "he -> Sagar\n",
      "he -> Sagar\n",
      "He -> Imran\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12/15/2023 14:21:34 - INFO - \t Tokenize 1 inputs...\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 105.09 examples/s]\n",
      "12/15/2023 14:21:34 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 19.35it/s]\n",
      "12/15/2023 14:21:34 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "He -> Bellamy\n",
      "his -> Doc\n",
      "his -> Doc\n",
      "His -> Doc\n",
      "his -> Doc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 87.65 examples/s]\n",
      "12/15/2023 14:21:34 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 52.83it/s]\n",
      "12/15/2023 14:21:34 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "he -> Antonio\n",
      "his -> Antonio\n",
      "his -> Antonio\n",
      "He -> Antonio\n",
      "his -> Antonio\n",
      "he -> Antonio\n",
      "his -> Antonio\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<?, ? examples/s]\n",
      "12/15/2023 14:21:34 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.76it/s]\n",
      "12/15/2023 14:21:34 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "her -> Yaeli\n",
      "she -> Yaeli\n",
      "He -> Constanza\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<?, ? examples/s]\n",
      "12/15/2023 14:21:34 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 17.00it/s]\n",
      "12/15/2023 14:21:35 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "she -> Rachel's\n",
      "she -> Rachel's\n",
      "her -> Rachel's\n",
      "she -> Rachel\n",
      "her -> Rachel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 62.17 examples/s]\n",
      "12/15/2023 14:21:35 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.93it/s]\n",
      "12/15/2023 14:21:35 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "her -> The woman\n",
      "she -> The woman\n",
      "her -> The woman\n",
      "she -> The woman\n",
      "she -> The woman\n",
      "her -> The woman\n",
      "his -> the boy\n",
      "he -> The boy\n",
      "he -> The boy\n",
      "him -> The boy\n",
      "He -> The boy\n",
      "his -> The boy\n",
      "he -> The boy\n",
      "his -> The boy\n",
      "he -> the boy\n",
      "he -> the boy\n",
      "he -> the boy\n",
      "his -> the boy\n",
      "he -> the boy\n",
      "his -> the boy\n",
      "his -> The boy\n",
      "his -> The boy\n",
      "he -> Francisco\n",
      "his -> Francisco\n",
      "his -> Francisco\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 77.97 examples/s]\n",
      "12/15/2023 14:21:35 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 15.29it/s]\n",
      "12/15/2023 14:21:35 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "his -> Philibert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 88.05 examples/s]\n",
      "12/15/2023 14:21:35 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 10.43it/s]\n",
      "12/15/2023 14:21:35 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "his -> Warren Schmidt\n",
      "his -> Schmidt\n",
      "he -> Schmidt\n",
      "He -> Schmidt\n",
      "his -> Schmidt\n",
      "he -> Schmidt\n",
      "his -> Schmidt\n",
      "his -> Schmidt\n",
      "his -> Schmidt\n",
      "he -> Schmidt\n",
      "his -> Schmidt\n",
      "his -> Schmidt\n",
      "He -> Schmidt\n",
      "his -> Schmidt\n",
      "his -> Schmidt\n",
      "his -> Schmidt\n",
      "his -> Schmidt\n",
      "him -> Schmidt\n",
      "him -> Schmidt\n",
      "his -> Schmidt\n",
      "He -> Schmidt\n",
      "him -> Schmidt\n",
      "his -> Schmidt\n",
      "he -> Schmidt\n",
      "He -> Schmidt\n",
      "his -> Schmidt\n",
      "he -> Schmidt\n",
      "his -> Schmidt\n",
      "he -> Schmidt\n",
      "his -> Schmidt\n",
      "his -> Schmidt\n",
      "He -> Schmidt\n",
      "him -> he's\n",
      "his -> Schmidt\n",
      "his -> Schmidt\n",
      "His -> Schmidt\n",
      "he -> Schmidt\n",
      "his -> Schmidt\n",
      "his -> Schmidt\n",
      "his -> Schmidt\n",
      "He -> Schmidt\n",
      "He -> Schmidt\n",
      "his -> Schmidt\n",
      "his -> Schmidt\n",
      "him -> Schmidt\n",
      "his -> Schmidt\n",
      "he -> Schmidt\n",
      "he -> Schmidt\n",
      "his -> Schmidt\n",
      "he -> Schmidt\n",
      "him -> Schmidt\n",
      "he -> Schmidt\n",
      "her -> Jeannie\n",
      "she -> Jeannie\n",
      "she -> Jeannie\n",
      "she -> Jeannie\n",
      "They -> Friends\n",
      "her -> his wife\n",
      "she -> his wife\n",
      "her -> his wife\n",
      "her -> his daughter\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<?, ? examples/s]\n",
      "12/15/2023 14:21:35 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 24.93it/s]\n",
      "12/15/2023 14:21:35 - INFO - \t Tokenize 1 inputs...\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 124.98 examples/s]\n",
      "12/15/2023 14:21:35 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.51it/s]\n",
      "12/15/2023 14:21:35 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "He -> Stephen\n",
      "his -> Stephen\n",
      "his -> Stephen\n",
      "he -> Stephen\n",
      "he -> Stephen\n",
      "he -> Stephen\n",
      "him -> Stephen\n",
      "his -> Stephen\n",
      "his -> Stephen\n",
      "he -> Stephen\n",
      "him -> Stephen\n",
      "he -> Stephen\n",
      "his -> Stephen\n",
      "his -> Stephen\n",
      "he -> Stephen\n",
      "he -> Stephen\n",
      "his -> Stephen\n",
      "he -> Stephen\n",
      "She -> Hester\n",
      "her -> Hester\n",
      "he -> Don\n",
      "he -> Don\n",
      "he -> Ho\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 86.35 examples/s]\n",
      "12/15/2023 14:21:35 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "his -> Littlefoot\n",
      "his -> Littlefoot\n",
      "his -> Hyp\n",
      "his -> Hyp\n",
      "him -> Hyp\n",
      "his -> Hyp\n",
      "his -> Hyp\n",
      "he -> Hyp\n",
      "his -> Hyp\n",
      "his -> Hyp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12/15/2023 14:21:35 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "he -> Grandpa\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 58.91 examples/s]\n",
      "12/15/2023 14:21:35 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.36it/s]\n",
      "12/15/2023 14:21:36 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "He -> Fletcher Reede\n",
      "his -> Fletcher Reede\n",
      "his -> Fletcher\n",
      "his -> Fletcher\n",
      "him -> Fletcher\n",
      "he -> Fletcher\n",
      "he -> Fletcher\n",
      "his -> Fletcher\n",
      "he -> Fletcher\n",
      "his -> Fletcher\n",
      "he -> Fletcher\n",
      "he -> Fletcher\n",
      "he -> Fletcher\n",
      "he -> Fletcher\n",
      "he -> Fletcher\n",
      "he -> Fletcher\n",
      "his -> Fletcher\n",
      "His -> Fletcher\n",
      "His -> Fletcher\n",
      "he -> Fletcher\n",
      "he -> Fletcher\n",
      "he -> Fletcher\n",
      "he -> Fletcher\n",
      "he -> Fletcher\n",
      "he -> Fletcher\n",
      "he -> Fletcher\n",
      "he -> Fletcher\n",
      "his -> Fletcher\n",
      "him -> Fletcher\n",
      "his -> Fletcher\n",
      "his -> Fletcher\n",
      "his -> Fletcher\n",
      "his -> Fletcher\n",
      "him -> Fletcher\n",
      "his -> Fletcher\n",
      "he -> Fletcher\n",
      "his -> Fletcher\n",
      "his -> Fletcher\n",
      "He -> Fletcher\n",
      "he -> Fletcher\n",
      "his -> Fletcher\n",
      "he -> Fletcher\n",
      "his -> Fletcher\n",
      "his -> Max\n",
      "his -> Max\n",
      "him -> Max\n",
      "him -> Max\n",
      "him -> Max\n",
      "he -> Max\n",
      "his -> Max\n",
      "he -> Max\n",
      "his -> Max\n",
      "his -> Max\n",
      "her -> Miranda\n",
      "her -> Audrey\n",
      "she -> Audrey\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 101.81 examples/s]\n",
      "12/15/2023 14:21:36 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.17it/s]\n",
      "12/15/2023 14:21:36 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "her -> Charlotte\n",
      "She -> Charlotte\n",
      "she -> Charlotte\n",
      "her -> Charlotte\n",
      "her -> Charlotte\n",
      "her -> Charlotte\n",
      "her -> Charlotte\n",
      "She -> Charlotte\n",
      "her -> Charlotte\n",
      "her -> Charlotte\n",
      "she -> Charlotte\n",
      "her -> Charlotte\n",
      "her -> Charlotte's\n",
      "her -> Charlotte's\n",
      "her -> Charlotte\n",
      "her -> Charlotte\n",
      "her -> Charlotte\n",
      "She -> Charlotte\n",
      "her -> Charlotte\n",
      "she -> Charlotte\n",
      "her -> Charlotte\n",
      "he -> John\n",
      "her -> Miriam\n",
      "she -> Miriam\n",
      "her -> Velma\n",
      "her -> Velma\n",
      "her -> Jewel\n",
      "her -> Jewel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 62.17 examples/s]\n",
      "12/15/2023 14:21:36 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 62.39it/s]\n",
      "12/15/2023 14:21:36 - INFO - \t Tokenize 1 inputs...\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 123.31 examples/s]\n",
      "12/15/2023 14:21:36 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 41.36it/s]\n",
      "12/15/2023 14:21:36 - INFO - \t Tokenize 1 inputs...\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 101.46 examples/s]\n",
      "12/15/2023 14:21:36 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 60.07it/s]\n",
      "12/15/2023 14:21:36 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "his -> Jean\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 60.50 examples/s]\n",
      "12/15/2023 14:21:36 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.30it/s]\n",
      "12/15/2023 14:21:36 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "his -> Robeson\n",
      "his -> Jones\n",
      "his -> Jones\n",
      "he -> Jones\n",
      "him -> Jones\n",
      "he -> Jones\n",
      "his -> Jones\n",
      "he -> Jones\n",
      "his -> Jones\n",
      "he -> Jones\n",
      "He -> Jones\n",
      "his -> Jones\n",
      "him -> Jones\n",
      "he -> Jones\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 60.58 examples/s]\n",
      "12/15/2023 14:21:36 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 18.29it/s]\n",
      "12/15/2023 14:21:36 - INFO - \t Tokenize 1 inputs...\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 81.88 examples/s]\n",
      "12/15/2023 14:21:36 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 34.03it/s]\n",
      "12/15/2023 14:21:36 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "his -> Murray\n",
      "his -> Murray\n",
      "he -> Murray\n",
      "him -> Murray\n",
      "his -> Murray\n",
      "his -> Murray\n",
      "him -> Murray\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 72.93 examples/s]\n",
      "12/15/2023 14:21:36 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "she -> Randy\n",
      "her -> Randy\n",
      "her -> Randy\n",
      "her -> Evie\n",
      "her -> Evie\n",
      "she -> Evie\n",
      "her -> Evie\n",
      "her -> Evie\n",
      "she -> Evie\n",
      "her -> Evie\n",
      "her -> Evie\n",
      "she -> Evie\n",
      "her -> Evie\n",
      "her -> Evie\n",
      "her -> Evie\n",
      "her -> Evie\n",
      "her -> Evie\n",
      "her -> you\n",
      "she -> you\n",
      "she -> Evelyn\n",
      "she -> Evelyn\n",
      "she -> Evie\n",
      "her -> Vicky\n",
      "he -> Frank\n",
      "her -> Ali\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12/15/2023 14:21:36 - INFO - \t Tokenize 1 inputs...\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 161.24 examples/s]\n",
      "12/15/2023 14:21:37 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 84.69it/s]\n",
      "12/15/2023 14:21:37 - INFO - \t Tokenize 1 inputs...\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 124.73 examples/s]\n",
      "12/15/2023 14:21:37 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 29.55it/s]\n",
      "12/15/2023 14:21:37 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "he -> Pierre\n",
      "his -> Pierre\n",
      "His -> Pierre\n",
      "him -> Pierre\n",
      "he -> Pierre\n",
      "he -> Pierre\n",
      "his -> Pierre\n",
      "he -> Pierre\n",
      "he -> Pierre\n",
      "his -> Pierre\n",
      "He -> Pierre\n",
      "his -> Pierre\n",
      "him -> Pierre\n",
      "her -> the girl\n",
      "her -> the girl\n",
      "her -> the girl\n",
      "she -> Madeleine\n",
      "their -> Both\n",
      "they -> the police\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 795.73 examples/s]\n",
      "12/15/2023 14:21:37 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 51.75it/s]\n",
      "12/15/2023 14:21:37 - INFO - \t Tokenize 1 inputs...\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 132.76 examples/s]\n",
      "12/15/2023 14:21:37 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.98it/s]\n",
      "12/15/2023 14:21:37 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "He -> Karthik\n",
      "his -> Karthik\n",
      "he -> Karthik\n",
      "he -> Karthik\n",
      "he -> Karthik\n",
      "he -> Karthik\n",
      "he -> Karthik\n",
      "his -> Karthik\n",
      "his -> Karthik\n",
      "his -> Karthik\n",
      "his -> Karthik\n",
      "his -> Karthik\n",
      "him -> Karthik\n",
      "his -> Karthik\n",
      "he -> Karthik\n",
      "him -> Karthik\n",
      "him -> Karthik\n",
      "he -> Karthik\n",
      "his -> Karthik\n",
      "him -> Karthik\n",
      "her -> Chitra\n",
      "her -> Chitra\n",
      "she -> Chitra\n",
      "her -> Chitra\n",
      "her -> Chitra\n",
      "her -> Chitra\n",
      "her -> Chitra\n",
      "her -> Chitra\n",
      "her -> Chitra\n",
      "She -> Chitra\n",
      "her -> Chitra\n",
      "her -> Chitra\n",
      "she -> Chitra\n",
      "her -> Chitra\n",
      "She -> Chitra\n",
      "her -> Chitra\n",
      "she -> Chitra\n",
      "her -> Chitra\n",
      "her -> Chitra\n",
      "her -> Chitra\n",
      "she -> Chitra\n",
      "her -> Chitra\n",
      "her -> Chitra\n",
      "She -> Chitra\n",
      "she -> Chitra\n",
      "her -> Chitra\n",
      "her -> Chitra\n",
      "her -> Chitra\n",
      "her -> Chitra\n",
      "her -> Chitra\n",
      "her -> Chitra\n",
      "she -> Chitra\n",
      "He -> Karthik's father\n",
      "him -> the man\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 154.01 examples/s]\n",
      "12/15/2023 14:21:37 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 37.36it/s]\n",
      "12/15/2023 14:21:37 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Her -> Joan\n",
      "her -> Joan\n",
      "her -> Joan\n",
      "her -> Joan\n",
      "she -> Joan\n",
      "she -> Joan\n",
      "she -> Joan\n",
      "her -> Joan\n",
      "she -> Joan\n",
      "she -> Joan\n",
      "her -> Joan\n",
      "she -> Joan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 133.06 examples/s]\n",
      "12/15/2023 14:21:37 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 16.84it/s]\n",
      "12/15/2023 14:21:37 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "his -> Rajveer\n",
      "he -> Rajveer\n",
      "he -> Rajveer\n",
      "him -> Abbas\n",
      "his -> Abbas\n",
      "his -> Abbas\n",
      "his -> Abbas\n",
      "his -> Abbas\n",
      "his -> Abbas\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<?, ? examples/s]\n",
      "12/15/2023 14:21:37 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 53.61it/s]\n",
      "12/15/2023 14:21:37 - INFO - \t Tokenize 1 inputs...\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 188.68 examples/s]\n",
      "12/15/2023 14:21:37 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 24.79it/s]\n",
      "12/15/2023 14:21:37 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "her -> Badki\n",
      "she -> Badki\n",
      "her -> Badki\n",
      "she -> Badki\n",
      "her -> Badki\n",
      "her -> Badki\n",
      "her -> Badki\n",
      "her -> Badki\n",
      "her -> Badki\n",
      "her -> Badki\n",
      "her -> Badki\n",
      "her -> Badki\n",
      "her -> Badki\n",
      "her -> Badki\n",
      "she -> Badki\n",
      "she -> Badki\n",
      "them -> the family\n",
      "them -> the family\n",
      "her -> Chutki\n",
      "her -> Chutki\n",
      "his -> Rohan\n",
      "he -> Rohan\n",
      "he -> Rohan\n",
      "he -> Rohan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 126.63 examples/s]\n",
      "12/15/2023 14:21:37 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.19it/s]\n",
      "12/15/2023 14:21:37 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "his -> Anton\n",
      "his -> Anton\n",
      "his -> Anton\n",
      "him -> Anton\n",
      "him -> Anton\n",
      "he -> Anton\n",
      "his -> Anton\n",
      "he -> Anton\n",
      "his -> Anton\n",
      "his -> Anton\n",
      "his -> Anton\n",
      "He -> Anton\n",
      "him -> Anton\n",
      "he -> Anton\n",
      "him -> Anton\n",
      "his -> he,\n",
      "his -> Anton\n",
      "his -> Anton\n",
      "He -> Anton\n",
      "he -> Anton\n",
      "his -> Yegor\n",
      "He -> Yegor\n",
      "he -> Yegor\n",
      "his -> Yegor\n",
      "he -> Yegor\n",
      "his -> Yegor\n",
      "his -> Yegor\n",
      "his -> Yegor\n",
      "him -> Zavulon's\n",
      "her -> Olga's\n",
      "she -> Svetlana\n",
      "she -> Svetlana\n",
      "her -> Svetlana's\n",
      "her -> Svetlana\n",
      "She -> Svetlana\n",
      "her -> Svetlana\n",
      "her -> Svetlana\n",
      "her -> Svetlana\n",
      "her -> Svetlana\n",
      "he -> Zavulon\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 100.11 examples/s]\n",
      "12/15/2023 14:21:38 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 23.05it/s]\n",
      "12/15/2023 14:21:38 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "she -> Sophie\n",
      "her -> Sophie\n",
      "her -> Sophie\n",
      "she -> Sophie\n",
      "her -> Sophie\n",
      "her -> Sophie\n",
      "she -> Sophie\n",
      "her -> Sophie\n",
      "her -> Sophie\n",
      "She -> Sophie\n",
      "she -> Sophie\n",
      "she -> Sophie\n",
      "her -> Sophie\n",
      "she -> Sophie\n",
      "her -> Sophie\n",
      "her -> Sophie\n",
      "her -> Sophie,\n",
      "him -> Stingo\n",
      "his -> Stingo\n",
      "his -> Stingo\n",
      "he -> Nathan\n",
      "his -> Nathan\n",
      "he -> Nathan\n",
      "him -> Nathan\n",
      "he -> Nathan\n",
      "he -> Nathan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 62.65 examples/s]\n",
      "12/15/2023 14:21:38 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.58it/s]\n",
      "12/15/2023 14:21:38 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "she -> Claire\n",
      "her -> Claire\n",
      "her -> Claire\n",
      "She -> Claire\n",
      "she -> Claire\n",
      "her -> Claire\n",
      "she -> Claire\n",
      "her -> Claire\n",
      "She -> Claire\n",
      "She -> Claire\n",
      "she -> Claire\n",
      "She -> Claire\n",
      "her -> Claire\n",
      "Her -> Claire\n",
      "she -> Claire\n",
      "her -> Claire\n",
      "her -> Claire's\n",
      "her -> Claire's\n",
      "she -> Claire's\n",
      "her -> Claire\n",
      "her -> Claire\n",
      "her -> Claire\n",
      "her -> Claire\n",
      "her -> Claire\n",
      "Her -> Claire\n",
      "her -> Claire\n",
      "she -> Claire\n",
      "she -> Claire\n",
      "her -> Claire\n",
      "she -> Claire\n",
      "her -> Claire\n",
      "she -> Claire\n",
      "her -> Claire\n",
      "She -> Claire\n",
      "her -> Claire\n",
      "she -> Claire\n",
      "her -> Claire\n",
      "she -> Claire,\n",
      "her -> Claire\n",
      "her -> Claire\n",
      "her -> Claire\n",
      "she -> Claire\n",
      "he -> Jay\n",
      "him -> Jay\n",
      "him -> Jay\n",
      "him -> Jay\n",
      "he -> Jay\n",
      "he -> Jay\n",
      "he -> Jay\n",
      "he -> Jay\n",
      "his -> Jay\n",
      "him -> Jay\n",
      "He -> Jay\n",
      "his -> Jay\n",
      "He -> Jay\n",
      "his -> Jay\n",
      "his -> Jay\n",
      "he -> Jay's\n",
      "his -> Jay\n",
      "he -> Jay\n",
      "he -> Jay\n",
      "him -> Jay\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 124.75 examples/s]\n",
      "12/15/2023 14:21:38 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 25.16it/s]\n",
      "12/15/2023 14:21:38 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "his -> P. Sukumaran\n",
      "his -> Sukumaran\n",
      "she -> Thara Kurup\n",
      "her -> Thara Kurup\n",
      "he -> Murali's\n",
      "His -> Murali's\n",
      "his -> Murali's\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 148.98 examples/s]\n",
      "12/15/2023 14:21:38 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 30.62it/s]\n",
      "12/15/2023 14:21:38 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "she -> my\n",
      "her -> my\n",
      "she -> my\n",
      "her -> my\n",
      "Her -> my\n",
      "she -> my\n",
      "her -> my\n",
      "she -> my\n",
      "she -> my\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 23.74 examples/s]\n",
      "12/15/2023 14:21:38 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00,  2.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "he -> shiro\n",
      "him -> Shiro\n",
      "He -> Shiro\n",
      "his -> Shiro\n",
      "he -> Shiro\n",
      "He -> Shiro\n",
      "him -> Shiro\n",
      "he -> Shiro\n",
      "him -> Shiro\n",
      "him -> Shiro\n",
      "his -> Shiro\n",
      "He -> Shiro\n",
      "he -> Shiro\n",
      "him -> Shiro\n",
      "him -> Shiro\n",
      "he -> Shiro\n",
      "his -> Shiro\n",
      "his -> Shiro\n",
      "his -> Shiro\n",
      "he -> you\n",
      "he -> you\n",
      "he -> you\n",
      "him -> you\n",
      "he -> you\n",
      "he -> you\n",
      "he -> you\n",
      "he -> you\n",
      "him -> you\n",
      "his -> you\n",
      "him -> you\n",
      "her -> The girl\n",
      "She -> The girl\n",
      "she -> The girl\n",
      "her -> her,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12/15/2023 14:21:39 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Her -> Ocho\n",
      "her -> Ocho\n",
      "she -> Ocho\n",
      "her -> Ocho\n",
      "her -> Ocho\n",
      "her -> Ocho\n",
      "his -> Shiro\n",
      "he -> Shiro\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 74.22 examples/s]\n",
      "12/15/2023 14:21:39 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "his"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "12/15/2023 14:21:39 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -> Swansey\n",
      "his -> Swansey\n",
      "he -> Swansey\n",
      "their -> Both\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 537.04 examples/s]\n",
      "12/15/2023 14:21:39 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 10.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "his -> Stowe\n",
      "he -> Stowe\n",
      "him -> Stowe\n",
      "his -> Stowe\n",
      "his -> Stowe\n",
      "him -> Stowe\n",
      "he -> Stowe\n",
      "him -> Stowe\n",
      "him -> Stowe\n",
      "his -> Stowe\n",
      "he -> Stowe\n",
      "he -> Stowe\n",
      "he -> Stowe\n",
      "his -> Stowe\n",
      "his -> Stowe\n",
      "He -> Stowe\n",
      "his -> Stowe\n",
      "He -> Stowe\n",
      "his -> Stowe\n",
      "his -> Stowe\n",
      "his -> Stowe\n",
      "He -> Stowe\n",
      "his -> Stowe\n",
      "his -> Stowe\n",
      "he -> Stowe\n",
      "his -> Stowe\n",
      "his -> Stowe\n",
      "he -> Stowe\n",
      "his -> Stowe\n",
      "his -> Callahan\n",
      "she -> Valerie\n",
      "she -> Valerie\n",
      "she -> Valerie\n",
      "she -> Valerie\n",
      "his -> Jimmy\n",
      "him -> Jimmy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12/15/2023 14:21:39 - INFO - \t Tokenize 1 inputs...\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 53.20 examples/s]\n",
      "12/15/2023 14:21:39 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00,  9.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "him -> Frank,\n",
      "him -> Frank\n",
      "his -> Frank\n",
      "him -> Frank\n",
      "he -> Frank\n",
      "his -> Frank\n",
      "he -> Frank\n",
      "he -> Frank\n",
      "He -> Frank\n",
      "his -> Frank\n",
      "his -> Frank\n",
      "his -> Frank\n",
      "his -> Frank\n",
      "his -> Frank\n",
      "his -> Frank\n",
      "his -> Frank\n",
      "her -> Susan's\n",
      "her -> Susan's\n",
      "her -> Susan's\n",
      "she -> Susan's\n",
      "she -> Susan\n",
      "her -> Susan\n",
      "her -> Susan\n",
      "She -> Susan\n",
      "she -> Susan's\n",
      "she -> Susan's\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12/15/2023 14:21:39 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "him -> Duane\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<?, ? examples/s]\n",
      "12/15/2023 14:21:39 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 24.17it/s]\n",
      "12/15/2023 14:21:39 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "his -> Sakthivel Gounder\n",
      "He -> Sakthivel Gounder\n",
      "his -> Sakthivel Gounder\n",
      "his -> Sakthivel Gounder\n",
      "his -> Chinnarasu\n",
      "he -> Chinnarasu\n",
      "his -> Chinnarasu\n",
      "her -> Nandini\n",
      "she -> Nandini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 121.73 examples/s]\n",
      "12/15/2023 14:21:40 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 60.08it/s]\n",
      "12/15/2023 14:21:40 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "her -> Rebecca's\n",
      "Her -> Rebecca\n",
      "her -> Rebecca\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 69.31 examples/s]\n",
      "12/15/2023 14:21:40 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 22.15it/s]\n",
      "12/15/2023 14:21:40 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "she -> her,\n",
      "her -> her,\n",
      "her -> her,\n",
      "her -> her,\n",
      "She -> Maki\n",
      "him -> Near\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 125.15 examples/s]\n",
      "12/15/2023 14:21:40 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.43it/s]\n",
      "12/15/2023 14:21:40 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "his -> Ivan\n",
      "his -> Ivan\n",
      "his -> Ivan\n",
      "his -> Ivan\n",
      "he -> Ivan\n",
      "he -> Ivan\n",
      "He -> Ivan\n",
      "his -> Ivan\n",
      "him -> Ivan\n",
      "his -> Ivan\n",
      "his -> Ivan\n",
      "He -> Ivan\n",
      "he -> Ivan\n",
      "his -> Ivan\n",
      "he -> Ivan's\n",
      "his -> Ivan's\n",
      "he -> Ivan's\n",
      "his -> Ivan\n",
      "He -> Ivan\n",
      "him -> Ivan\n",
      "he -> Ivan\n",
      "his -> Ivan\n",
      "his -> Ivan\n",
      "He -> Ivan\n",
      "him -> Ivan\n",
      "his -> Ivan\n",
      "him -> Ivan\n",
      "he -> Ivan\n",
      "his -> Ivan\n",
      "his -> Ivan\n",
      "He -> Ivan\n",
      "he -> Ivan\n",
      "he -> Ivan\n",
      "he -> Ivan\n",
      "he -> Ivan\n",
      "her -> Maria's\n",
      "her -> Maria\n",
      "she -> Maria\n",
      "her -> Maria\n",
      "her -> Maria,\n",
      "she -> Maria,\n",
      "She -> Maria\n",
      "she -> her,\n",
      "her -> her,\n",
      "she -> Maria\n",
      "her -> Maria\n",
      "her -> Maria\n",
      "she -> Maria,\n",
      "her -> her,\n",
      "his -> Al\n",
      "he -> Al\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 121.01 examples/s]\n",
      "12/15/2023 14:21:40 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 62.44it/s]\n",
      "12/15/2023 14:21:40 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "his -> Pepito\n",
      "he -> Pepito\n",
      "he -> Pepito\n",
      "his -> Pepito\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 60.99 examples/s]\n",
      "12/15/2023 14:21:40 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 26.83it/s]\n",
      "12/15/2023 14:21:40 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "his -> Martin\n",
      "his -> Martin\n",
      "his -> Martin\n",
      "he -> Martin\n",
      "him -> Martin\n",
      "his -> Martin\n",
      "his -> Stannard\n",
      "he -> Stannard\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 147.99 examples/s]\n",
      "12/15/2023 14:21:40 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 15.04it/s]\n",
      "12/15/2023 14:21:40 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "his -> The President\n",
      "his -> The President\n",
      "he -> Omer's\n",
      "He -> Omer's\n",
      "he -> Omer's\n",
      "his -> Omer's\n",
      "he -> Omer's\n",
      "He -> Omer's\n",
      "his -> Omer's\n",
      "his -> Omer's\n",
      "his -> Omer\n",
      "He -> Omer\n",
      "his -> Omer\n",
      "his -> Omer\n",
      "he -> Omer\n",
      "she -> Sally\n",
      "she -> Sally\n",
      "he -> William\n",
      "their -> people\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<?, ? examples/s]\n",
      "12/15/2023 14:21:40 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 30.76it/s]\n",
      "12/15/2023 14:21:40 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "his -> Muthu\n",
      "his -> Muthu\n",
      "he -> Muthu\n",
      "he -> Muthu\n",
      "his -> Muthu\n",
      "he -> Veerasamy\n",
      "he -> Veerasamy\n",
      "his -> Veerasamy\n",
      "his -> Veerasamy\n",
      "he -> Kumar\n",
      "him -> Kumar\n",
      "she -> Meena\n",
      "her -> Meena\n",
      "her -> Meena\n",
      "her -> Meena\n",
      "her -> Meena\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 124.78 examples/s]\n",
      "12/15/2023 14:21:40 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 23.18it/s]\n",
      "12/15/2023 14:21:40 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "they -> people\n",
      "they -> people\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 737.27 examples/s]\n",
      "12/15/2023 14:21:40 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 65.21it/s]\n",
      "12/15/2023 14:21:40 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "her -> Rose\n",
      "her -> Rose\n",
      "his -> Anthony\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 115.54 examples/s]\n",
      "12/15/2023 14:21:40 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 30.03it/s]\n",
      "12/15/2023 14:21:40 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "he -> Johnny\n",
      "he -> Johnny\n",
      "He -> Johnny\n",
      "him -> Johnny\n",
      "he -> Johnny\n",
      "His -> Johnny\n",
      "his -> Johnny\n",
      "His -> Johnny\n",
      "him -> Johnny\n",
      "he -> Johnny\n",
      "his -> Johnny\n",
      "his -> Johnny\n",
      "he -> Johnny\n",
      "he -> Johnny\n",
      "his -> Johnny\n",
      "him -> Anthony\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 86.15 examples/s]\n",
      "12/15/2023 14:21:41 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 54.01it/s]\n",
      "12/15/2023 14:21:41 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "he -> Shyam\n",
      "his -> Deepak\n",
      "him -> Deepak\n",
      "his -> Deepak's\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 93.09 examples/s]\n",
      "12/15/2023 14:21:41 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 18.18it/s]\n",
      "12/15/2023 14:21:41 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "his -> The Wolf\n",
      "him -> The Wolf\n",
      "his -> the Wolf\n",
      "he -> the Wolf\n",
      "he -> The Wolf\n",
      "He -> The Wolf\n",
      "his -> The Wolf\n",
      "He -> The Wolf\n",
      "his -> The Wolf\n",
      "his -> The Wolf\n",
      "him -> the Wolf\n",
      "he -> the Wolf\n",
      "his -> I\n",
      "he -> I\n",
      "he -> I\n",
      "his -> I\n",
      "he -> I\n",
      "his -> I\n",
      "his -> the Wolf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 371.67 examples/s]\n",
      "12/15/2023 14:21:41 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 38.39it/s]\n",
      "12/15/2023 14:21:41 - INFO - \t Tokenize 1 inputs...\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 115.06 examples/s]\n",
      "12/15/2023 14:21:41 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 111.38it/s]\n",
      "12/15/2023 14:21:41 - INFO - \t Tokenize 1 inputs...\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 153.47 examples/s]\n",
      "12/15/2023 14:21:41 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 25.84it/s]\n",
      "12/15/2023 14:21:41 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "he -> Vishwanathan\n",
      "him -> Vishwanathan\n",
      "his -> Vishwanathan\n",
      "his -> Vishwanathan\n",
      "his -> Vishwanathan\n",
      "He -> Vishwanathan\n",
      "his -> Vishwanathan\n",
      "his -> Vishwanathan\n",
      "His -> Vishwanathan\n",
      "him -> Vishwanathan\n",
      "his -> Vishwanathan\n",
      "his -> Vishwanathan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 93.80 examples/s]\n",
      "12/15/2023 14:21:41 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 59.93it/s]\n",
      "12/15/2023 14:21:41 - INFO - \t Tokenize 1 inputs...\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 151.82 examples/s]\n",
      "12/15/2023 14:21:41 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 32.31it/s]\n",
      "12/15/2023 14:21:41 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "his -> Vinod\n",
      "He -> Vinod\n",
      "his -> Vinod\n",
      "his -> Santhosh\n",
      "he -> Mahesh\n",
      "him -> Mahesh\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 105.61 examples/s]\n",
      "12/15/2023 14:21:41 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 28.80it/s]\n",
      "12/15/2023 14:21:41 - INFO - \t Tokenize 1 inputs...\n",
      "Map: 100%|██████████| 1/1 [00:00<?, ? examples/s]\n",
      "12/15/2023 14:21:41 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 60.08it/s]\n",
      "12/15/2023 14:21:41 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "his -> Carlos\n",
      "his -> Carlos\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 183.40 examples/s]\n",
      "12/15/2023 14:21:41 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 59.77it/s]\n",
      "12/15/2023 14:21:41 - INFO - \t Tokenize 1 inputs...\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 134.24 examples/s]\n",
      "12/15/2023 14:21:41 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 62.34it/s]\n",
      "12/15/2023 14:21:41 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "his -> Jerry Falk\n",
      "him -> Jerry Falk\n",
      "his -> Jerry\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 59.91 examples/s]\n",
      "12/15/2023 14:21:41 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.46it/s]\n",
      "12/15/2023 14:21:42 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "him -> Jimmy\n",
      "he -> Jimmy\n",
      "him -> Jimmy\n",
      "he -> Jimmy\n",
      "him -> Jimmy\n",
      "he -> Jimmy\n",
      "his -> Peter\n",
      "he -> Peter\n",
      "he -> Peter\n",
      "his -> Peter\n",
      "his -> Peter\n",
      "him -> Peter\n",
      "he -> Peter\n",
      "his -> Peter\n",
      "his -> Peter\n",
      "his -> Peter's\n",
      "He -> Peter\n",
      "he -> Peter\n",
      "he -> Peter\n",
      "he -> Peter\n",
      "he -> Peter\n",
      "his -> Peter\n",
      "they -> the gang\n",
      "they -> the gang\n",
      "their -> the gang\n",
      "their -> the gang\n",
      "she -> Bonny\n",
      "She -> Bonny\n",
      "she -> Bonny\n",
      "her -> Bonny\n",
      "he -> Bonny\n",
      "he -> Hook\n",
      "his -> Hook\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 794.53 examples/s]\n",
      "12/15/2023 14:21:42 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 44.11it/s]\n",
      "12/15/2023 14:21:42 - INFO - \t Tokenize 1 inputs...\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 1078.23 examples/s]\n",
      "12/15/2023 14:21:42 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 38.86it/s]\n",
      "12/15/2023 14:21:42 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "his -> Buckwheat\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 68.27 examples/s]\n",
      "12/15/2023 14:21:42 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.40it/s]\n",
      "12/15/2023 14:21:42 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "His -> Ross\n",
      "him -> Ross\n",
      "he -> Ross\n",
      "him -> Ross\n",
      "his -> Ross\n",
      "his -> Ross\n",
      "He -> Ross\n",
      "he -> Ross\n",
      "he -> Ross\n",
      "he -> Ross\n",
      "his -> Ross\n",
      "his -> Hanley\n",
      "he -> Hanley\n",
      "He -> Hanley\n",
      "him -> Stacey\n",
      "his -> Stacey\n",
      "He -> Stacey\n",
      "him -> Stacey\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 180.48 examples/s]\n",
      "12/15/2023 14:21:42 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 44.17it/s]\n",
      "12/15/2023 14:21:42 - INFO - \t Tokenize 1 inputs...\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 75.53 examples/s]\n",
      "12/15/2023 14:21:42 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.73it/s]\n",
      "12/15/2023 14:21:42 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "her -> Viola\n",
      "She -> Viola\n",
      "she -> Viola\n",
      "He -> Orsino\n",
      "his -> Orsino\n",
      "her -> Olivia\n",
      "her -> Olivia\n",
      "she -> her,\n",
      "him -> Sebastian\n",
      "him -> Sebastian\n",
      "he -> Sebastian\n",
      "his -> Sebastian\n",
      "he -> Sebastian\n",
      "her -> Sebastian\n",
      "his -> Feste\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 79.52 examples/s]\n",
      "12/15/2023 14:21:42 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "he -> Snyder\n",
      "his -> Snyder\n",
      "him -> Snyder\n",
      "He -> Snyder\n",
      "he -> Snyder\n",
      "him -> Snyder\n",
      "his -> Snyder\n",
      "he -> Snyder\n",
      "he -> Snyder\n",
      "his -> Snyder\n",
      "He -> McBride\n",
      "she -> Joyce\n",
      "he -> Joyce\n",
      "he -> Richardson\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12/15/2023 14:21:42 - INFO - \t Tokenize 1 inputs...\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 284.09 examples/s]\n",
      "12/15/2023 14:21:42 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 62.33it/s]\n",
      "12/15/2023 14:21:42 - INFO - \t Tokenize 1 inputs...\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 110.90 examples/s]\n",
      "12/15/2023 14:21:43 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.00it/s]\n",
      "12/15/2023 14:21:43 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "him -> Roy\n",
      "him -> Roy\n",
      "he -> Roy\n",
      "him -> Roy\n",
      "his -> Roy\n",
      "him -> Roy\n",
      "she -> Rose\n",
      "she -> Rose\n",
      "he -> Graham\n",
      "his -> Graham\n",
      "he -> Graham\n",
      "he -> Graham\n",
      "he -> Graham\n",
      "his -> Graham\n",
      "he -> Graham\n",
      "he -> Graham\n",
      "him -> Graham\n",
      "his -> Graham\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 91.75 examples/s]\n",
      "12/15/2023 14:21:43 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 16.91it/s]\n",
      "12/15/2023 14:21:43 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "his -> Don Carlos\n",
      "his -> Don Carlos\n",
      "his -> Carlos,\n",
      "his -> Carlos\n",
      "him -> Carlos\n",
      "his -> Carlos\n",
      "his -> Carlos\n",
      "his -> Carlitos\n",
      "he -> Carlitos\n",
      "his -> Carlitos\n",
      "his -> the boy\n",
      "his -> Carlitos\n",
      "him -> Julio\n",
      "his -> Julio\n",
      "his -> Julio\n",
      "she -> Rosario\n",
      "she -> Rosario\n",
      "she -> Rosario\n",
      "she -> Rosario\n",
      "she -> Rosario\n",
      "her -> Rosario\n",
      "her -> Rosario\n",
      "She -> Rosario\n",
      "she -> Rosario\n",
      "her -> Rosario\n",
      "he -> Miguel\n",
      "his -> Miguel's\n",
      "he -> Miguel's\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 161.42 examples/s]\n",
      "12/15/2023 14:21:43 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 35.85it/s]\n",
      "12/15/2023 14:21:43 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "he -> Ben\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 145.40 examples/s]\n",
      "12/15/2023 14:21:43 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 59.99it/s]\n",
      "12/15/2023 14:21:43 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "He -> Andrew\n",
      "he -> Andrew\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 92.87 examples/s]\n",
      "12/15/2023 14:21:43 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 65.95it/s]\n",
      "12/15/2023 14:21:43 - INFO - \t Tokenize 1 inputs...\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 142.80 examples/s]\n",
      "12/15/2023 14:21:43 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 92.32it/s]\n",
      "12/15/2023 14:21:43 - INFO - \t Tokenize 1 inputs...\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 182.93 examples/s]\n",
      "12/15/2023 14:21:43 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 87.16it/s]\n",
      "12/15/2023 14:21:43 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "her -> Jane\n",
      "her -> Jane\n",
      "her -> Jane\n",
      "her -> Jane\n",
      "she -> her,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 98.50 examples/s]\n",
      "12/15/2023 14:21:43 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00,  9.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "He -> Raju\n",
      "he -> Raju\n",
      "He -> Raju\n",
      "him -> Prem\n",
      "he -> Prem\n",
      "him -> Prem's\n",
      "him -> Prem\n",
      "his -> Prem\n",
      "he -> Prem\n",
      "his -> Prem\n",
      "her -> Neetu\n",
      "her -> Neetu\n",
      "he -> Raju\n",
      "his -> Raju\n",
      "his -> Raju\n",
      "he -> Raju\n",
      "him -> Raju\n",
      "he -> Raju\n",
      "he -> Raju\n",
      "his -> Raju\n",
      "he -> Raju\n",
      "him -> Raju\n",
      "he -> Raju\n",
      "his -> Raju\n",
      "he -> Raju\n",
      "his -> Raju\n",
      "him -> Raju\n",
      "his -> Raju\n",
      "he -> Raju\n",
      "he -> Raju\n",
      "him -> Raju\n",
      "he -> Raju\n",
      "he -> Raju\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12/15/2023 14:21:43 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "her -> the Queen\n",
      "she -> the Queen\n",
      "her -> Queen\n",
      "She -> Queen\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 90.76 examples/s]\n",
      "12/15/2023 14:21:43 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.64it/s]\n",
      "12/15/2023 14:21:44 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "she -> Jordan\n",
      "her -> Jordan\n",
      "her -> Jordan\n",
      "her -> Jordan\n",
      "Her -> Jordan\n",
      "her -> Jordan\n",
      "she -> Jordan\n",
      "her -> Jordan\n",
      "her -> Jordan\n",
      "her -> Jordan\n",
      "her -> Jordan\n",
      "she -> Jordan\n",
      "her -> Jordan\n",
      "her -> Jordan\n",
      "her -> Jordan\n",
      "he -> Hunter\n",
      "him -> David\n",
      "he -> David\n",
      "his -> David\n",
      "she -> Paulina\n",
      "She -> Paulina\n",
      "her -> Paulina\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 51.69 examples/s]\n",
      "12/15/2023 14:21:44 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 16.78it/s]\n",
      "12/15/2023 14:21:44 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "her -> Radha\n",
      "her -> Sukhilala\n",
      "she -> Sukhilala\n",
      "his -> Sukhilala\n",
      "her -> Sukhilala\n",
      "her -> Sukhilala\n",
      "He -> Shamu\n",
      "his -> Shamu\n",
      "he -> Shamu\n",
      "his -> Shamu\n",
      "he -> Shamu\n",
      "he -> Birju\n",
      "his -> Birju\n",
      "his -> Birju's\n",
      "He -> Birju's\n",
      "his -> Birju\n",
      "He -> Birju\n",
      "his -> Birju\n",
      "he -> Ramu\n",
      "his -> Ramu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 135.40 examples/s]\n",
      "12/15/2023 14:21:44 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.10it/s]\n",
      "12/15/2023 14:21:44 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "her -> Dr. Allen\n",
      "she -> Dr. Allen\n",
      "her -> Dr. Allen\n",
      "She -> Dr. Allen\n",
      "her -> Dr. Allen\n",
      "she -> Dr. Allen\n",
      "her -> Dr. Allen\n",
      "She -> Dr. Allen\n",
      "her -> Dr. Allen\n",
      "she -> Dr. Allen\n",
      "she -> Dr. Allen\n",
      "she -> her,\n",
      "her -> her,\n",
      "she -> Dr. Allen\n",
      "She -> Dr. Allen\n",
      "she -> Dr. Allen\n",
      "she -> Dr. Allen\n",
      "her -> Dr. Allen\n",
      "He -> Ray\n",
      "he -> Ray\n",
      "his -> Ray\n",
      "his -> Ray\n",
      "he -> Ray's\n",
      "He -> Tom,\n",
      "He -> Tom\n",
      "he -> Tom\n",
      "him -> Tom\n",
      "him -> The monster\n",
      "him -> The monster\n",
      "him -> The monster\n",
      "him -> the monster\n",
      "he -> the monster\n",
      "She -> The monster\n",
      "him -> The monster\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 43.61 examples/s]\n",
      "12/15/2023 14:21:44 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 22.57it/s]\n",
      "12/15/2023 14:21:44 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "he -> Neruda\n",
      "his -> Neruda\n",
      "his -> Neruda\n",
      "he -> Neruda\n",
      "his -> Neruda\n",
      "he -> Neruda\n",
      "his -> Mario\n",
      "he -> Mario\n",
      "He -> Mario\n",
      "his -> Mario\n",
      "He -> Mario\n",
      "he -> Mario\n",
      "his -> Mario\n",
      "his -> Mario\n",
      "he -> Mario\n",
      "his -> Mario\n",
      "he -> Mario\n",
      "he -> Mario\n",
      "he -> Mario\n",
      "his -> Mario\n",
      "he -> Mario\n",
      "her -> Beatrice\n",
      "She -> her,\n",
      "his -> The priest\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 73.60 examples/s]\n",
      "12/15/2023 14:21:44 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 36.93it/s]\n",
      "12/15/2023 14:21:44 - INFO - \t Tokenize 1 inputs...\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 114.91 examples/s]\n",
      "12/15/2023 14:21:44 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 60.73it/s]\n",
      "12/15/2023 14:21:44 - INFO - \t Tokenize 1 inputs...\n",
      "Map: 100%|██████████| 1/1 [00:00<?, ? examples/s]\n",
      "12/15/2023 14:21:44 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 56.42it/s]\n",
      "12/15/2023 14:21:44 - INFO - \t Tokenize 1 inputs...\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 152.59 examples/s]\n",
      "12/15/2023 14:21:44 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 72.02it/s]\n",
      "12/15/2023 14:21:44 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "her -> Love\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<?, ? examples/s]\n",
      "12/15/2023 14:21:44 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 40.43it/s]\n",
      "12/15/2023 14:21:44 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "him -> Hawk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 111.45 examples/s]\n",
      "12/15/2023 14:21:44 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "He -> Zorg\n",
      "He -> Zorg\n",
      "him -> Zorg\n",
      "he -> Zorg\n",
      "his -> Zorg\n",
      "his -> Zorg\n",
      "he -> Zorg\n",
      "his -> Zorg\n",
      "his -> Zorg\n",
      "he -> Zorg\n",
      "he -> Zorg\n",
      "his -> Zorg\n",
      "his -> Zorg\n",
      "his -> Zorg\n",
      "he -> Zorg\n",
      "his -> Zorg\n",
      "him -> Zorg\n",
      "his -> Zorg\n",
      "he -> Zorg\n",
      "he -> Zorg\n",
      "he -> Zorg\n",
      "He -> Zorg\n",
      "His -> Zorg\n",
      "him -> Zorg\n",
      "He -> Zorg\n",
      "his -> Zorg\n",
      "He -> Zorg\n",
      "his -> Zorg\n",
      "He -> Zorg\n",
      "he -> Zorg\n",
      "his -> Zorg\n",
      "him -> Zorg\n",
      "his -> Zorg\n",
      "he -> Zorg\n",
      "She -> Betty\n",
      "her -> Betty\n",
      "she -> Betty\n",
      "her -> Betty\n",
      "She -> Betty\n",
      "she -> Betty\n",
      "she -> Betty\n",
      "She -> Betty\n",
      "she -> Betty\n",
      "her -> Betty\n",
      "her -> Betty\n",
      "her -> Betty's\n",
      "she -> Betty's\n",
      "her -> Betty\n",
      "she -> Betty\n",
      "she -> Betty\n",
      "her -> Betty,\n",
      "her -> Betty,\n",
      "Her -> Betty,\n",
      "her -> Betty\n",
      "her -> Betty\n",
      "She -> Betty\n",
      "she -> Betty\n",
      "her -> Betty\n",
      "her -> Betty\n",
      "her -> Betty\n",
      "her -> Betty\n",
      "her -> Betty\n",
      "her -> Betty\n",
      "She -> Betty's\n",
      "her -> Betty's\n",
      "her -> Betty's\n",
      "her -> Betty's\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12/15/2023 14:21:45 - INFO - \t Tokenize 1 inputs...\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 160.12 examples/s]\n",
      "12/15/2023 14:21:45 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 49.19it/s]\n",
      "12/15/2023 14:21:45 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "He -> Hargan\n",
      "his -> Hargan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 153.40 examples/s]\n",
      "12/15/2023 14:21:45 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 47.46it/s]\n",
      "12/15/2023 14:21:45 - INFO - \t Tokenize 1 inputs...\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 95.56 examples/s]\n",
      "12/15/2023 14:21:45 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 49.41it/s]\n",
      "12/15/2023 14:21:45 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "he -> Johnny\n",
      "his -> Wayne\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 148.83 examples/s]\n",
      "12/15/2023 14:21:45 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 42.42it/s]\n",
      "12/15/2023 14:21:45 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "her -> Hannah\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 59.24 examples/s]\n",
      "12/15/2023 14:21:45 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.44it/s]\n",
      "12/15/2023 14:21:45 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "his -> Mithun\n",
      "he -> Mithun\n",
      "his -> Mithun\n",
      "his -> Mithun\n",
      "He -> Mithun\n",
      "his -> Mithun\n",
      "He -> Mithun\n",
      "He -> Mithun\n",
      "his -> Mithun\n",
      "He -> Mithun\n",
      "his -> Mithun\n",
      "he -> Mithun\n",
      "he -> Mithun\n",
      "he -> Mithun\n",
      "He -> Mithun\n",
      "he -> Mithun\n",
      "his -> Mithun\n",
      "he -> Mithun\n",
      "His -> Mithun\n",
      "he -> Mithun\n",
      "his -> Mithun\n",
      "he -> Mithun\n",
      "he -> Mithun\n",
      "he -> Mithun\n",
      "he -> Mithun\n",
      "he -> one\n",
      "he -> one\n",
      "her -> Rati\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 38.28 examples/s]\n",
      "12/15/2023 14:21:45 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00,  4.52it/s]\n",
      "12/15/2023 14:21:46 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "her -> Jessica\n",
      "she -> Jessica\n",
      "her -> Jessica\n",
      "she -> Jessica\n",
      "she -> Jessica\n",
      "her -> Jessica\n",
      "she -> Jessica\n",
      "she -> Jessica\n",
      "she -> Jessica\n",
      "she -> Jessica\n",
      "her -> Jessica\n",
      "she -> Jessica\n",
      "he -> Valdemar\n",
      "him -> Valdemar\n",
      "he -> Valdemar\n",
      "he -> Valdemar\n",
      "him -> Valdemar\n",
      "him -> Valdemar\n",
      "his -> Valdemar\n",
      "him -> Valdemar\n",
      "his -> Valdemar\n",
      "he -> Robert\n",
      "he -> Robert,\n",
      "him -> Robert,\n",
      "him -> Robert\n",
      "him -> Robert\n",
      "him -> Robert\n",
      "his -> Robert\n",
      "he -> Robert\n",
      "his -> Robert\n",
      "he -> Robert\n",
      "his -> Robert\n",
      "him -> Robert\n",
      "his -> Robert\n",
      "him -> Robert,\n",
      "his -> Robert,\n",
      "him -> Grogan\n",
      "he -> Rod\n",
      "he -> my\n",
      "his -> Rod\n",
      "his -> Rod\n",
      "he -> Rod\n",
      "he -> Rod\n",
      "him -> Rod\n",
      "his -> Rod\n",
      "his -> Rod\n",
      "he -> Rod\n",
      "he -> Rod\n",
      "his -> Rod\n",
      "him -> Rod\n",
      "his -> Rod\n",
      "he -> Rod\n",
      "his -> Rod\n",
      "his -> Rod\n",
      "he -> Rod\n",
      "his -> Rod\n",
      "his -> Rod\n",
      "his -> Rod\n",
      "his -> Rod\n",
      "his -> Rod\n",
      "his -> Rod\n",
      "he -> Rod\n",
      "his -> Rod\n",
      "she -> Annabel\n",
      "her -> Annabel\n",
      "her -> Annabel\n",
      "she -> Annabel\n",
      "her -> Annabel\n",
      "her -> Annabel\n",
      "her -> Annabel\n",
      "her -> Annabel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 58.98 examples/s]\n",
      "12/15/2023 14:21:46 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.23it/s]\n",
      "12/15/2023 14:21:46 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "her -> Camille\n",
      "her -> Camille,\n",
      "her -> Camille,\n",
      "her -> Camille,\n",
      "her -> Camille,\n",
      "her -> Camille,\n",
      "her -> Camille\n",
      "her -> Camille\n",
      "her -> Camille\n",
      "her -> Camille\n",
      "She -> Camille\n",
      "her -> Camille\n",
      "she -> Camille\n",
      "her -> Camille\n",
      "she -> Camille\n",
      "she -> Camille\n",
      "his -> Jean-Baptiste\n",
      "his -> Jean-Baptiste\n",
      "he -> Jean-Baptiste\n",
      "he -> Jean-Baptiste\n",
      "his -> Jean-Baptiste\n",
      "his -> Jean-Baptiste\n",
      "him -> Jean-Baptiste\n",
      "him -> Jean-Baptiste\n",
      "they -> the family\n",
      "them -> the family\n",
      "they -> the family\n",
      "they -> the family\n",
      "He -> Guy\n",
      "his -> Étienne\n",
      "his -> Étienne\n",
      "he -> Étienne\n",
      "He -> Étienne\n",
      "He -> Étienne\n",
      "his -> Étienne\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 221.35 examples/s]\n",
      "12/15/2023 14:21:46 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 49.20it/s]\n",
      "12/15/2023 14:21:46 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "he -> Joe Johnson\n",
      "he -> Joe Johnson\n",
      "his -> Joe Johnson\n",
      "he -> Joe Johnson\n",
      "He -> Joe Johnson\n",
      "his -> Joe\n",
      "him -> Joe\n",
      "his -> Joe\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<?, ? examples/s]\n",
      "12/15/2023 14:21:46 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 36.83it/s]\n",
      "12/15/2023 14:21:46 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "he -> Caesar's\n",
      "he -> Caesar's\n",
      "He -> Caesar's\n",
      "he -> Caesar's\n",
      "his -> Caesar's\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 156.90 examples/s]\n",
      "12/15/2023 14:21:46 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 27.21it/s]\n",
      "12/15/2023 14:21:46 - INFO - \t Tokenize 1 inputs...\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 90.24 examples/s]\n",
      "12/15/2023 14:21:46 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.03it/s]\n",
      "12/15/2023 14:21:46 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "him -> Horton\n",
      "his -> Horton\n",
      "his -> Horton\n",
      "his -> Horton\n",
      "his -> The Mayor\n",
      "his -> JoJo\n",
      "he -> JoJo\n",
      "she -> Jane\n",
      "her -> Jane's\n",
      "she -> Jane's\n",
      "her -> Jane's\n",
      "her -> Jane's\n",
      "she -> Jane,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<?, ? examples/s]\n",
      "12/15/2023 14:21:46 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 59.93it/s]\n",
      "12/15/2023 14:21:46 - INFO - \t Tokenize 1 inputs...\n",
      "Map: 100%|██████████| 1/1 [00:00<?, ? examples/s]\n",
      "12/15/2023 14:21:46 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 54.73it/s]\n",
      "12/15/2023 14:21:46 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "her -> Katka\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 118.28 examples/s]\n",
      "12/15/2023 14:21:46 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 21.98it/s]\n",
      "12/15/2023 14:21:47 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "his -> Baggs\n",
      "his -> Baggs\n",
      "her -> Maggie\n",
      "she -> Maggie\n",
      "His -> Doug\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 149.64 examples/s]\n",
      "12/15/2023 14:21:47 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 44.64it/s]\n",
      "12/15/2023 14:21:47 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "He -> Dan\n",
      "his -> Dan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 100.36 examples/s]\n",
      "12/15/2023 14:21:47 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 59.98it/s]\n",
      "12/15/2023 14:21:47 - INFO - \t Tokenize 1 inputs...\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 103.30 examples/s]\n",
      "12/15/2023 14:21:47 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 10.89it/s]\n",
      "12/15/2023 14:21:47 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "his -> Jon\n",
      "his -> Jon\n",
      "his -> Jon\n",
      "him -> Jon\n",
      "his -> Jon\n",
      "his -> Jon\n",
      "he -> Jon\n",
      "him -> Jon\n",
      "he -> Jon\n",
      "his -> Jon\n",
      "his -> Jon\n",
      "him -> Jon\n",
      "his -> Jon\n",
      "he -> Jon\n",
      "his -> Jon\n",
      "his -> Jon\n",
      "he -> Jon\n",
      "him -> Jon\n",
      "he -> Jon\n",
      "his -> Jon\n",
      "he -> Jon\n",
      "his -> Jon\n",
      "his -> Jon\n",
      "him -> Jon\n",
      "his -> Jon\n",
      "he -> Jon\n",
      "he -> Jon\n",
      "his -> Jon\n",
      "his -> Jon\n",
      "his -> Jon\n",
      "he -> Jon\n",
      "he -> John\n",
      "his -> John\n",
      "him -> Jon\n",
      "he -> Jon\n",
      "his -> Jon\n",
      "he -> Jon\n",
      "he -> Jon\n",
      "her -> Arlene\n",
      "his -> Arlene\n",
      "her -> Arlene\n",
      "they -> the family\n",
      "their -> the family\n",
      "their -> the family\n",
      "she -> Audrey\n",
      "she -> Audrey\n",
      "her -> Audrey\n",
      "she -> Audrey\n",
      "she -> Audrey\n",
      "he -> Harry\n",
      "he -> Harry\n",
      "he -> Harry\n",
      "he -> Harry\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<?, ? examples/s]\n",
      "12/15/2023 14:21:47 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 26.25it/s]\n",
      "12/15/2023 14:21:47 - INFO - \t Tokenize 1 inputs...\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 133.04 examples/s]\n",
      "12/15/2023 14:21:47 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 15.36it/s]\n",
      "12/15/2023 14:21:47 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "his -> Burns\n",
      "he -> Nate\n",
      "he -> Nate\n",
      "he -> Nate\n",
      "he -> Nate\n",
      "he -> Nate\n",
      "her -> Meg\n",
      "her -> Meg\n",
      "she -> Meg\n",
      "he -> Max's\n",
      "he -> Max's\n",
      "he -> Max's\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 124.77 examples/s]\n",
      "12/15/2023 14:21:47 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 55.85it/s]\n",
      "12/15/2023 14:21:47 - INFO - \t Tokenize 1 inputs...\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 59.12 examples/s]\n",
      "12/15/2023 14:21:47 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00,  5.63it/s]\n",
      "12/15/2023 14:21:47 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "her -> a woman\n",
      "her -> a woman\n",
      "She -> a woman\n",
      "she -> a woman\n",
      "her -> a woman\n",
      "she -> a woman\n",
      "her -> a woman\n",
      "she -> a woman\n",
      "she -> a woman\n",
      "Her -> Tiva\n",
      "She -> Tiva\n",
      "she -> Tiva\n",
      "her -> Tiva\n",
      "she -> Tiva\n",
      "her -> Tiva\n",
      "her -> Tiva\n",
      "her -> Tiva\n",
      "her -> Tiva\n",
      "him -> Terr\n",
      "him -> Terr\n",
      "him -> Terr\n",
      "He -> Terr\n",
      "he -> Terr\n",
      "him -> Terr\n",
      "his -> Terr\n",
      "he -> Terr\n",
      "he -> Terr\n",
      "his -> Terr\n",
      "him -> Terr\n",
      "him -> Terr\n",
      "he -> Terr\n",
      "his -> Terr\n",
      "she -> The woman\n",
      "her -> The woman\n",
      "she -> The woman\n",
      "his -> an Om\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 604.11 examples/s]\n",
      "12/15/2023 14:21:47 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 49.13it/s]\n",
      "12/15/2023 14:21:47 - INFO - \t Tokenize 1 inputs...\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 223.83 examples/s]\n",
      "12/15/2023 14:21:48 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 25.37it/s]\n",
      "12/15/2023 14:21:48 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "his -> Willie\n",
      "him -> Willie\n",
      "he -> Willie\n",
      "He -> Willie\n",
      "him -> Willie\n",
      "he -> Willie\n",
      "he -> Willie\n",
      "he -> Willie\n",
      "his -> Willie\n",
      "him -> Willie\n",
      "him -> Willie\n",
      "her -> Lola\n",
      "her -> Lola\n",
      "he -> Cooper\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 124.94 examples/s]\n",
      "12/15/2023 14:21:48 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 56.49it/s]\n",
      "12/15/2023 14:21:48 - INFO - \t Tokenize 1 inputs...\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 62.51 examples/s]\n",
      "12/15/2023 14:21:48 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.01it/s]\n",
      "12/15/2023 14:21:48 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "her -> Min Soo-ah\n",
      "her -> Min Soo-ah\n",
      "her -> Min Soo-ah\n",
      "her -> Min Soo-ah\n",
      "she -> her,\n",
      "her -> her,\n",
      "her -> her,\n",
      "her -> her,\n",
      "she -> her,\n",
      "her -> her,\n",
      "her -> her,\n",
      "her -> her,\n",
      "She -> her,\n",
      "her -> her,\n",
      "her -> her,\n",
      "she -> her,\n",
      "she -> her,\n",
      "her -> her,\n",
      "she -> her,\n",
      "she -> her,\n",
      "her -> her,\n",
      "her -> her,\n",
      "her -> her,\n",
      "she -> her,\n",
      "She -> her,\n",
      "her -> her,\n",
      "she -> her,\n",
      "her -> her,\n",
      "her -> her,\n",
      "She -> her,\n",
      "she -> her,\n",
      "She -> her,\n",
      "her -> her,\n",
      "she -> her,\n",
      "his -> the Detective\n",
      "he -> the Detective\n",
      "him -> The killer\n",
      "him -> The killer\n",
      "her -> Seul-Gi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 74.81 examples/s]\n",
      "12/15/2023 14:21:48 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.73it/s]\n",
      "12/15/2023 14:21:48 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "his -> Neely\n",
      "him -> Barb\n",
      "He -> Ryan\n",
      "he -> Ryan\n",
      "his -> Ryan\n",
      "He -> Ryan\n",
      "his -> Ryan\n",
      "he -> Ryan\n",
      "He -> Ryan\n",
      "him -> Ryan\n",
      "she -> Mom\n",
      "her -> Dottie\n",
      "her -> Dottie\n",
      "her -> Dottie\n",
      "her -> Dottie\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<?, ? examples/s]\n",
      "12/15/2023 14:21:48 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 42.19it/s]\n",
      "12/15/2023 14:21:48 - INFO - \t Tokenize 1 inputs...\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 75.82 examples/s]\n",
      "12/15/2023 14:21:48 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.24it/s]\n",
      "12/15/2023 14:21:48 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "He -> Jago\n",
      "him -> Jago\n",
      "his -> Jago\n",
      "he -> Jago\n",
      "he -> Jago\n",
      "he -> Jago\n",
      "he -> Jago\n",
      "he -> Jago\n",
      "his -> Othello\n",
      "he -> Othello\n",
      "his -> Othello\n",
      "him -> Othello\n",
      "his -> Othello\n",
      "him -> Othello\n",
      "he -> Othello\n",
      "he -> Othello\n",
      "her -> Dessie\n",
      "him -> Roderick\n",
      "he -> Roderick\n",
      "he -> Roderick\n",
      "he -> Roderick\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 41.66 examples/s]\n",
      "12/15/2023 14:21:49 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.64it/s]\n",
      "12/15/2023 14:21:49 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "her -> Lisa\n",
      "she -> Lisa\n",
      "she -> her,\n",
      "her -> Lisa\n",
      "her -> Lisa's\n",
      "his -> Sam\n",
      "his -> Sam\n",
      "his -> Talman\n",
      "him -> Talman\n",
      "he -> Talman\n",
      "him -> Talman\n",
      "he -> Talman\n",
      "He -> Talman\n",
      "he -> Talman\n",
      "his -> Talman\n",
      "he -> Talman\n",
      "he -> Talman\n",
      "him -> Talman\n",
      "he -> Carlino\n",
      "he -> Roat\n",
      "him -> Roat\n",
      "he -> Roat\n",
      "him -> Roat\n",
      "him -> Roat\n",
      "he -> Roat\n",
      "his -> Roat\n",
      "he -> Roat\n",
      "his -> Roat\n",
      "him -> Roat\n",
      "his -> Roat\n",
      "her -> Susy\n",
      "her -> Susy\n",
      "her -> Susy\n",
      "she -> Susy\n",
      "her -> Susy\n",
      "she -> Susy\n",
      "she -> Susy\n",
      "she -> Susy\n",
      "she -> Susy\n",
      "She -> her,\n",
      "she -> her,\n",
      "her -> Susy\n",
      "her -> Susy\n",
      "her -> Susy\n",
      "her -> Susy\n",
      "she -> Susy\n",
      "her -> Susy\n",
      "She -> Susy\n",
      "She -> Susy\n",
      "her -> Susy\n",
      "she -> her,\n",
      "She -> Susy\n",
      "her -> Susy\n",
      "she -> Gloria\n",
      "She -> Gloria\n",
      "her -> Gloria\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 134.38 examples/s]\n",
      "12/15/2023 14:21:49 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 24.17it/s]\n",
      "12/15/2023 14:21:49 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "he -> Majors\n",
      "him -> Majors\n",
      "he -> Majors\n",
      "his -> Majors\n",
      "his -> Majors\n",
      "his -> Majors\n",
      "his -> Majors\n",
      "he -> Majors\n",
      "him -> Cobbs\n",
      "she -> Gloria,\n",
      "She -> Gloria,\n",
      "he -> Devon\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 106.57 examples/s]\n",
      "12/15/2023 14:21:49 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 16.37it/s]\n",
      "12/15/2023 14:21:49 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "her -> Henriette\n",
      "her -> Henriette\n",
      "She -> Henriette\n",
      "she -> Henriette\n",
      "her -> Henriette\n",
      "her -> Henriette\n",
      "her -> Henriette\n",
      "she -> Henriette\n",
      "she -> Henriette\n",
      "her -> Henriette\n",
      "her -> Henriette\n",
      "her -> Henriette\n",
      "she -> Louise\n",
      "her -> Louise\n",
      "her -> Louise\n",
      "she -> Louise\n",
      "he -> Danton\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 62.11 examples/s]\n",
      "12/15/2023 14:21:49 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00,  5.82it/s]\n",
      "12/15/2023 14:21:49 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "He -> The man\n",
      "his -> The man\n",
      "his -> The man\n",
      "their -> both\n",
      "their -> both\n",
      "they -> both\n",
      "his -> Agent Vinod\n",
      "him -> Agent Vinod\n",
      "He -> Vinod\n",
      "him -> Vinod\n",
      "him -> Vinod\n",
      "he -> Vinod\n",
      "he -> Vinod\n",
      "he -> Vinod\n",
      "he -> Vinod\n",
      "He -> Vinod\n",
      "He -> Vinod\n",
      "He -> Vinod\n",
      "he -> Vinod\n",
      "him -> Agent Vinod\n",
      "He -> Vinod\n",
      "his -> Vinod\n",
      "he -> Vinod\n",
      "him -> Vinod\n",
      "his -> Vinod\n",
      "his -> Rajan\n",
      "him -> Kazan\n",
      "her -> Ruby\n",
      "his -> Iram\n",
      "she -> Iram\n",
      "his -> The Colonel\n",
      "him -> Colonel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 108.76 examples/s]\n",
      "12/15/2023 14:21:49 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 47.06it/s]\n",
      "12/15/2023 14:21:49 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "he -> Karan\n",
      "her -> Karishma\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 166.14 examples/s]\n",
      "12/15/2023 14:21:50 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.76it/s]\n",
      "12/15/2023 14:21:50 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "he -> Seb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 124.99 examples/s]\n",
      "12/15/2023 14:21:50 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 60.97it/s]\n",
      "12/15/2023 14:21:50 - INFO - \t Tokenize 1 inputs...\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 39.47 examples/s]\n",
      "12/15/2023 14:21:50 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00,  4.87it/s]\n",
      "12/15/2023 14:21:50 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "his -> Zack\n",
      "his -> Zack\n",
      "his -> Zack\n",
      "he -> Zack\n",
      "he -> Zack\n",
      "he -> Zack\n",
      "his -> Zack\n",
      "he -> Zack\n",
      "he -> Zack\n",
      "him -> Zack\n",
      "he -> Zack\n",
      "he -> Zack\n",
      "his -> Zack\n",
      "him -> Zack\n",
      "him -> Zack\n",
      "his -> Zack\n",
      "her -> Kelly\n",
      "she -> Kelly\n",
      "she -> Kelly's\n",
      "she -> Kelly\n",
      "her -> Kelly\n",
      "her -> Kelly's\n",
      "he -> Slater\n",
      "his -> Screech\n",
      "him -> Screech\n",
      "him -> Screech\n",
      "his -> Screech\n",
      "they -> the gang\n",
      "their -> the gang\n",
      "them -> the gang\n",
      "them -> the gang\n",
      "he -> Kurt\n",
      "he -> Kurt\n",
      "he -> Kurt\n",
      "her -> Carla\n",
      "she -> Carla\n",
      "his -> Bert\n",
      "she -> Diana\n",
      "him -> Freddy\n",
      "he -> Freddy\n",
      "his -> Freddy\n",
      "his -> Freddy\n",
      "she -> Jessie Spano\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 72.54 examples/s]\n",
      "12/15/2023 14:21:50 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00,  9.83it/s]\n",
      "12/15/2023 14:21:50 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "he -> Billa\n",
      "his -> Billa\n",
      "He -> Billa\n",
      "his -> Billa\n",
      "his -> Billa\n",
      "he -> Billa\n",
      "he -> Billa\n",
      "He -> Billa\n",
      "He -> Billa\n",
      "his -> Billa\n",
      "his -> Billa\n",
      "he -> Billa\n",
      "him -> Billa\n",
      "his -> Billa\n",
      "he -> Billa\n",
      "his -> Billa\n",
      "he -> Billa\n",
      "him -> Billa\n",
      "he -> Billa\n",
      "he -> Billa\n",
      "him -> Billa\n",
      "his -> Billa\n",
      "him -> Billa\n",
      "his -> Billa\n",
      "he -> Billa\n",
      "he -> Billa\n",
      "He -> Billa\n",
      "his -> Billa\n",
      "he -> Billa\n",
      "he -> Billa\n",
      "he -> Billa\n",
      "his -> Billa\n",
      "their -> Both\n",
      "them -> fish\n",
      "they -> fish\n",
      "them -> fish\n",
      "him -> Dimitri\n",
      "He -> Dimitri\n",
      "his -> Dimitri\n",
      "his -> Dimitri\n",
      "his -> Dimitri\n",
      "him -> Dimitri\n",
      "her -> Jasmine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 277.58 examples/s]\n",
      "12/15/2023 14:21:50 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 20.13it/s]\n",
      "12/15/2023 14:21:50 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "his -> Omi\n",
      "his -> Omi\n",
      "his -> Omi\n",
      "his -> Omi\n",
      "he -> Omi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 68.25 examples/s]\n",
      "12/15/2023 14:21:50 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 10.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "them -> all\n",
      "he -> Ray\n",
      "she -> Tuesday\n",
      "his -> he's\n",
      "he -> he's\n",
      "he -> Burling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12/15/2023 14:21:51 - INFO - \t Tokenize 1 inputs...\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 102.64 examples/s]\n",
      "12/15/2023 14:21:51 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "her -> Regina\n",
      "her -> Regina\n",
      "Her -> Regina\n",
      "her -> Regina\n",
      "her -> Regina\n",
      "his -> Mark\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "12/15/2023 14:21:51 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "his -> Albert\n",
      "he -> Albert\n",
      "he -> Albert\n",
      "he -> Albert\n",
      "his -> Albert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 56.31 examples/s]\n",
      "12/15/2023 14:21:51 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.64it/s]\n",
      "12/15/2023 14:21:51 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "his -> Avner\n",
      "his -> Avner\n",
      "he -> Avner\n",
      "his -> Avner\n",
      "his -> Avner\n",
      "he -> Avner\n",
      "he -> Avner\n",
      "him -> Avner\n",
      "his -> Avner\n",
      "he -> Avner\n",
      "him -> Avner\n",
      "He -> Robert\n",
      "he -> Robert\n",
      "he -> Robert\n",
      "his -> Robert\n",
      "he -> Robert\n",
      "him -> Robert\n",
      "him -> Robert\n",
      "his -> Robert\n",
      "he -> Louis\n",
      "he -> Louis\n",
      "his -> Hans\n",
      "her -> a woman\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 113.41 examples/s]\n",
      "12/15/2023 14:21:51 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 42.90it/s]\n",
      "12/15/2023 14:21:51 - INFO - \t Tokenize 1 inputs...\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 94.92 examples/s]\n",
      "12/15/2023 14:21:51 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00,  9.85it/s]\n",
      "12/15/2023 14:21:51 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "her -> Jazz\n",
      "he -> Singha\n",
      "his -> Singha\n",
      "He -> Singha\n",
      "his -> Singha\n",
      "He -> Singha\n",
      "he -> Singha\n",
      "He -> Singha\n",
      "his -> Singha\n",
      "his -> Singha\n",
      "he -> Singha\n",
      "He -> Singha\n",
      "him -> Singha\n",
      "his -> Singha\n",
      "his -> Singha\n",
      "He -> Singha\n",
      "He -> Singha\n",
      "He -> Singha\n",
      "He -> Singha\n",
      "his -> Singha\n",
      "him -> Singha\n",
      "He -> Singha\n",
      "his -> Singha\n",
      "him -> Singha\n",
      "her -> Singha\n",
      "she -> Singha\n",
      "she -> Singha\n",
      "her -> Singha\n",
      "He -> Singha\n",
      "he -> Singha\n",
      "he -> Singha\n",
      "He -> Singha\n",
      "him -> Singha\n",
      "him -> Singha\n",
      "his -> Singha\n",
      "her -> a woman\n",
      "she -> Mituna\n",
      "She -> Mituna\n",
      "she -> Mituna\n",
      "her -> Mituna\n",
      "her -> Mituna\n",
      "she -> Mituna\n",
      "she -> Mituna\n",
      "her -> Mituna\n",
      "She -> Mituna\n",
      "she -> Mituna\n",
      "she -> Mituna\n",
      "her -> Mituna\n",
      "her -> Mituna\n",
      "she -> Mituna\n",
      "Her -> Mituna\n",
      "her -> Mituna\n",
      "him -> Lam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<?, ? examples/s]\n",
      "12/15/2023 14:21:51 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 59.52it/s]\n",
      "12/15/2023 14:21:51 - INFO - \t Tokenize 1 inputs...\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 56.38 examples/s]\n",
      "12/15/2023 14:21:52 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00,  5.93it/s]\n",
      "12/15/2023 14:21:52 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "her -> Ava\n",
      "she -> Ava\n",
      "her -> Ava\n",
      "her -> Ava\n",
      "her -> Ava\n",
      "she -> Ava\n",
      "her -> Ava\n",
      "her -> Ava\n",
      "She -> Ava\n",
      "her -> Ava\n",
      "she -> Ava\n",
      "her -> Ava\n",
      "her -> Ava\n",
      "her -> Ava\n",
      "her -> Ava\n",
      "she -> Ava\n",
      "She -> Ava\n",
      "her -> Ava's\n",
      "her -> Ava\n",
      "her -> Ava\n",
      "her -> Ava\n",
      "her -> Ava\n",
      "her -> Ava\n",
      "her -> Ava\n",
      "she -> Ava\n",
      "her -> Ava\n",
      "her -> Ava\n",
      "she -> Ava\n",
      "She -> Ava\n",
      "her -> Ava\n",
      "her -> Ava\n",
      "her -> Ava\n",
      "her -> Ava's\n",
      "her -> Ava\n",
      "her -> Ava\n",
      "her -> Ava\n",
      "she -> Ava\n",
      "she -> Ava\n",
      "her -> Ava\n",
      "her -> Ava\n",
      "her -> Ava\n",
      "she -> Ava\n",
      "her -> Ava\n",
      "She -> Ava\n",
      "her -> Ava\n",
      "her -> Ava\n",
      "she -> Ava\n",
      "her -> Ava\n",
      "her -> Ava\n",
      "her -> Ava\n",
      "her -> Ava\n",
      "she -> Ava\n",
      "her -> Ava\n",
      "she -> Ava\n",
      "her -> Ava\n",
      "her -> Ava\n",
      "her -> Ava\n",
      "she -> Ava\n",
      "her -> Ava\n",
      "she -> Ava\n",
      "her -> Ava\n",
      "her -> Ava\n",
      "her -> Ava\n",
      "she -> Ava\n",
      "she -> Ava\n",
      "She -> Ava\n",
      "her -> Ava\n",
      "she -> Ava\n",
      "she -> Ava\n",
      "he -> Bradley\n",
      "him -> Bradley\n",
      "him -> Bradley\n",
      "he -> Bradley\n",
      "he -> Bradley\n",
      "he -> Bradley\n",
      "his -> Bradley\n",
      "she -> Betty\n",
      "she -> Betty\n",
      "she -> Betty\n",
      "her -> Betty\n",
      "she -> Betty\n",
      "him -> Charlie\n",
      "He -> Charlie\n",
      "he -> Charlie\n",
      "his -> Charlie\n",
      "her -> Charlie\n",
      "her -> Charlie\n",
      "his -> Charlie\n",
      "him -> Charlie\n",
      "he -> Charlie\n",
      "he -> Charlie\n",
      "him -> Charlie\n",
      "He -> Charlie\n",
      "him -> Charlie\n",
      "he -> Charlie\n",
      "he -> Charlie\n",
      "his -> Charlie\n",
      "He -> Charlie\n",
      "he -> Charlie\n",
      "him -> Charlie,\n",
      "his -> Charlie\n",
      "he -> Gerber\n",
      "he -> Gerber\n",
      "his -> Gerber\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 117.85 examples/s]\n",
      "12/15/2023 14:21:52 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 30.98it/s]\n",
      "12/15/2023 14:21:52 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "her -> Ting\n",
      "Her -> Ting\n",
      "her -> Ting\n",
      "her -> Ting\n",
      "they -> the police\n",
      "their -> the police\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 142.81 examples/s]\n",
      "12/15/2023 14:21:52 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 41.49it/s]\n",
      "12/15/2023 14:21:52 - INFO - \t Tokenize 1 inputs...\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 90.18 examples/s]\n",
      "12/15/2023 14:21:52 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 17.82it/s]\n",
      "12/15/2023 14:21:52 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "his -> Sylvester\n",
      "he -> Sylvester\n",
      "his -> Tweety\n",
      "him -> Tweety\n",
      "his -> Tweety\n",
      "him -> Tweety\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 66.04 examples/s]\n",
      "12/15/2023 14:21:52 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 70.06it/s]\n",
      "12/15/2023 14:21:52 - INFO - \t Tokenize 1 inputs...\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 124.74 examples/s]\n",
      "12/15/2023 14:21:52 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 46.71it/s]\n",
      "12/15/2023 14:21:52 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "her -> Lee\n",
      "her -> Lee\n",
      "him -> Blue\n",
      "him -> Blue\n",
      "his -> Blue\n",
      "him -> Blue\n",
      "he -> Blue\n",
      "his -> Blue\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 61.48 examples/s]\n",
      "12/15/2023 14:21:52 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.21it/s]\n",
      "12/15/2023 14:21:52 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "he -> Larry\n",
      "he -> Larry\n",
      "he -> Larry\n",
      "their -> all\n",
      "them -> all\n",
      "them -> all\n",
      "them -> all\n",
      "his -> Shack\n",
      "his -> my\n",
      "he -> my\n",
      "his -> my\n",
      "him -> my\n",
      "his -> Bob\n",
      "his -> Bob\n",
      "He -> Larry\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 125.97 examples/s]\n",
      "12/15/2023 14:21:52 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 60.30it/s]\n",
      "12/15/2023 14:21:53 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "his -> Slip\n",
      "his -> Slip\n",
      "his -> Slip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 161.73 examples/s]\n",
      "12/15/2023 14:21:53 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 47.15it/s]\n",
      "12/15/2023 14:21:53 - INFO - \t Tokenize 1 inputs...\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 124.76 examples/s]\n",
      "12/15/2023 14:21:53 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 15.02it/s]\n",
      "12/15/2023 14:21:53 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "his -> Monty\n",
      "He -> Monty\n",
      "his -> Monty\n",
      "his -> Monty\n",
      "his -> Monty\n",
      "he -> Monty\n",
      "he -> Monty\n",
      "he -> Monty\n",
      "he -> Monty\n",
      "his -> Monty\n",
      "he -> Monty\n",
      "his -> Monty\n",
      "he -> Monty\n",
      "his -> Monty\n",
      "he -> Monty\n",
      "his -> Monty\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 100.50 examples/s]\n",
      "12/15/2023 14:21:53 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 21.40it/s]\n",
      "12/15/2023 14:21:53 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "His -> Willie\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 161.46 examples/s]\n",
      "12/15/2023 14:21:53 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 31.13it/s]\n",
      "12/15/2023 14:21:53 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "his -> Janek\n",
      "He -> Janek\n",
      "his -> Janek\n",
      "his -> Janek\n",
      "his -> Janek\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 133.00 examples/s]\n",
      "12/15/2023 14:21:53 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 45.43it/s]\n",
      "12/15/2023 14:21:53 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "he -> Beko\n",
      "he -> Beko\n",
      "his -> Beko\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 82.53 examples/s]\n",
      "12/15/2023 14:21:53 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 18.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "they -> police\n",
      "her -> Mildred\n",
      "She -> Mildred\n",
      "her -> Mildred\n",
      "she -> Mildred\n",
      "her -> Mildred\n",
      "she -> Mildred\n",
      "she -> Mildred\n",
      "her -> Mildred\n",
      "her -> Mildred\n",
      "her -> Mildred\n",
      "her -> Mildred\n",
      "her -> Mildred\n",
      "He -> Beragon\n",
      "he -> Beragon\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "12/15/2023 14:21:53 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "her -> Kay\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 142.73 examples/s]\n",
      "12/15/2023 14:21:53 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 41.48it/s]\n",
      "12/15/2023 14:21:53 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "he -> Chris\n",
      "his -> Chris\n",
      "his -> Chris\n",
      "he -> Chris\n",
      "he -> Chris\n",
      "his -> Chris\n",
      "he -> Shifty\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 57.03 examples/s]\n",
      "12/15/2023 14:21:53 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 10.97it/s]\n",
      "12/15/2023 14:21:53 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "him -> the boy\n",
      "his -> the boy\n",
      "his -> Pip\n",
      "him -> Pip\n",
      "him -> Pip\n",
      "He -> Pip\n",
      "him -> Pip\n",
      "his -> Pip's\n",
      "him -> Pip\n",
      "she -> Pip\n",
      "his -> Pip\n",
      "He -> Pip\n",
      "he -> Pip\n",
      "he -> Pip\n",
      "him -> Pip\n",
      "he -> Magwitch\n",
      "she -> Miss Havisham\n",
      "her -> Miss Havisham\n",
      "she -> Miss Havisham\n",
      "she -> you\n",
      "Her -> you\n",
      "her -> you\n",
      "his -> Magwitch\n",
      "He -> Magwitch\n",
      "his -> Magwitch\n",
      "him -> Magwitch\n",
      "She -> Estella\n",
      "she -> Estella\n",
      "she -> Estella\n",
      "she -> Estella\n",
      "she -> Estella\n",
      "her -> Estella\n",
      "Her -> Estella\n",
      "her -> Estella\n",
      "she -> Estella\n",
      "she -> Estella\n",
      "he -> Joe Gargery\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 152.89 examples/s]\n",
      "12/15/2023 14:21:53 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 59.71it/s]\n",
      "12/15/2023 14:21:53 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "his -> a man\n",
      "he -> a man\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<?, ? examples/s]\n",
      "12/15/2023 14:21:53 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 59.82it/s]\n",
      "12/15/2023 14:21:54 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "his -> Kishore\n",
      "him -> Raj\n",
      "his -> Raj\n",
      "he -> Raj\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 114.73 examples/s]\n",
      "12/15/2023 14:21:54 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00,  9.96it/s]\n",
      "12/15/2023 14:21:54 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "his -> Chappy\n",
      "him -> Chappy\n",
      "him -> Chappy\n",
      "he -> Chappy\n",
      "his -> Chappy\n",
      "him -> Chappy\n",
      "him -> Chappy\n",
      "his -> Chappy\n",
      "him -> Chappy\n",
      "him -> Chappy\n",
      "him -> Chappy\n",
      "he -> Chappy\n",
      "his -> Simms\n",
      "his -> Simms\n",
      "his -> Simms\n",
      "her -> Anna\n",
      "her -> Anna\n",
      "she -> Anna\n",
      "she -> Anna\n",
      "her -> Anna\n",
      "She -> Anna\n",
      "her -> Anna\n",
      "she -> Anna's\n",
      "her -> Anna\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 83.69 examples/s]\n",
      "12/15/2023 14:21:54 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 93.62it/s]\n",
      "12/15/2023 14:21:54 - INFO - \t Tokenize 1 inputs...\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 114.71 examples/s]\n",
      "12/15/2023 14:21:54 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.01it/s]\n",
      "12/15/2023 14:21:54 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "He -> Marshall\n",
      "him -> Marshall\n",
      "he -> Marshall\n",
      "his -> Marshall\n",
      "her -> Holly\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 101.84 examples/s]\n",
      "12/15/2023 14:21:54 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 15.70it/s]\n",
      "12/15/2023 14:21:54 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "his -> Scott\n",
      "his -> Scott\n",
      "he -> Scott\n",
      "he -> Scott\n",
      "he -> Scott\n",
      "his -> Scott\n",
      "His -> Scott\n",
      "his -> Scott\n",
      "his -> Scott\n",
      "him -> Scott\n",
      "his -> Scott\n",
      "his -> Scott\n",
      "he -> Scott\n",
      "He -> Scott\n",
      "him -> Scott\n",
      "his -> Scott\n",
      "he -> Scott\n",
      "her -> Carol\n",
      "his -> Santa\n",
      "him -> Santa's\n",
      "He -> Jack Frost\n",
      "he -> Jack Frost\n",
      "his -> Jack Frost\n",
      "him -> Jack Frost\n",
      "His -> Frost\n",
      "he -> Frost\n",
      "his -> Jack\n",
      "his -> Jack\n",
      "he -> Jack\n",
      "his -> Jack Frost\n",
      "her -> Lucy\n",
      "her -> Lucy\n",
      "her -> Lucy\n",
      "her -> Lucy\n",
      "her -> Lucy\n",
      "his -> Jack\n",
      "him -> Jack\n",
      "him -> Jack\n",
      "he -> Jack\n",
      "he -> Jack\n",
      "his -> Jack\n",
      "he -> Jack\n",
      "him -> Frost\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<?, ? examples/s]\n",
      "12/15/2023 14:21:54 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 32.54it/s]\n",
      "12/15/2023 14:21:54 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "his -> Bharathi\n",
      "His -> Bharathi\n",
      "his -> Bharathi\n",
      "him -> Bharathi\n",
      "her -> Kannamma\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 114.57 examples/s]\n",
      "12/15/2023 14:21:54 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 37.43it/s]\n",
      "12/15/2023 14:21:54 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "his -> Rabbit\n",
      "his -> Rabbit\n",
      "his -> Darby\n",
      "he -> Darby\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 60.10 examples/s]\n",
      "12/15/2023 14:21:54 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.18it/s]\n",
      "12/15/2023 14:21:54 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "she -> Cheryl\n",
      "Her -> Cheryl\n",
      "her -> Cheryl\n",
      "she -> Cheryl\n",
      "her -> Cheryl\n",
      "her -> Cheryl\n",
      "she -> Cheryl\n",
      "her -> Cheryl\n",
      "her -> Cheryl\n",
      "him -> Ash\n",
      "he -> Ash\n",
      "he -> Ash\n",
      "he -> Ash\n",
      "him -> Ash\n",
      "his -> Ash\n",
      "him -> Ash\n",
      "he -> Ash\n",
      "his -> Scotty\n",
      "him -> Scotty\n",
      "He -> Scotty\n",
      "he -> Scotty\n",
      "her -> Shelly\n",
      "she -> Linda,\n",
      "her -> Linda\n",
      "her -> Linda\n",
      "her -> Linda\n",
      "her -> Linda's\n",
      "her -> Linda's\n",
      "She -> Linda's\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 207.54 examples/s]\n",
      "12/15/2023 14:21:54 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 49.88it/s]\n",
      "12/15/2023 14:21:55 - INFO - \t Tokenize 1 inputs...\n",
      "Map: 100%|██████████| 1/1 [00:00<?, ? examples/s]\n",
      "12/15/2023 14:21:55 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 103.74it/s]\n",
      "12/15/2023 14:21:55 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "he -> James McGregor\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 120.09 examples/s]\n",
      "12/15/2023 14:21:55 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 73.60it/s]\n",
      "12/15/2023 14:21:55 - INFO - \t Tokenize 1 inputs...\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 139.18 examples/s]\n",
      "12/15/2023 14:21:55 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 26.72it/s]\n",
      "12/15/2023 14:21:55 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "his -> Jimmy\n",
      "them -> the police\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 124.98 examples/s]\n",
      "12/15/2023 14:21:55 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 21.70it/s]\n",
      "12/15/2023 14:21:55 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "her -> Amanda\n",
      "her -> Amanda\n",
      "him -> Lenny\n",
      "he -> Lenny\n",
      "him -> Lenny\n",
      "He -> Lenny\n",
      "her -> Linda\n",
      "her -> Linda\n",
      "her -> Linda,\n",
      "her -> Linda,\n",
      "she -> Linda,\n",
      "her -> Linda\n",
      "her -> Linda\n",
      "she -> Linda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<?, ? examples/s]\n",
      "12/15/2023 14:21:55 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 17.85it/s]\n",
      "12/15/2023 14:21:55 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "his -> Emperor Akbar\n",
      "his -> Akbar\n",
      "his -> Akbar\n",
      "his -> Akbar\n",
      "he -> Akbar\n",
      "his -> Akbar\n",
      "him -> Akbar\n",
      "his -> Akbar\n",
      "He -> Akbar\n",
      "her -> the maid\n",
      "she -> the maid\n",
      "him -> Salim's\n",
      "his -> Salim\n",
      "his -> Salim\n",
      "his -> Salim\n",
      "his -> Salim\n",
      "him -> Salim\n",
      "he -> Salim\n",
      "her -> Anarkali\n",
      "she -> Anarkali\n",
      "her -> Anarkali\n",
      "she -> Anarkali\n",
      "she -> Anarkali\n",
      "She -> Anarkali\n",
      "her -> Anarkali\n",
      "she -> Anarkali\n",
      "She -> Anarkali\n",
      "she -> Anarkali\n",
      "her -> Anarkali\n",
      "she -> Anarkali\n",
      "her -> Anarkali\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 97.40 examples/s]\n",
      "12/15/2023 14:21:55 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 55.51it/s]\n",
      "12/15/2023 14:21:55 - INFO - \t Tokenize 1 inputs...\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 124.63 examples/s]\n",
      "12/15/2023 14:21:55 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 59.59it/s]\n",
      "12/15/2023 14:21:55 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "he -> Jakob\n",
      "He -> Jakob\n",
      "his -> Jakob\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 84.61 examples/s]\n",
      "12/15/2023 14:21:55 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 59.87it/s]\n",
      "12/15/2023 14:21:55 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "him -> Steven\n",
      "his -> Steven\n",
      "his -> Steven\n",
      "his -> Steven\n",
      "she -> Carol\n",
      "she -> Carol\n",
      "she -> Carol\n",
      "her -> Carol\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 116.07 examples/s]\n",
      "12/15/2023 14:21:55 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.40it/s]\n",
      "12/15/2023 14:21:55 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "him -> its\n",
      "him -> its\n",
      "He -> Clark\n",
      "his -> Clark\n",
      "his -> Clark\n",
      "she -> Lois\n",
      "she -> her,\n",
      "her -> her,\n",
      "She -> Lois\n",
      "his -> Superman\n",
      "He -> Superman\n",
      "him -> Superman\n",
      "he -> Superman\n",
      "he -> Superman\n",
      "his -> Superman\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 82.04 examples/s]\n",
      "12/15/2023 14:21:55 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 17.25it/s]\n",
      "12/15/2023 14:21:56 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "his -> Johnny\n",
      "his -> Johnny\n",
      "his -> Johnny\n",
      "his -> Johnny\n",
      "her -> Vanessa\n",
      "she -> Vanessa\n",
      "she -> Vanessa\n",
      "her -> Vanessa\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 163.91 examples/s]\n",
      "12/15/2023 14:21:56 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 41.12it/s]\n",
      "12/15/2023 14:21:56 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "her -> Molly\n",
      "her -> Molly\n",
      "her -> Molly\n",
      "her -> Molly\n",
      "her -> Molly\n",
      "her -> Molly\n",
      "he -> Keith\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 95.38 examples/s]\n",
      "12/15/2023 14:21:56 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 51.83it/s]\n",
      "12/15/2023 14:21:56 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "his -> Sathya\n",
      "He -> Sathya\n",
      "he -> Sathya\n",
      "He -> Sathya\n",
      "she -> Lavanya\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 189.93 examples/s]\n",
      "12/15/2023 14:21:56 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.62it/s]\n",
      "12/15/2023 14:21:56 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "his -> Sean\n",
      "him -> Sean\n",
      "his -> Sean\n",
      "he -> Sean\n",
      "he -> Sean\n",
      "he -> Sean\n",
      "his -> Sean\n",
      "he -> Sean\n",
      "him -> Sean\n",
      "his -> Sean\n",
      "his -> Sean\n",
      "him -> Sean\n",
      "his -> Sean\n",
      "him -> Sean\n",
      "he -> Sean\n",
      "he -> Sean\n",
      "he -> Sean\n",
      "his -> Sean\n",
      "he -> Sean\n",
      "his -> Sean\n",
      "his -> Sean\n",
      "he -> Sean\n",
      "his -> Sean\n",
      "him -> Sean\n",
      "his -> Sean\n",
      "he -> Sean\n",
      "He -> Sean\n",
      "he -> Sean\n",
      "he -> Sean\n",
      "his -> Sean\n",
      "he -> Sean\n",
      "him -> Sean\n",
      "his -> Sean\n",
      "his -> Ray,\n",
      "he -> Matthews\n",
      "his -> Ray\n",
      "him -> Ray,\n",
      "him -> Ray,\n",
      "him -> Ray,\n",
      "his -> Gatley\n",
      "him -> Gatley\n",
      "his -> Gatley\n",
      "him -> Carl\n",
      "him -> Carl\n",
      "his -> Carl,\n",
      "his -> Carl,\n",
      "he -> Duke\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 125.02 examples/s]\n",
      "12/15/2023 14:21:56 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 48.27it/s]\n",
      "12/15/2023 14:21:56 - INFO - \t Tokenize 1 inputs...\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 108.99 examples/s]\n",
      "12/15/2023 14:21:56 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 60.00it/s]\n",
      "12/15/2023 14:21:56 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "her -> Jackie\n",
      "her -> Jackie\n",
      "her -> Jackie\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 73.92 examples/s]\n",
      "12/15/2023 14:21:56 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 24.04it/s]\n",
      "12/15/2023 14:21:56 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "her -> Nancy\n",
      "She -> Nancy\n",
      "she -> Nancy\n",
      "her -> Nancy\n",
      "she -> Nancy\n",
      "her -> Nancy\n",
      "her -> Nancy\n",
      "she -> Nancy\n",
      "her -> Nancy\n",
      "She -> Nancy\n",
      "she -> Nancy\n",
      "his -> Barrie\n",
      "he -> Barrie\n",
      "him -> Barrie\n",
      "him -> Cassius\n",
      "he -> Cassius\n",
      "He -> Cassius\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 67.99 examples/s]\n",
      "12/15/2023 14:21:56 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "She -> Hana\n",
      "her -> Hana\n",
      "her -> Hana\n",
      "her -> Hana\n",
      "her -> Hana\n",
      "her -> Hana\n",
      "she -> Hana\n",
      "she -> his wife\n",
      "she -> Hana\n",
      "her -> Hana\n",
      "she -> Hana\n",
      "she -> Hana\n",
      "her -> Hana\n",
      "she -> Hana\n",
      "her -> Hana\n",
      "her -> Hana\n",
      "her -> Hana\n",
      "her -> Hana\n",
      "her -> Hana\n",
      "she -> Hana\n",
      "she -> Hana\n",
      "She -> Hana\n",
      "her -> Hana\n",
      "her -> Hana\n",
      "his -> Emil\n",
      "his -> Emil\n",
      "him -> Emil\n",
      "his -> Emil\n",
      "he -> Emil\n",
      "him -> Emil\n",
      "him -> Emil\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12/15/2023 14:21:56 - INFO - \t Tokenize 1 inputs...\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 178.47 examples/s]\n",
      "12/15/2023 14:21:56 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 64.30it/s]\n",
      "12/15/2023 14:21:56 - INFO - \t Tokenize 1 inputs...\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 86.83 examples/s]\n",
      "12/15/2023 14:21:56 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 17.05it/s]\n",
      "12/15/2023 14:21:56 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "her -> Spears\n",
      "she -> Spears\n",
      "She -> Spears\n",
      "her -> I\n",
      "her -> I\n",
      "her -> I\n",
      "her -> Spears\n",
      "her -> Spears\n",
      "she -> Spears\n",
      "her -> Spears\n",
      "she -> I\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 110.81 examples/s]\n",
      "12/15/2023 14:21:56 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 10.82it/s]\n",
      "12/15/2023 14:21:57 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "he -> Scott\n",
      "his -> Scott\n",
      "his -> Scott\n",
      "him -> Scott\n",
      "he -> Scott\n",
      "his -> Scott\n",
      "he -> Scott\n",
      "he -> Scott\n",
      "his -> Scott\n",
      "he -> Scott\n",
      "he -> Scott\n",
      "his -> Scott\n",
      "his -> Scott\n",
      "his -> Scott's\n",
      "his -> Scott\n",
      "his -> Scott\n",
      "she -> Peggy\n",
      "she -> Peggy\n",
      "She -> Peggy\n",
      "her -> Peggy\n",
      "she -> Peggy\n",
      "she -> Peggy\n",
      "he -> Tod\n",
      "he -> Tod\n",
      "him -> Tod\n",
      "he -> Tod\n",
      "him -> Tod\n",
      "he -> Tod\n",
      "He -> Tod\n",
      "his -> Tod\n",
      "his -> Tod\n",
      "he -> Tod\n",
      "his -> Tod\n",
      "his -> Tod\n",
      "him -> Tod\n",
      "his -> Tod\n",
      "he -> Tod\n",
      "he -> Tod\n",
      "he -> Tod\n",
      "his -> Tod\n",
      "his -> Tod's\n",
      "he -> Tod's\n",
      "his -> Tod's\n",
      "He -> Tod's\n",
      "him -> Tod's\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<?, ? examples/s]\n",
      "12/15/2023 14:21:57 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 62.20it/s]\n",
      "12/15/2023 14:21:57 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "his -> François\n",
      "He -> François\n",
      "his -> François\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 30.67 examples/s]\n",
      "12/15/2023 14:21:57 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00,  3.53it/s]\n",
      "12/15/2023 14:21:57 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "he -> Cavil\n",
      "his -> Cavil\n",
      "he -> Cavil\n",
      "he -> Cavil\n",
      "he -> Cavil\n",
      "his -> Cavil\n",
      "He -> Cavil\n",
      "he -> Cavil\n",
      "he -> Cavil\n",
      "his -> Cavil\n",
      "him -> Cavil\n",
      "him -> Cavil\n",
      "his -> Cavil\n",
      "his -> Cavil\n",
      "He -> Cavil\n",
      "he -> Cavil\n",
      "he -> Cavil\n",
      "he -> Cavil\n",
      "he -> Cavil\n",
      "He -> Cavil\n",
      "he -> Cavil\n",
      "He -> Cavil\n",
      "his -> Cavil\n",
      "he -> Cavil\n",
      "his -> Cavil\n",
      "his -> Anders\n",
      "his -> Commander Adama\n",
      "him -> Commander Adama\n",
      "he -> Baltar\n",
      "his -> Sam\n",
      "his -> Sam\n",
      "she -> Boomer\n",
      "her -> Boomer\n",
      "she -> Boomer\n",
      "She -> Boomer\n",
      "her -> the Six\n",
      "his -> Simon\n",
      "he -> Simon\n",
      "he -> Simon\n",
      "his -> Simon\n",
      "he -> Simon\n",
      "her -> his wife\n",
      "him -> the boy\n",
      "him -> The boy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 97.13 examples/s]\n",
      "12/15/2023 14:21:57 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 16.10it/s]\n",
      "12/15/2023 14:21:57 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "his -> Clayton\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 124.10 examples/s]\n",
      "12/15/2023 14:21:57 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.80it/s]\n",
      "12/15/2023 14:21:58 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "his -> Jason Voorhees\n",
      "He -> Jason\n",
      "He -> Jason\n",
      "his -> Jason\n",
      "he -> Jason\n",
      "his -> Jason\n",
      "he -> Jason\n",
      "his -> Jason\n",
      "his -> Jason\n",
      "him -> Jason\n",
      "he -> Jason\n",
      "his -> Jason\n",
      "him -> Jason\n",
      "he -> Jason\n",
      "his -> Jason\n",
      "his -> Jason\n",
      "she -> Ginny\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 121.36 examples/s]\n",
      "12/15/2023 14:21:58 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 17.11it/s]\n",
      "12/15/2023 14:21:58 - INFO - \t Tokenize 1 inputs...\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 157.28 examples/s]\n",
      "12/15/2023 14:21:58 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 39.38it/s]\n",
      "12/15/2023 14:21:58 - INFO - \t Tokenize 1 inputs...\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 116.23 examples/s]\n",
      "12/15/2023 14:21:58 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 40.32it/s]\n",
      "12/15/2023 14:21:58 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "his -> Shivan\n",
      "He -> Shivan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 179.54 examples/s]\n",
      "12/15/2023 14:21:58 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 55.23it/s]\n",
      "12/15/2023 14:21:58 - INFO - \t Tokenize 1 inputs...\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 125.08 examples/s]\n",
      "12/15/2023 14:21:58 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 65.92it/s]\n",
      "12/15/2023 14:21:58 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "He -> Dante\n",
      "he -> Dante\n",
      "his -> Dante\n",
      "he -> Dante\n",
      "him -> Dante\n",
      "his -> Dante\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 125.68 examples/s]\n",
      "12/15/2023 14:21:58 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 31.69it/s]\n",
      "12/15/2023 14:21:58 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "him -> Bernie\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 124.76 examples/s]\n",
      "12/15/2023 14:21:58 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 24.46it/s]\n",
      "12/15/2023 14:21:58 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "her -> Meenakshi\n",
      "her -> Meenakshi\n",
      "her -> Divya\n",
      "her -> Divya\n",
      "she -> Divya\n",
      "her -> her,\n",
      "her -> Meenakshi\n",
      "her -> Meenakshi\n",
      "her -> Meenakshi's\n",
      "her -> Meenakshi's\n",
      "his -> Jeeva\n",
      "his -> Jeeva\n",
      "he -> Jeeva\n",
      "his -> Jeeva\n",
      "he -> Jeeva\n",
      "he -> Jeeva\n",
      "he -> Jeeva\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 63.96 examples/s]\n",
      "12/15/2023 14:21:58 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 17.84it/s]\n",
      "12/15/2023 14:21:58 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "her -> Roopa's\n",
      "her -> Roopa's\n",
      "her -> Roopa's\n",
      "she -> Roopa\n",
      "she -> Roopa\n",
      "she -> Roopa\n",
      "her -> Roopa\n",
      "she -> Roopa\n",
      "her -> her,\n",
      "her -> her,\n",
      "she -> her,\n",
      "her -> her,\n",
      "her -> her,\n",
      "her -> Roopa\n",
      "her -> Roopa\n",
      "her -> Gujjar\n",
      "his -> Gujjar\n",
      "his -> Kishan\n",
      "he -> Kishan\n",
      "him -> Shankar\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 120.59 examples/s]\n",
      "12/15/2023 14:21:58 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 41.50it/s]\n",
      "12/15/2023 14:21:58 - INFO - \t Tokenize 1 inputs...\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 89.01 examples/s]\n",
      "12/15/2023 14:21:58 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 35.00it/s]\n",
      "12/15/2023 14:21:58 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "his -> Criswell\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 79.87 examples/s]\n",
      "12/15/2023 14:21:58 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 21.21it/s]\n",
      "12/15/2023 14:21:59 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "his -> MacKay\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 133.05 examples/s]\n",
      "12/15/2023 14:21:59 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 51.07it/s]\n",
      "12/15/2023 14:21:59 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "his -> Kane\n",
      "his -> Kane\n",
      "his -> Kane\n",
      "he -> Kane\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 327.07 examples/s]\n",
      "12/15/2023 14:21:59 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 46.99it/s]\n",
      "12/15/2023 14:21:59 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "his -> Nico\n",
      "him -> Nico\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 124.73 examples/s]\n",
      "12/15/2023 14:21:59 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 55.09it/s]\n",
      "12/15/2023 14:21:59 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "He -> Tirupati\n",
      "his -> Tirupati\n",
      "him -> Tirupati\n",
      "his -> Tirupati\n",
      "him -> Tirupati\n",
      "his -> Tirupati\n",
      "he -> Tirupati\n",
      "his -> Guru\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<?, ? examples/s]\n",
      "12/15/2023 14:21:59 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 24.05it/s]\n",
      "12/15/2023 14:21:59 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "his -> Ned Kynaston\n",
      "his -> Ned Kynaston\n",
      "His -> Ned Kynaston\n",
      "his -> Kynaston\n",
      "he -> Kynaston\n",
      "he -> Kynaston\n",
      "he -> Kynaston\n",
      "he -> Kynaston\n",
      "he -> Kynaston\n",
      "his -> Kynaston\n",
      "her -> Maria's\n",
      "she -> Maria's\n",
      "she -> Maria's\n",
      "she -> Maria\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 430.58 examples/s]\n",
      "12/15/2023 14:21:59 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 45.67it/s]\n",
      "12/15/2023 14:21:59 - INFO - \t Tokenize 1 inputs...\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 124.67 examples/s]\n",
      "12/15/2023 14:21:59 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 50.59it/s]\n",
      "12/15/2023 14:21:59 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "her -> Roberta\n",
      "his -> Frank's\n",
      "his -> Frank's\n",
      "he -> Frank\n",
      "his -> Frank\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 76.42 examples/s]\n",
      "12/15/2023 14:21:59 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "they -> you\n",
      "them -> you\n",
      "They -> you\n",
      "they -> you\n",
      "They -> you\n",
      "They -> you\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "12/15/2023 14:21:59 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "He -> Ollie\n",
      "him -> Ollie\n",
      "him -> Ollie\n",
      "he -> Ollie\n",
      "his -> Ollie\n",
      "he -> Stan\n",
      "he -> Stan\n",
      "his -> Stan\n",
      "his -> Stan\n",
      "him -> Stan's\n",
      "him -> Stan's\n",
      "he -> Stan's\n",
      "his -> Stan's\n",
      "he -> Stan\n",
      "him -> Stan\n",
      "his -> Stan\n",
      "him -> Stan\n",
      "he -> Stan\n",
      "him -> Stan\n",
      "him -> Stan\n",
      "his -> Stan\n",
      "his -> my\n",
      "he -> Oliver\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 40.92 examples/s]\n",
      "12/15/2023 14:21:59 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.21it/s]\n",
      "12/15/2023 14:21:59 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "his -> Rob\n",
      "he -> Rob\n",
      "his -> Rob\n",
      "his -> Rob\n",
      "he -> Rob\n",
      "he -> Rob\n",
      "he -> Rob\n",
      "He -> Rob\n",
      "He -> Rob\n",
      "his -> Rob\n",
      "He -> Rob\n",
      "him -> Rob\n",
      "him -> Rob\n",
      "his -> Rob\n",
      "him -> Rob's\n",
      "he -> Rob\n",
      "He -> Rob\n",
      "his -> Rob\n",
      "he -> Rob\n",
      "he -> Rob\n",
      "him -> Rob\n",
      "He -> Rob\n",
      "him -> Rob\n",
      "he -> Rob\n",
      "his -> Rob\n",
      "him -> Rob\n",
      "he -> Rob\n",
      "him -> Rob\n",
      "his -> Rob\n",
      "his -> Rob\n",
      "his -> Rob\n",
      "his -> Nathan\n",
      "she -> Dana\n",
      "her -> Dana\n",
      "her -> her,\n",
      "she -> Heidi\n",
      "she -> Heidi\n",
      "her -> Heidi\n",
      "her -> Heidi\n",
      "her -> Heidi\n",
      "she -> Heidi\n",
      "her -> Heidi\n",
      "he -> Lube\n",
      "he -> Lube\n",
      "him -> Lube\n",
      "his -> Lube\n",
      "his -> Lube\n",
      "he -> Lube\n",
      "her -> Ashley\n",
      "she -> her,\n",
      "her -> Ashley\n",
      "her -> her,\n",
      "he -> Stifler\n",
      "he -> Stifler\n",
      "he -> Stifler\n",
      "him -> Stifler\n",
      "she -> Katie\n",
      "her -> Katie\n",
      "She -> Katie\n",
      "she -> Katie\n",
      "her -> Katie\n",
      "she -> his mother\n",
      "her -> his mother\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 199.36 examples/s]\n",
      "12/15/2023 14:22:00 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 20.74it/s]\n",
      "12/15/2023 14:22:00 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "his -> Prakash\n",
      "his -> Prakash\n",
      "his -> Prakash\n",
      "his -> Prakash\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 139.98 examples/s]\n",
      "12/15/2023 14:22:00 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 19.62it/s]\n",
      "12/15/2023 14:22:00 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "his -> Merlin\n",
      "his -> Merlin\n",
      "his -> Merlin\n",
      "she -> Christine\n",
      "she -> Christine\n",
      "she -> Christine\n",
      "her -> Christine\n",
      "she -> her,\n",
      "her -> her,\n",
      "her -> her,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 85.59 examples/s]\n",
      "12/15/2023 14:22:00 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.35it/s]\n",
      "12/15/2023 14:22:00 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "he -> Mick O'Brien\n",
      "him -> Mick O'Brien\n",
      "his -> Mick\n",
      "he -> Mick\n",
      "him -> Mick\n",
      "him -> Mick\n",
      "he -> Mick\n",
      "his -> Paco's\n",
      "he -> Paco\n",
      "he -> Paco's\n",
      "his -> Paco's\n",
      "him -> Horowitz\n",
      "him -> Horowitz\n",
      "he -> Horowitz\n",
      "he -> Horowitz\n",
      "He -> Ramon\n",
      "him -> Mick\n",
      "He -> Mick\n",
      "his -> Mick\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 115.73 examples/s]\n",
      "12/15/2023 14:22:00 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 24.46it/s]\n",
      "12/15/2023 14:22:00 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "He -> the stranger\n",
      "his -> the stranger\n",
      "his -> the stranger\n",
      "his -> the stranger\n",
      "him -> the stranger\n",
      "he -> the stranger\n",
      "her -> Laura\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 124.82 examples/s]\n",
      "12/15/2023 14:22:00 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 38.03it/s]\n",
      "12/15/2023 14:22:00 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "He -> Samson\n",
      "her -> Mallika\n",
      "her -> the girl\n",
      "She -> Mallika\n",
      "her -> Mallika\n",
      "she -> Mallika\n",
      "her -> Mallika\n",
      "her -> Mallika\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 71.69 examples/s]\n",
      "12/15/2023 14:22:00 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 24.34it/s]\n",
      "12/15/2023 14:22:00 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "his -> Luke\n",
      "his -> Luke\n",
      "his -> Luke\n",
      "he -> Luke\n",
      "he -> Luke\n",
      "his -> Luke\n",
      "his -> Luke\n",
      "his -> Luke\n",
      "he -> Luke\n",
      "his -> Luke\n",
      "he -> Luke\n",
      "He -> Luke\n",
      "he -> Luke\n",
      "he -> Luke\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 120.17 examples/s]\n",
      "12/15/2023 14:22:00 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 59.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "her -> his wife\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12/15/2023 14:22:00 - INFO - \t Tokenize 1 inputs...\n",
      "Map: 100%|██████████| 1/1 [00:00<?, ? examples/s]\n",
      "12/15/2023 14:22:00 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 15.37it/s]\n",
      "12/15/2023 14:22:00 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "he -> Smith's\n",
      "her -> Pam\n",
      "her -> Pam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<?, ? examples/s]\n",
      "12/15/2023 14:22:00 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 61.98it/s]\n",
      "12/15/2023 14:22:00 - INFO - \t Tokenize 1 inputs...\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 116.55 examples/s]\n",
      "12/15/2023 14:22:00 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 24.17it/s]\n",
      "12/15/2023 14:22:01 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "his -> Hamilton\n",
      "His -> Hamilton\n",
      "him -> Hamilton\n",
      "his -> Hamilton\n",
      "his -> Hamilton\n",
      "his -> his brother\n",
      "him -> his brother\n",
      "his -> his brother\n",
      "they -> people\n",
      "them -> people\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 124.72 examples/s]\n",
      "12/15/2023 14:22:01 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 63.37it/s]\n",
      "12/15/2023 14:22:01 - INFO - \t Tokenize 1 inputs...\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 124.74 examples/s]\n",
      "12/15/2023 14:22:01 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 50.81it/s]\n",
      "12/15/2023 14:22:01 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "him -> Bobby\n",
      "his -> Bobby\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 124.75 examples/s]\n",
      "12/15/2023 14:22:01 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 36.86it/s]\n",
      "12/15/2023 14:22:01 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "he -> Louis XVII\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 124.76 examples/s]\n",
      "12/15/2023 14:22:01 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 46.53it/s]\n",
      "12/15/2023 14:22:01 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "his -> Dave\n",
      "his -> Dave\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<?, ? examples/s]\n",
      "12/15/2023 14:22:01 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 44.87it/s]\n",
      "12/15/2023 14:22:01 - INFO - \t Tokenize 1 inputs...\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 230.27 examples/s]\n",
      "12/15/2023 14:22:01 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 30.92it/s]\n",
      "12/15/2023 14:22:01 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "him -> Stan\n",
      "he -> Stan\n",
      "he -> Stan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 96.38 examples/s]\n",
      "12/15/2023 14:22:01 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 31.34it/s]\n",
      "12/15/2023 14:22:01 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "he -> Sivaji\n",
      "He -> Sivaji\n",
      "he -> Sivaji\n",
      "his -> Sivaji\n",
      "He -> Sivaji\n",
      "her -> her,\n",
      "she -> her,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 181.25 examples/s]\n",
      "12/15/2023 14:22:01 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 62.46it/s]\n",
      "12/15/2023 14:22:01 - INFO - \t Tokenize 1 inputs...\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 284.42 examples/s]\n",
      "12/15/2023 14:22:01 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 74.08it/s]\n",
      "12/15/2023 14:22:01 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "his -> Suat\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 120.26 examples/s]\n",
      "12/15/2023 14:22:01 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 30.93it/s]\n",
      "12/15/2023 14:22:01 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "his -> Chan\n",
      "he -> Chan\n",
      "He -> Chan\n",
      "his -> Chan\n",
      "him -> Chan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 124.73 examples/s]\n",
      "12/15/2023 14:22:01 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 37.95it/s]\n",
      "12/15/2023 14:22:01 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "her -> Hayden\n",
      "she -> Claire\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 153.46 examples/s]\n",
      "12/15/2023 14:22:01 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 50.92it/s]\n",
      "12/15/2023 14:22:01 - INFO - \t Tokenize 1 inputs...\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 63.50 examples/s]\n",
      "12/15/2023 14:22:02 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 56.58it/s]\n",
      "12/15/2023 14:22:02 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "he -> Viswanathan\n",
      "him -> manu\n",
      "his -> Manu\n",
      "him -> Manu\n",
      "him -> Manu\n",
      "his -> Manu\n",
      "he -> Manu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 122.23 examples/s]\n",
      "12/15/2023 14:22:02 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.34it/s]\n",
      "12/15/2023 14:22:02 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "his -> Tweety\n",
      "his -> Tweety\n",
      "he -> Tweety\n",
      "his -> Tweety\n",
      "his -> Sylvester\n",
      "He -> Sylvester\n",
      "his -> Sylvester\n",
      "him -> Sylvester\n",
      "him -> Sylvester\n",
      "he -> Sylvester\n",
      "He -> Sylvester\n",
      "He -> Sylvester\n",
      "He -> Sylvester\n",
      "his -> Sylvester\n",
      "him -> Sylvester\n",
      "He -> Sylvester\n",
      "His -> Sylvester\n",
      "him -> Sylvester\n",
      "he -> Sylvester\n",
      "his -> Sylvester\n",
      "him -> Sylvester\n",
      "he -> Sylvester\n",
      "his -> Sylvester\n",
      "his -> Sylvester\n",
      "her -> Tweety\n",
      "he -> Sylvester\n",
      "his -> Sylvester\n",
      "He -> Sylvester\n",
      "he -> Sylvester\n",
      "He -> Sylvester\n",
      "him -> Sylvester\n",
      "him -> Sylvester\n",
      "he -> Sylvester\n",
      "his -> Sylvester\n",
      "he -> Sylvester\n",
      "him -> Tweety\n",
      "he -> Tweety\n",
      "him -> Tweety\n",
      "he -> he's\n",
      "his -> he's\n",
      "He -> he's\n",
      "he -> Sylvester\n",
      "His -> Sylvester\n",
      "he -> Sylvester\n",
      "she -> Granny\n",
      "her -> Granny\n",
      "she -> Granny\n",
      "She -> Granny\n",
      "her -> Granny\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 181.24 examples/s]\n",
      "12/15/2023 14:22:02 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 62.49it/s]\n",
      "12/15/2023 14:22:02 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "his -> Jerry Logan\n",
      "he -> Jerry Logan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<?, ? examples/s]\n",
      "12/15/2023 14:22:02 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 50.66it/s]\n",
      "12/15/2023 14:22:02 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "their -> people\n",
      "he -> Comfort\n",
      "his -> Comfort\n",
      "He -> Comfort\n",
      "his -> Comfort\n",
      "He -> Comfort\n",
      "his -> Comfort\n",
      "his -> Comfort\n",
      "he -> Comfort\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 44.72 examples/s]\n",
      "12/15/2023 14:22:02 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00,  5.41it/s]\n",
      "12/15/2023 14:22:02 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "she -> Marietta\n",
      "she -> Marietta\n",
      "she -> Marietta\n",
      "her -> Marietta\n",
      "her -> Marietta\n",
      "she -> Marietta\n",
      "her -> Marietta\n",
      "she -> Marietta\n",
      "her -> Marietta\n",
      "her -> Marietta\n",
      "her -> Marietta\n",
      "her -> Marietta\n",
      "she -> Marietta\n",
      "she -> Marietta\n",
      "she -> Marietta\n",
      "she -> Marietta\n",
      "she -> Marietta\n",
      "she -> Marietta\n",
      "her -> Marietta\n",
      "her -> Marietta\n",
      "she -> Marietta\n",
      "her -> Marietta\n",
      "her -> Marietta\n",
      "her -> Marietta\n",
      "she -> Marietta\n",
      "she -> Marietta\n",
      "she -> Marietta\n",
      "her -> Marietta\n",
      "her -> Marietta\n",
      "her -> Marietta\n",
      "she -> Marietta\n",
      "her -> Marietta\n",
      "he -> Warrington\n",
      "she -> Warrington\n",
      "he -> Warrington\n",
      "him -> Warrington\n",
      "his -> Warrington\n",
      "he -> Warrington\n",
      "he -> I\n",
      "he -> Warrington\n",
      "he -> Warrington\n",
      "he -> Warrington\n",
      "him -> Warrington\n",
      "his -> Warrington\n",
      "him -> Warrington\n",
      "him -> Warrington\n",
      "his -> The Governor\n",
      "he -> The Governor\n",
      "he -> The Governor\n",
      "him -> The Governor\n",
      "he -> The Governor\n",
      "He -> The Governor\n",
      "his -> her Uncle\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 90.30 examples/s]\n",
      "12/15/2023 14:22:02 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.66it/s]\n",
      "12/15/2023 14:22:02 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "he -> its\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 62.50 examples/s]\n",
      "12/15/2023 14:22:02 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.62it/s]\n",
      "12/15/2023 14:22:03 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "she -> Lizzie\n",
      "she -> Lizzie\n",
      "She -> Lizzie\n",
      "she -> Lizzie\n",
      "her -> Lizzie\n",
      "her -> Lizzie\n",
      "her -> Lizzie\n",
      "her -> Lizzie\n",
      "her -> Lizzie\n",
      "her -> Lizzie\n",
      "her -> Lizzie\n",
      "her -> Lizzie\n",
      "her -> Lizzie\n",
      "her -> Lizzie\n",
      "her -> Lizzie's\n",
      "her -> Lizzie\n",
      "her -> Lizzie\n",
      "her -> Lizzie\n",
      "him -> Paolo\n",
      "him -> Paolo\n",
      "his -> Paolo\n",
      "his -> Paolo\n",
      "him -> Paolo\n",
      "he -> Paolo\n",
      "his -> he's\n",
      "he -> Gordo\n",
      "him -> Gordo\n",
      "his -> Gordo\n",
      "he -> he's\n",
      "him -> Gordo\n",
      "he -> Gordo\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 148.90 examples/s]\n",
      "12/15/2023 14:22:03 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 34.18it/s]\n",
      "12/15/2023 14:22:03 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "her -> Nana\n",
      "her -> Nana\n",
      "her -> Nana\n",
      "she -> Nana\n",
      "she -> Nana\n",
      "her -> Nana\n",
      "her -> Nana\n",
      "she -> Nana\n",
      "she -> Nana\n",
      "she -> Daisy\n",
      "her -> Daisy\n",
      "She -> Daisy\n",
      "she -> Daisy\n",
      "she -> Daisy\n",
      "her -> Daisy\n",
      "She -> Daisy\n",
      "she -> Daisy\n",
      "he -> the boy\n",
      "He -> the boy\n",
      "his -> the boy\n",
      "he -> the boy\n",
      "him -> the boy\n",
      "he -> the boy\n",
      "his -> the boy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<?, ? examples/s]\n",
      "12/15/2023 14:22:03 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 104.28it/s]\n",
      "12/15/2023 14:22:03 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "her -> Brandi\n",
      "her -> Brandi\n",
      "her -> Brandi\n",
      "him -> Jake's\n",
      "him -> Jake\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 394.80 examples/s]\n",
      "12/15/2023 14:22:03 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 81.57it/s]\n",
      "12/15/2023 14:22:03 - INFO - \t Tokenize 1 inputs...\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 46.70 examples/s]\n",
      "12/15/2023 14:22:03 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00,  4.99it/s]\n",
      "12/15/2023 14:22:03 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "his -> Charlie\n",
      "his -> Charlie\n",
      "his -> Charlie\n",
      "he -> Charlie\n",
      "he -> Charlie\n",
      "He -> Charlie\n",
      "he -> Charlie\n",
      "he -> Charlie,\n",
      "he -> Charlie\n",
      "he -> Charlie\n",
      "his -> Charlie\n",
      "he -> Charlie\n",
      "his -> Charlie\n",
      "his -> Charlie\n",
      "his -> Charlie\n",
      "his -> Charlie\n",
      "him -> Charlie\n",
      "he -> Charlie\n",
      "his -> Charlie\n",
      "his -> Charlie\n",
      "his -> Charlie\n",
      "him -> Charlie\n",
      "his -> Charlie\n",
      "his -> Charlie\n",
      "his -> Gus\n",
      "he -> Gus\n",
      "him -> Gus\n",
      "his -> Gus\n",
      "he -> Gus\n",
      "he -> Gus\n",
      "his -> Gus\n",
      "she -> Josie\n",
      "her -> Josie\n",
      "She -> Josie\n",
      "her -> Josie\n",
      "her -> Josie\n",
      "her -> Josie\n",
      "she -> Josie\n",
      "him -> Josie\n",
      "his -> Josie\n",
      "him -> Josie\n",
      "his -> Josie\n",
      "She -> Josie\n",
      "she -> Josie\n",
      "her -> Josie\n",
      "He -> the policeman\n",
      "he -> the policeman\n",
      "his -> the policeman\n",
      "his -> the policeman\n",
      "his -> the policeman\n",
      "she -> her,\n",
      "she -> her,\n",
      "them -> men\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 114.22 examples/s]\n",
      "12/15/2023 14:22:03 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.84it/s]\n",
      "12/15/2023 14:22:03 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "his -> Troy\n",
      "his -> Duffy\n",
      "his -> Duffy\n",
      "his -> Duffy\n",
      "he -> Duffy\n",
      "his -> Duffy\n",
      "him -> Duffy\n",
      "his -> Duffy\n",
      "he -> Duffy\n",
      "his -> Weinstein\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 60.10 examples/s]\n",
      "12/15/2023 14:22:03 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00,  4.99it/s]\n",
      "12/15/2023 14:22:04 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "her -> a woman\n",
      "her -> her,\n",
      "she -> her,\n",
      "him -> the boy\n",
      "him -> the boy\n",
      "his -> the boy\n",
      "he -> the boy\n",
      "he -> the boy\n",
      "his -> the boy\n",
      "him -> the boy\n",
      "he -> the boy\n",
      "he -> the boy\n",
      "he -> the boy\n",
      "his -> the boy\n",
      "his -> the boy\n",
      "She -> The mother\n",
      "her -> The mother\n",
      "they -> our\n",
      "them -> our\n",
      "They -> our\n",
      "they -> our\n",
      "their -> our\n",
      "their -> our\n",
      "their -> our\n",
      "Their -> our\n",
      "They -> our\n",
      "they -> our\n",
      "him -> Juxian\n",
      "his -> Juxian\n",
      "he -> her,\n",
      "her -> her,\n",
      "She -> her,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 31.04 examples/s]\n",
      "12/15/2023 14:22:04 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00,  5.31it/s]\n",
      "12/15/2023 14:22:04 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "He -> Nash\n",
      "his -> Nash\n",
      "his -> Chou\n",
      "his -> Keane\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 57.75 examples/s]\n",
      "12/15/2023 14:22:04 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 10.72it/s]\n",
      "12/15/2023 14:22:04 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "her -> Shivani\n",
      "his -> Arjun\n",
      "his -> Arjun\n",
      "he -> Kishan\n",
      "he -> Kishan\n",
      "him -> kishan\n",
      "him -> kishan\n",
      "him -> kishan\n",
      "he -> kishan\n",
      "he -> kishan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 149.69 examples/s]\n",
      "12/15/2023 14:22:04 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 31.16it/s]\n",
      "12/15/2023 14:22:05 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "He -> Raj Kumar\n",
      "his -> Raj Kumar\n",
      "he -> Raj\n",
      "his -> Raj\n",
      "him -> Raj\n",
      "his -> Raj\n",
      "He -> Raj\n",
      "his -> Raj\n",
      "his -> Raj\n",
      "his -> Raj\n",
      "he -> Raj\n",
      "his -> Ramnath\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<?, ? examples/s]\n",
      "12/15/2023 14:22:05 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 99.97it/s]\n",
      "12/15/2023 14:22:05 - INFO - \t Tokenize 1 inputs...\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 159.35 examples/s]\n",
      "12/15/2023 14:22:05 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 45.42it/s]\n",
      "12/15/2023 14:22:05 - INFO - \t Tokenize 1 inputs...\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 63.58 examples/s]\n",
      "12/15/2023 14:22:05 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 20.89it/s]\n",
      "12/15/2023 14:22:05 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "his -> David\n",
      "him -> David\n",
      "him -> David\n",
      "he -> David\n",
      "his -> David\n",
      "he -> David\n",
      "his -> David\n",
      "he -> David\n",
      "he -> David\n",
      "he -> David\n",
      "his -> David\n",
      "he -> David\n",
      "his -> David\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<?, ? examples/s]\n",
      "12/15/2023 14:22:05 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 32.94it/s]\n",
      "12/15/2023 14:22:05 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "his -> Harry\n",
      "his -> Harry\n",
      "Her -> Ethel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<?, ? examples/s]\n",
      "12/15/2023 14:22:05 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 45.19it/s]\n",
      "12/15/2023 14:22:05 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "his -> Pierce\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 83.11 examples/s]\n",
      "12/15/2023 14:22:05 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.90it/s]\n",
      "12/15/2023 14:22:05 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "he -> Bernie\n",
      "He -> Bernie\n",
      "his -> Bernie\n",
      "he -> Bernie\n",
      "he -> Bernie\n",
      "he -> Bernie\n",
      "his -> Bernie\n",
      "he -> Bernie\n",
      "She -> Liz\n",
      "her -> Liz\n",
      "she -> Liz\n",
      "her -> Liz\n",
      "her -> Liz\n",
      "her -> Liz\n",
      "she -> Liz\n",
      "her -> Liz\n",
      "she -> Liz\n",
      "her -> her,\n",
      "her -> her,\n",
      "she -> Jane\n",
      "her -> Jane\n",
      "she -> Jane\n",
      "she -> Jane\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 94.90 examples/s]\n",
      "12/15/2023 14:22:05 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 30.48it/s]\n",
      "12/15/2023 14:22:05 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "his -> Day\n",
      "his -> Day\n",
      "his -> Day\n",
      "his -> Day\n",
      "him -> Day\n",
      "his -> Day\n",
      "He -> Day\n",
      "he -> Day\n",
      "his -> Day\n",
      "his -> Day\n",
      "he -> Day\n",
      "his -> Day\n",
      "he -> Day\n",
      "his -> Day\n",
      "his -> Day\n",
      "his -> Day\n",
      "she -> her,\n",
      "her -> her,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 62.77 examples/s]\n",
      "12/15/2023 14:22:05 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "his -> Jordan\n",
      "his -> Jordan\n",
      "He -> Jordan\n",
      "him -> Jordan\n",
      "his -> Jordan\n",
      "He -> Jordan\n",
      "he -> Jordan\n",
      "He -> Michael\n",
      "his -> Michael\n",
      "his -> Michael\n",
      "he -> Michael Jordan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12/15/2023 14:22:05 - INFO - \t Tokenize 1 inputs...\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 82.20 examples/s]\n",
      "12/15/2023 14:22:05 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 22.19it/s]\n",
      "12/15/2023 14:22:05 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "his -> Butch\n",
      "him -> Butch\n",
      "him -> Butch\n",
      "He -> Butch\n",
      "he -> Butch\n",
      "his -> Butch\n",
      "He -> Butch\n",
      "his -> Butch\n",
      "his -> Butch\n",
      "his -> Butch\n",
      "his -> Butch\n",
      "he -> Butch's\n",
      "he -> Butch\n",
      "he -> Jerry\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 142.45 examples/s]\n",
      "12/15/2023 14:22:05 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 19.43it/s]\n",
      "12/15/2023 14:22:06 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "his -> Jake\n",
      "his -> Tex\n",
      "he -> Tex\n",
      "he -> Tex\n",
      "He -> Tex\n",
      "he -> Tex\n",
      "his -> Dizzy\n",
      "he -> Dizzy\n",
      "him -> Dizzy\n",
      "him -> Dizzy\n",
      "he -> Dizzy\n",
      "he -> Dizzy\n",
      "him -> Dizzy\n",
      "He -> Dizzy\n",
      "his -> Dizzy\n",
      "he -> Dizzy\n",
      "he -> Dizzy\n",
      "He -> Dizzy\n",
      "his -> the man\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 356.08 examples/s]\n",
      "12/15/2023 14:22:06 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 41.51it/s]\n",
      "12/15/2023 14:22:06 - INFO - \t Tokenize 1 inputs...\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 62.53 examples/s]\n",
      "12/15/2023 14:22:06 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.05it/s]\n",
      "12/15/2023 14:22:06 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "his -> Diwan\n",
      "him -> Diwan\n",
      "her -> Chitralekha\n",
      "She -> Chitralekha\n",
      "her -> Chitralekha\n",
      "she -> Chitralekha\n",
      "her -> Chitralekha\n",
      "her -> Chitralekha\n",
      "she -> Vasanthi\n",
      "her -> Vasanthi\n",
      "she -> Chitralekha\n",
      "Her -> Chitralekha\n",
      "he -> Bharath\n",
      "him -> Bharath\n",
      "his -> Bharath\n",
      "he -> Bharath\n",
      "his -> Bharath\n",
      "his -> Anand\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 189.86 examples/s]\n",
      "12/15/2023 14:22:06 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 78.43it/s]\n",
      "12/15/2023 14:22:06 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Her -> Melissa Peyser\n",
      "he -> Peyser\n",
      "he -> Peyser\n",
      "he -> Steve Tobias\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<?, ? examples/s]\n",
      "12/15/2023 14:22:06 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 71.12it/s]\n",
      "12/15/2023 14:22:06 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "he -> Thara\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<?, ? examples/s]\n",
      "12/15/2023 14:22:06 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 54.46it/s]\n",
      "12/15/2023 14:22:06 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "his -> Rahul\n",
      "his -> Rahul\n",
      "his -> Rahul\n",
      "his -> Rahul\n",
      "she -> Pooja's\n",
      "her -> Pooja's\n",
      "she -> Pooja\n",
      "her -> Pooja's\n",
      "she -> Pooja\n",
      "she -> Pooja\n",
      "Her -> Pooja\n",
      "her -> Pooja\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 241.86 examples/s]\n",
      "12/15/2023 14:22:06 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 36.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "His -> Rama Chandra\n",
      "his -> Rama Chandra\n",
      "him -> Rama Chandra\n",
      "He -> Rama Chandra\n",
      "he -> Rama Chandra\n",
      "his -> Rama Chandra\n",
      "him -> Rama Chandra\n",
      "his -> Rama Chandra\n",
      "his -> Rama Chandra\n",
      "his -> Rama Chandra\n",
      "his -> Rama Chandra\n",
      "She -> Maya\n",
      "her -> Maya\n",
      "her -> Maya\n",
      "she -> Maya\n",
      "her -> Maya\n",
      "her -> Maya\n",
      "his -> Panda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12/15/2023 14:22:06 - INFO - \t Tokenize 1 inputs...\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 71.33 examples/s]\n",
      "12/15/2023 14:22:06 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 10.94it/s]\n",
      "12/15/2023 14:22:06 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "his -> Derek\n",
      "his -> Derek\n",
      "him -> Derek\n",
      "his -> Derek\n",
      "he -> Derek\n",
      "he -> Derek\n",
      "he -> Derek\n",
      "he -> Derek\n",
      "his -> Derek\n",
      "him -> Derek\n",
      "his -> Derek\n",
      "his -> Derek\n",
      "his -> Mugatu\n",
      "him -> Mugatu\n",
      "her -> Matilda\n",
      "her -> Matilda\n",
      "he -> Hansel\n",
      "he -> Maury\n",
      "his -> Maury\n",
      "his -> Larry\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<?, ? examples/s]\n",
      "12/15/2023 14:22:06 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 44.47it/s]\n",
      "12/15/2023 14:22:06 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "him -> Marc\n",
      "he -> Marc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<?, ? examples/s]\n",
      "12/15/2023 14:22:06 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 21.42it/s]\n",
      "12/15/2023 14:22:07 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "she -> Pari\n",
      "she -> Pari\n",
      "her -> Pari's\n",
      "her -> Pari's\n",
      "He -> Pari's\n",
      "he -> Rishabh\n",
      "he -> Rishabh\n",
      "he -> Rishabh\n",
      "he -> Rishabh\n",
      "he -> Rishabh\n",
      "He -> Rishabh\n",
      "he -> Rishabh\n",
      "her -> Dhani\n",
      "her -> Dhani\n",
      "she -> Dhani\n",
      "her -> Dhani\n",
      "she -> Dhani\n",
      "her -> Dhani\n",
      "her -> Dhani\n",
      "she -> her,\n",
      "she -> her,\n",
      "She -> her,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<?, ? examples/s]\n",
      "12/15/2023 14:22:07 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 42.69it/s]\n",
      "12/15/2023 14:22:07 - INFO - \t Tokenize 1 inputs...\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 63.62 examples/s]\n",
      "12/15/2023 14:22:07 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 59.00it/s]\n",
      "12/15/2023 14:22:07 - INFO - \t Tokenize 1 inputs...\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 64.00 examples/s]\n",
      "12/15/2023 14:22:07 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 64.04it/s]\n",
      "12/15/2023 14:22:07 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "his -> Aladdin\n",
      "they -> the gang\n",
      "their -> the gang\n",
      "his -> Stymie\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 63.94 examples/s]\n",
      "12/15/2023 14:22:07 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "He -> SpongeBob\n",
      "his -> SpongeBob\n",
      "His -> SpongeBob\n",
      "him -> SpongeBob\n",
      "he -> SpongeBob\n",
      "he -> SpongeBob\n",
      "his -> SpongeBob\n",
      "he -> SpongeBob\n",
      "his -> SpongeBob\n",
      "his -> SpongeBob\n",
      "He -> SpongeBob\n",
      "his -> SpongeBob\n",
      "his -> SpongeBob\n",
      "He -> SpongeBob\n",
      "he -> SpongeBob\n",
      "his -> SpongeBob\n",
      "he -> SpongeBob\n",
      "his -> SpongeBob\n",
      "he -> SpongeBob\n",
      "He -> SpongeBob\n",
      "he -> SpongeBob\n",
      "he -> SpongeBob\n",
      "he -> SpongeBob\n",
      "his -> SpongeBob\n",
      "his -> SpongeBob\n",
      "he -> SpongeBob\n",
      "he -> SpongeBob\n",
      "he -> SpongeBob\n",
      "he -> SpongeBob\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "12/15/2023 14:22:07 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "He -> Plankton\n",
      "he -> Plankton\n",
      "him -> Plankton\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 73.99 examples/s]\n",
      "12/15/2023 14:22:07 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 19.21it/s]\n",
      "12/15/2023 14:22:07 - INFO - \t Tokenize 1 inputs...\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 83.25 examples/s]\n",
      "12/15/2023 14:22:07 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 20.02it/s]\n",
      "12/15/2023 14:22:07 - INFO - \t Tokenize 1 inputs...\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 83.23 examples/s]\n",
      "12/15/2023 14:22:07 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 42.29it/s]\n",
      "12/15/2023 14:22:07 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "He -> Shiva\n",
      "he -> Shiva\n",
      "his -> Shiva\n",
      "his -> Shiva\n",
      "he -> Shiva\n",
      "his -> Shiva\n",
      "his -> Shiva\n",
      "he -> Shiva\n",
      "his -> Shiva\n",
      "He -> Shiva\n",
      "his -> Shiva\n",
      "his -> Shiva\n",
      "His -> Shiva\n",
      "her -> Priya\n",
      "his -> Mayandi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 64.00 examples/s]\n",
      "12/15/2023 14:22:07 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 51.47it/s]\n",
      "12/15/2023 14:22:07 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "his -> Dave Stewie\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 63.93 examples/s]\n",
      "12/15/2023 14:22:07 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00,  9.85it/s]\n",
      "12/15/2023 14:22:08 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "his -> Natha\n",
      "his -> Natha\n",
      "his -> Natha\n",
      "he -> Natha\n",
      "him -> Natha\n",
      "his -> Natha\n",
      "his -> Natha\n",
      "his -> Natha\n",
      "his -> Natha\n",
      "him -> Natha\n",
      "His -> Natha\n",
      "their -> the family\n",
      "their -> the family\n",
      "they -> its\n",
      "their -> its\n",
      "their -> each\n",
      "his -> Deepak\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 61.78 examples/s]\n",
      "12/15/2023 14:22:08 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 34.52it/s]\n",
      "12/15/2023 14:22:08 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "He -> Suraj\n",
      "his -> Suraj\n",
      "he -> Suraj\n",
      "he -> Suraj\n",
      "he -> Suraj\n",
      "his -> Suraj\n",
      "his -> Suraj\n",
      "he -> Naved Ali\n",
      "his -> Naved Ali\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<?, ? examples/s]\n",
      "12/15/2023 14:22:08 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 16.46it/s]\n",
      "12/15/2023 14:22:08 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "her -> Lena\n",
      "she -> her,\n",
      "her -> her,\n",
      "She -> her,\n",
      "she -> Lena\n",
      "she -> Lena\n",
      "She -> Lena\n",
      "she -> Lena\n",
      "She -> Lena\n",
      "her -> Lena\n",
      "she -> Lena\n",
      "his -> Bill\n",
      "him -> Bill\n",
      "his -> Bill\n",
      "his -> Bill\n",
      "him -> Bill\n",
      "him -> Bill\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<?, ? examples/s]\n",
      "12/15/2023 14:22:08 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.62it/s]\n",
      "12/15/2023 14:22:08 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "his -> Kusaka\n",
      "he -> Kusaka\n",
      "him -> Kusaka\n",
      "his -> Kusaka\n",
      "his -> Kusaka\n",
      "his -> Kusaka\n",
      "his -> Kusaka\n",
      "him -> Kusaka\n",
      "his -> Kusaka\n",
      "his -> Kusaka\n",
      "his -> Kusaka\n",
      "he -> Kusaka\n",
      "his -> Kusaka\n",
      "he -> Kusaka\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 57.60 examples/s]\n",
      "12/15/2023 14:22:08 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 17.67it/s]\n",
      "12/15/2023 14:22:08 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "him -> Nikhil Chopra\n",
      "his -> Nikhil Chopra\n",
      "he -> Nikhil Chopra\n",
      "he -> Nikhil Chopra\n",
      "he -> Nikhil Chopra\n",
      "He -> Nikhil Chopra\n",
      "he -> Nikhil Chopra\n",
      "he -> Nikhil Chopra\n",
      "he -> Nikhil\n",
      "he -> Nikhil\n",
      "he -> Nikhil\n",
      "he -> Nikhil\n",
      "he -> Nikhil\n",
      "he -> Nikhil\n",
      "his -> Nikhil\n",
      "him -> Nikhil\n",
      "his -> Nikhil\n",
      "him -> Nikhil\n",
      "his -> Nikhil\n",
      "his -> Nikhil\n",
      "he -> Nikhil\n",
      "he -> Nikhil\n",
      "He -> Nikhil\n",
      "his -> Nikhil\n",
      "She -> Lalitha\n",
      "her -> Lalitha\n",
      "her -> Lalitha\n",
      "she -> Lalitha\n",
      "She -> Lalitha\n",
      "her -> Lalitha\n",
      "she -> her,\n",
      "her -> Lalitha\n",
      "she -> Lalitha\n",
      "she -> Lalitha\n",
      "she -> Lalitha\n",
      "her -> Lalitha\n",
      "her -> Lalitha\n",
      "She -> Lalitha\n",
      "she -> her,\n",
      "she -> Lalitha\n",
      "her -> Lalitha\n",
      "her -> Lalitha's\n",
      "she -> her,\n",
      "her -> Lalitha\n",
      "her -> Lalitha\n",
      "her -> Lalitha\n",
      "her -> Lalitha\n",
      "her -> Lalitha\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<?, ? examples/s]\n",
      "12/15/2023 14:22:08 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 18.10it/s]\n",
      "12/15/2023 14:22:08 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "her -> Fonda\n",
      "he -> Robinson\n",
      "his -> Robinson\n",
      "his -> Robinson\n",
      "he -> Robinson\n",
      "they -> people\n",
      "they -> people\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<?, ? examples/s]\n",
      "12/15/2023 14:22:08 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 16.24it/s]\n",
      "12/15/2023 14:22:08 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "his -> Luke\n",
      "him -> Luke\n",
      "he -> Luke\n",
      "he -> Luke\n",
      "him -> Luke\n",
      "his -> Luke\n",
      "his -> Luke\n",
      "he -> Luke's\n",
      "their -> most\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 125.01 examples/s]\n",
      "12/15/2023 14:22:08 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "She -> Batwoman\n",
      "her -> Batwoman\n",
      "she -> Batwoman\n",
      "her -> Batwoman\n",
      "his -> the driver\n",
      "he -> Batman\n",
      "his -> Bruce\n",
      "her -> Kathy\n",
      "She -> Kathy\n",
      "she -> Kathy\n",
      "her -> Kathy\n",
      "she -> Sonia\n",
      "her -> Sonia\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "12/15/2023 14:22:09 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "he -> Batman\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 124.99 examples/s]\n",
      "12/15/2023 14:22:09 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 41.66it/s]\n",
      "12/15/2023 14:22:09 - INFO - \t Tokenize 1 inputs...\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 124.89 examples/s]\n",
      "12/15/2023 14:22:09 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 64.17it/s]\n",
      "12/15/2023 14:22:09 - INFO - \t Tokenize 1 inputs...\n",
      "Map: 100%|██████████| 1/1 [00:00<?, ? examples/s]\n",
      "12/15/2023 14:22:09 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 21.30it/s]\n",
      "12/15/2023 14:22:09 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "She -> Pooja Dharamchand\n",
      "her -> Pooja Dharamchand\n",
      "her -> Pooja\n",
      "her -> Pooja\n",
      "her -> Pooja\n",
      "her -> Pooja\n",
      "she -> Pooja\n",
      "her -> Pooja\n",
      "her -> Pooja\n",
      "she -> Pooja\n",
      "her -> Pooja\n",
      "her -> Pooja\n",
      "She -> Pooja\n",
      "her -> Pooja\n",
      "her -> Pooja\n",
      "her -> Pooja\n",
      "her -> Pooja\n",
      "she -> Pooja\n",
      "her -> Pooja\n",
      "he -> Raghu\n",
      "He -> Raghu\n",
      "he -> Raghu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 125.13 examples/s]\n",
      "12/15/2023 14:22:09 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 31.18it/s]\n",
      "12/15/2023 14:22:09 - INFO - \t Tokenize 1 inputs...\n",
      "Map: 100%|██████████| 1/1 [00:00<?, ? examples/s]\n",
      "12/15/2023 14:22:09 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 62.49it/s]\n",
      "12/15/2023 14:22:09 - INFO - \t Tokenize 1 inputs...\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 180.36 examples/s]\n",
      "12/15/2023 14:22:09 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.00it/s]\n",
      "12/15/2023 14:22:09 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "her -> Jean\n",
      "she -> Jean\n",
      "her -> Jean\n",
      "her -> Jean\n",
      "she -> Jean\n",
      "her -> Jean\n",
      "she -> Jean\n",
      "their -> the gang\n",
      "they -> the gang\n",
      "his -> Jimmy\n",
      "his -> Jimmy\n",
      "his -> Jimmy\n",
      "her -> Shirley,\n",
      "he -> Eddie\n",
      "his -> Eddie\n",
      "he -> Eddie\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 117.06 examples/s]\n",
      "12/15/2023 14:22:09 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 15.57it/s]\n",
      "12/15/2023 14:22:09 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "he -> Creed\n",
      "he -> Creed\n",
      "He -> Creed\n",
      "him -> Apollo Creed\n",
      "his -> Creed\n",
      "his -> Creed\n",
      "his -> Rocky's\n",
      "him -> Rocky's\n",
      "he -> Rocky's\n",
      "him -> Rocky's\n",
      "his -> Rocky\n",
      "him -> Rocky's\n",
      "his -> Rocky's\n",
      "He -> Rocky\n",
      "he -> Rocky\n",
      "he -> Rocky\n",
      "his -> Rocky\n",
      "her -> Adrian\n",
      "she -> Adrian\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<?, ? examples/s]\n",
      "12/15/2023 14:22:09 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 40.09it/s]\n",
      "12/15/2023 14:22:09 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "he -> O'Malley\n",
      "him -> O'Malley\n",
      "his -> O'Malley\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 64.00 examples/s]\n",
      "12/15/2023 14:22:09 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 21.39it/s]\n",
      "12/15/2023 14:22:09 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "her -> M'Lynn\n",
      "her -> M'Lynn\n",
      "her -> M'Lynn\n",
      "her -> Shelby\n",
      "she -> Shelby\n",
      "her -> Shelby\n",
      "her -> Shelby\n",
      "she -> Shelby\n",
      "her -> Shelby\n",
      "his -> Jackson\n",
      "she -> Annelle\n",
      "her -> Annelle\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 124.98 examples/s]\n",
      "12/15/2023 14:22:09 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 62.21it/s]\n",
      "12/15/2023 14:22:09 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "him -> Eddie\n",
      "He -> Eddie\n",
      "his -> Eddie\n",
      "his -> Eddie\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 125.18 examples/s]\n",
      "12/15/2023 14:22:10 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 17.91it/s]\n",
      "12/15/2023 14:22:10 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "him -> Charlie Brown\n",
      "he -> Charlie Brown\n",
      "his -> Charlie Brown\n",
      "his -> Charlie Brown\n",
      "his -> Schroeder\n",
      "his -> Schroeder\n",
      "his -> Linus\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 99.31 examples/s]\n",
      "12/15/2023 14:22:10 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 41.62it/s]\n",
      "12/15/2023 14:22:10 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "his -> Javier\n",
      "he -> Javier\n",
      "he -> Javier\n",
      "him -> Javier\n",
      "his -> Javier\n",
      "he -> Javier\n",
      "he -> Javier\n",
      "he -> Javier\n",
      "He -> Javier\n",
      "him -> Javier\n",
      "him -> Javier\n",
      "he -> Javier\n",
      "he -> Javier\n",
      "she -> María\n",
      "she -> María\n",
      "She -> María\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 41.66 examples/s]\n",
      "12/15/2023 14:22:10 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00,  2.82it/s]\n",
      "12/15/2023 14:22:10 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "him -> Caligula\n",
      "him -> Caligula\n",
      "he -> Caligula\n",
      "his -> Caligula\n",
      "his -> Caligula\n",
      "him -> Caligula\n",
      "his -> Caligula\n",
      "he -> Caligula\n",
      "He -> Caligula\n",
      "his -> Caligula\n",
      "his -> Caligula\n",
      "she -> Caligula\n",
      "her -> Caligula\n",
      "his -> Caligula\n",
      "she -> Diana\n",
      "her -> Diana\n",
      "her -> Diana\n",
      "her -> Diana\n",
      "her -> Diana\n",
      "her -> Diana's\n",
      "her -> Diana\n",
      "her -> Diana\n",
      "her -> Diana\n",
      "she -> Diana\n",
      "her -> Diana\n",
      "her -> Diana\n",
      "her -> Diana\n",
      "she -> Diana\n",
      "she -> Diana\n",
      "she -> Diana\n",
      "she -> Diana\n",
      "her -> Diana\n",
      "she -> her,\n",
      "her -> her,\n",
      "He -> Marcellus\n",
      "he -> Marcellus\n",
      "he -> Marcellus\n",
      "he -> Marcellus\n",
      "him -> Marcellus\n",
      "he -> Marcellus\n",
      "his -> Marcellus\n",
      "him -> Marcellus\n",
      "his -> Marcellus\n",
      "his -> Marcellus\n",
      "him -> Marcellus\n",
      "He -> Marcellus\n",
      "He -> Marcellus\n",
      "him -> Marcellus\n",
      "He -> Marcellus\n",
      "his -> Marcellus\n",
      "his -> Marcellus\n",
      "his -> Marcellus\n",
      "his -> Marcellus\n",
      "he -> Marcellus\n",
      "him -> Marcellus\n",
      "his -> Marcellus\n",
      "he -> Marcellus\n",
      "He -> Marcellus\n",
      "he -> Marcellus\n",
      "he -> Marcellus\n",
      "him -> Marcellus\n",
      "he -> Marcellus\n",
      "He -> Marcellus\n",
      "his -> Marcellus\n",
      "him -> Marcellus\n",
      "his -> Marcellus\n",
      "He -> Marcellus\n",
      "him -> Marcellus\n",
      "he -> Marcellus\n",
      "he -> Marcellus\n",
      "his -> Marcellus\n",
      "him -> Marcellus\n",
      "him -> Marcellus\n",
      "his -> Marcellus\n",
      "his -> Marcellus\n",
      "his -> Marcellus\n",
      "his -> Marcellus\n",
      "he -> Marcellus\n",
      "his -> Marcellus\n",
      "his -> Marcellus\n",
      "he -> Marcellus\n",
      "He -> Marcellus\n",
      "his -> Marcellus\n",
      "he -> Marcellus\n",
      "he -> Marcellus\n",
      "he -> Marcellus\n",
      "his -> Marcellus\n",
      "he -> Marcellus\n",
      "he -> Marcellus\n",
      "him -> Marcellus\n",
      "his -> Marcellus\n",
      "his -> Marcellus\n",
      "his -> Marcellus\n",
      "he -> Marcellus\n",
      "he -> Marcellus\n",
      "he -> Marcellus\n",
      "his -> Marcellus\n",
      "His -> Marcellus\n",
      "his -> Tiberius\n",
      "he -> Tiberius\n",
      "him -> Tiberius\n",
      "He -> Tiberias\n",
      "him -> Tiberias\n",
      "He -> Tiberias\n",
      "He -> Tiberias\n",
      "him -> Demetrius\n",
      "he -> Demetrius\n",
      "his -> Demetrius\n",
      "him -> Demetrius\n",
      "his -> Demetrius\n",
      "he -> Demetrius\n",
      "him -> Demetrius\n",
      "his -> Demetrius\n",
      "he -> Demetrius\n",
      "him -> Demetrius\n",
      "he -> Demetrius\n",
      "he -> Demetrius\n",
      "he -> Demetrius\n",
      "him -> Demetrius\n",
      "him -> Demetrius\n",
      "he -> Demetrius\n",
      "he -> Demetrius\n",
      "he -> Demetrius\n",
      "he -> Demetrius\n",
      "he -> Demetrius\n",
      "him -> Demetrius\n",
      "he -> Demetrius\n",
      "he -> Demetrius\n",
      "his -> Demetrius\n",
      "he -> Demetrius\n",
      "his -> Jesus\n",
      "His -> Jesus\n",
      "his -> Pilate\n",
      "he -> Pilate\n",
      "he -> Pilate\n",
      "his -> Pilate\n",
      "his -> Jonathan\n",
      "his -> Jonathan\n",
      "he -> Jonathan\n",
      "his -> Peter\n",
      "him -> Peter\n",
      "his -> Peter\n",
      "him -> Paulus\n",
      "his -> Paulus\n",
      "he -> Paulus\n",
      "his -> Paulus\n",
      "his -> Paulus\n",
      "him -> Paulus\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 124.97 examples/s]\n",
      "12/15/2023 14:22:10 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 15.46it/s]\n",
      "12/15/2023 14:22:10 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "his -> Viswanathan\n",
      "his -> Viswanathan\n",
      "his -> Viswanathan\n",
      "He -> Viswanathan\n",
      "his -> Viswanathan\n",
      "he -> Viswanathan\n",
      "He -> Viswanathan\n",
      "his -> Viswanathan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 124.99 examples/s]\n",
      "12/15/2023 14:22:10 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 17.56it/s]\n",
      "12/15/2023 14:22:10 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "his -> Ryu\n",
      "he -> Ryu\n",
      "his -> Ryu\n",
      "his -> Ryu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 172.29 examples/s]\n",
      "12/15/2023 14:22:11 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.31it/s]\n",
      "12/15/2023 14:22:11 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "he -> Leo\n",
      "he -> Leo\n",
      "he -> Leo\n",
      "he -> Leo\n",
      "him -> Jesus\n",
      "his -> Jesus\n",
      "his -> Jesus\n",
      "his -> Brody\n",
      "his -> Shavoo\n",
      "he -> Shavoo\n",
      "He -> Shavoo\n",
      "his -> Shavoo\n",
      "his -> Bodega\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 110.02 examples/s]\n",
      "12/15/2023 14:22:11 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.05it/s]\n",
      "12/15/2023 14:22:11 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "his -> Bhanu\n",
      "his -> Bhanu\n",
      "his -> Gandadu\n",
      "he -> Gandadu\n",
      "his -> Gandadu\n",
      "He -> Gandadu\n",
      "his -> Gandadu\n",
      "his -> Gandadu\n",
      "They -> its\n",
      "they -> its\n",
      "they -> its\n",
      "he -> Bahadur\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 124.78 examples/s]\n",
      "12/15/2023 14:22:11 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 41.56it/s]\n",
      "12/15/2023 14:22:11 - INFO - \t Tokenize 1 inputs...\n",
      "Map: 100%|██████████| 1/1 [00:00<?, ? examples/s]\n",
      "12/15/2023 14:22:11 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 62.51it/s]\n",
      "12/15/2023 14:22:11 - INFO - \t Tokenize 1 inputs...\n",
      "Map: 100%|██████████| 1/1 [00:00<?, ? examples/s]\n",
      "12/15/2023 14:22:11 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 62.49it/s]\n",
      "12/15/2023 14:22:11 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "his -> surya\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 125.08 examples/s]\n",
      "12/15/2023 14:22:11 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 45.35it/s]\n",
      "12/15/2023 14:22:11 - INFO - \t Tokenize 1 inputs...\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 63.94 examples/s]\n",
      "12/15/2023 14:22:11 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 49.67it/s]\n",
      "12/15/2023 14:22:11 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "He -> Ravi Verma\n",
      "him -> Ravi Verma\n",
      "his -> Ravi Verma\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<?, ? examples/s]\n",
      "12/15/2023 14:22:11 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 17.11it/s]\n",
      "12/15/2023 14:22:11 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "her -> Aaliya\n",
      "Her -> Aaliya\n",
      "her -> Aaliya\n",
      "her -> Aaliya\n",
      "she -> Aaliya\n",
      "She -> Aaliya\n",
      "she -> Aaliya\n",
      "her -> Aaliya\n",
      "She -> Aaliya\n",
      "she -> Aaliya\n",
      "her -> Aaliya\n",
      "her -> Aaliya\n",
      "she -> Aaliya\n",
      "she -> Aaliya\n",
      "she -> Aaliya\n",
      "her -> Aaliya\n",
      "her -> Aaliya\n",
      "her -> Aaliya\n",
      "her -> Aaliya\n",
      "her -> Aaliya\n",
      "her -> Aaliya\n",
      "her -> Aaliya\n",
      "she -> Aaliya\n",
      "her -> Aaliya\n",
      "her -> Aaliya\n",
      "she -> Aaliya\n",
      "her -> Aaliya\n",
      "her -> Aaliya\n",
      "She -> Aaliya\n",
      "her -> Aaliya\n",
      "she -> Aaliya\n",
      "her -> Aaliya\n",
      "her -> Aaliya\n",
      "her -> Aaliya\n",
      "She -> Aaliya\n",
      "his -> Abhay\n",
      "him -> Abhay\n",
      "his -> Abhay\n",
      "he -> Abhay\n",
      "he -> Abhay\n",
      "him -> Abhay\n",
      "he -> Abhay\n",
      "him -> Abhay's\n",
      "him -> Abhay's\n",
      "his -> Abhay's\n",
      "him -> Abhay's\n",
      "he -> Abhay's\n",
      "him -> Abhay's\n",
      "him -> Abhay's\n",
      "his -> Abhay's\n",
      "he -> Abhay's\n",
      "his -> Abhay's father\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 63.99 examples/s]\n",
      "12/15/2023 14:22:11 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 38.74it/s]\n",
      "12/15/2023 14:22:11 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "his -> Lem\n",
      "he -> Lem\n",
      "he -> Lem\n",
      "his -> Lem\n",
      "he -> Lem\n",
      "he -> Lem\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 121.22 examples/s]\n",
      "12/15/2023 14:22:11 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 20.99it/s]\n",
      "12/15/2023 14:22:12 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "he -> Sébastien\n",
      "he -> Sébastien\n",
      "he -> Sébastien\n",
      "he -> Sébastien\n",
      "him -> Sébastien\n",
      "his -> Sébastien\n",
      "him -> Sébastien\n",
      "he -> Sébastien\n",
      "he -> Sébastien\n",
      "he -> Sébastien\n",
      "He -> Sébastien\n",
      "his -> Sébastien\n",
      "his -> Sébastien\n",
      "he -> Sébastien\n",
      "He -> Sébastien\n",
      "he -> Sébastien\n",
      "him -> Sébastien\n",
      "he -> Sébastien\n",
      "his -> Sébastien\n",
      "his -> Godon\n",
      "his -> Godon\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 64.01 examples/s]\n",
      "12/15/2023 14:22:12 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 31.16it/s]\n",
      "12/15/2023 14:22:12 - INFO - \t Tokenize 1 inputs...\n",
      "Map: 100%|██████████| 1/1 [00:00<?, ? examples/s]\n",
      "12/15/2023 14:22:12 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 21.28it/s]\n",
      "12/15/2023 14:22:12 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "she -> her,\n",
      "her -> her,\n",
      "she -> her,\n",
      "her -> her,\n",
      "her -> her,\n",
      "her -> her,\n",
      "she -> her,\n",
      "her -> her,\n",
      "she -> her,\n",
      "her -> her,\n",
      "she -> her,\n",
      "her -> her,\n",
      "she -> her,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 63.96 examples/s]\n",
      "12/15/2023 14:22:12 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 49.28it/s]\n",
      "12/15/2023 14:22:12 - INFO - \t Tokenize 1 inputs...\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 64.00 examples/s]\n",
      "12/15/2023 14:22:12 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00,  9.46it/s]\n",
      "12/15/2023 14:22:12 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "he -> Will Shaw\n",
      "He -> Will Shaw\n",
      "his -> Will Shaw\n",
      "he -> Will\n",
      "his -> Will\n",
      "he -> Will\n",
      "he -> Will\n",
      "He -> Will\n",
      "him -> Will's\n",
      "him -> Will's\n",
      "He -> Will\n",
      "He -> Will\n",
      "he -> Will\n",
      "he -> Will\n",
      "He -> Will\n",
      "his -> Will\n",
      "him -> Will\n",
      "He -> Will\n",
      "he -> Will\n",
      "him -> Will\n",
      "he -> Will\n",
      "his -> Will\n",
      "he -> Will\n",
      "he -> Will\n",
      "his -> Will\n",
      "him -> Will\n",
      "He -> Will\n",
      "his -> Will\n",
      "he -> Will\n",
      "He -> Will\n",
      "his -> Will\n",
      "his -> Will\n",
      "He -> Will\n",
      "he -> Will\n",
      "She -> Will\n",
      "her -> Will\n",
      "she -> Will\n",
      "her -> Will\n",
      "him -> Will\n",
      "he -> Will's\n",
      "he -> Will's\n",
      "him -> Will's\n",
      "his -> Martin\n",
      "his -> Martin's\n",
      "she -> Jean\n",
      "her -> Jean\n",
      "her -> Jean\n",
      "she -> Jean\n",
      "her -> Jean\n",
      "she -> Jean\n",
      "her -> his mother\n",
      "her -> Lucia\n",
      "her -> Lucia\n",
      "she -> Lucia\n",
      "her -> Lucia\n",
      "him -> Gorman\n",
      "him -> Gorman\n",
      "he -> Gorman\n",
      "his -> Gorman\n",
      "He -> Zahir\n",
      "He -> Zahir\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 62.49 examples/s]\n",
      "12/15/2023 14:22:12 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.13it/s]\n",
      "12/15/2023 14:22:12 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "he -> Uranus\n",
      "she -> Athena\n",
      "her -> Athena\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<?, ? examples/s]\n",
      "12/15/2023 14:22:12 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 67.00it/s]\n",
      "12/15/2023 14:22:12 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "she -> Cassie\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 64.00 examples/s]\n",
      "12/15/2023 14:22:12 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.94it/s]\n",
      "12/15/2023 14:22:12 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "her -> her,\n",
      "She -> her,\n",
      "her -> her,\n",
      "her -> her,\n",
      "her -> her,\n",
      "her -> her,\n",
      "her -> her,\n",
      "her -> her,\n",
      "her -> her,\n",
      "her -> her,\n",
      "her -> her,\n",
      "she -> her,\n",
      "her -> her,\n",
      "her -> her,\n",
      "her -> her,\n",
      "she -> her,\n",
      "her -> her,\n",
      "her -> her,\n",
      "her -> her,\n",
      "her -> her,\n",
      "her -> her,\n",
      "she -> her,\n",
      "His -> Renato\n",
      "he -> Renato\n",
      "him -> Renato\n",
      "His -> Renato\n",
      "him -> Renato\n",
      "he -> Renato\n",
      "his -> Renato\n",
      "he -> Renato\n",
      "He -> Renato\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 115.05 examples/s]\n",
      "12/15/2023 14:22:12 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 19.10it/s]\n",
      "12/15/2023 14:22:13 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "her -> Emily\n",
      "her -> Emily\n",
      "her -> Emily\n",
      "her -> Emily\n",
      "her -> her,\n",
      "she -> her,\n",
      "her -> her,\n",
      "her -> her,\n",
      "She -> her,\n",
      "She -> her,\n",
      "her -> her,\n",
      "she -> her,\n",
      "her -> her,\n",
      "she -> Emily,\n",
      "she -> Emily,\n",
      "she -> Emily,\n",
      "her -> Emily,\n",
      "she -> Emily,\n",
      "her -> Emily,\n",
      "her -> Emily,\n",
      "Her -> Emily's\n",
      "her -> Emily's\n",
      "she -> Emily's\n",
      "he -> Philip\n",
      "he -> Philip\n",
      "He -> Philip\n",
      "his -> Philip\n",
      "his -> Philip\n",
      "him -> Philip\n",
      "him -> Philip\n",
      "he -> David\n",
      "him -> David\n",
      "she -> her sister\n",
      "she -> her sister\n",
      "she -> her sister\n",
      "Her -> her sister\n",
      "she -> her sister\n",
      "she -> her sister\n",
      "she -> her sister\n",
      "she -> her sister\n",
      "she -> her sister\n",
      "she -> her sister\n",
      "her -> her sister\n",
      "she -> her sister\n",
      "she -> her sister\n",
      "him -> The driver\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 92.71 examples/s]\n",
      "12/15/2023 14:22:13 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.41it/s]\n",
      "12/15/2023 14:22:13 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "his -> Siddharth\n",
      "He -> Siddharth\n",
      "he -> Siddharth\n",
      "He -> Siddharth\n",
      "his -> Siddharth\n",
      "he -> Siddharth\n",
      "he -> Siddharth\n",
      "he -> Siddharth\n",
      "him -> Siddharth\n",
      "him -> Siddharth\n",
      "her -> Avni\n",
      "him -> Avni\n",
      "her -> Avni\n",
      "her -> Avni\n",
      "she -> Avni\n",
      "he -> the priest\n",
      "she -> Radha\n",
      "He -> Aditya\n",
      "he -> Aditya\n",
      "He -> Aditya\n",
      "her -> Aditya\n",
      "she -> Aditya\n",
      "her -> Aditya\n",
      "him -> Sharad\n",
      "him -> Sharad\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 48.02 examples/s]\n",
      "12/15/2023 14:22:13 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 17.84it/s]\n",
      "12/15/2023 14:22:13 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "his -> Guru\n",
      "his -> Guru\n",
      "his -> Guru\n",
      "him -> guru\n",
      "he -> guru\n",
      "he -> guru\n",
      "He -> guru\n",
      "he -> guru\n",
      "he -> guru\n",
      "he -> Guru\n",
      "him -> Guru\n",
      "He -> Guru\n",
      "him -> Guru\n",
      "him -> Guru\n",
      "he -> Guru\n",
      "his -> Guru\n",
      "his -> Guru\n",
      "he -> Guru\n",
      "his -> Guru\n",
      "he -> Guru\n",
      "her -> her,\n",
      "him -> JP\n",
      "him -> JP\n",
      "him -> JP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 63.94 examples/s]\n",
      "12/15/2023 14:22:13 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.20it/s]\n",
      "12/15/2023 14:22:13 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "he -> Holden\n",
      "his -> Holden\n",
      "his -> Holden\n",
      "him -> Brent\n",
      "he -> Jay\n",
      "him -> Jay\n",
      "her -> Justice\n",
      "he -> Federal Wildlife Marshal Willenholly\n",
      "He -> Federal Wildlife Marshal Willenholly\n",
      "he -> Willenholly\n",
      "he -> Willenholly\n",
      "his -> Willenholly\n",
      "he -> Willenholly\n",
      "their -> these\n",
      "they -> these\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 598.93 examples/s]\n",
      "12/15/2023 14:22:13 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 20.15it/s]\n",
      "12/15/2023 14:22:13 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "their -> its\n",
      "them -> its\n",
      "they -> its\n",
      "they -> its\n",
      "their -> its\n",
      "they -> its\n",
      "their -> its\n",
      "they -> its\n",
      "their -> its\n",
      "she -> Carly\n",
      "she -> Carly\n",
      "her -> Carly\n",
      "her -> Carly\n",
      "his -> Jay\n",
      "his -> Tomas\n",
      "him -> Tomas\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 72.87 examples/s]\n",
      "12/15/2023 14:22:13 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.93it/s]\n",
      "12/15/2023 14:22:14 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "his -> Fish\n",
      "his -> Fish\n",
      "his -> Fish\n",
      "he -> Fish\n",
      "his -> Fish\n",
      "his -> Fish\n",
      "he -> Fish\n",
      "his -> Fish\n",
      "he -> Fish\n",
      "his -> Fish\n",
      "he -> Fish\n",
      "his -> Fish\n",
      "him -> Fish\n",
      "he -> Fish\n",
      "his -> Fish\n",
      "his -> Fish\n",
      "him -> Fish\n",
      "he -> Fish\n",
      "he -> Fish\n",
      "his -> Fish\n",
      "his -> Fish\n",
      "he -> Fish\n",
      "their -> The band\n",
      "they -> The band\n",
      "They -> The band\n",
      "their -> The band\n",
      "them -> The band\n",
      "they -> The band\n",
      "their -> The band\n",
      "their -> The band\n",
      "their -> The band\n",
      "their -> The band\n",
      "their -> The band\n",
      "their -> The band\n",
      "they -> The band\n",
      "they -> The band\n",
      "he -> Curtis\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<?, ? examples/s]\n",
      "12/15/2023 14:22:14 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 57.26it/s]\n",
      "12/15/2023 14:22:14 - INFO - \t Tokenize 1 inputs...\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 62.50 examples/s]\n",
      "12/15/2023 14:22:14 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.75it/s]\n",
      "12/15/2023 14:22:14 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "her -> Vanessa\n",
      "her -> Vanessa's\n",
      "her -> Vanessa\n",
      "her -> Vanessa\n",
      "she -> Vanessa\n",
      "her -> Vanessa's\n",
      "her -> Vanessa's\n",
      "she -> Vanessa's\n",
      "her -> Vanessa\n",
      "her -> Vanessa\n",
      "her -> Vanessa's\n",
      "her -> Vanessa\n",
      "she -> Vanessa\n",
      "her -> Stacy\n",
      "her -> Stacy\n",
      "her -> Stacy\n",
      "her -> Stacy\n",
      "She -> Emily\n",
      "she -> Barbara\n",
      "her -> Barbara\n",
      "she -> Barbara\n",
      "she -> Barbara\n",
      "her -> Barbara\n",
      "She -> Barbara\n",
      "she -> Barbara\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 64.05 examples/s]\n",
      "12/15/2023 14:22:14 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 33.26it/s]\n",
      "12/15/2023 14:22:14 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "his -> Samson's\n",
      "his -> Samson\n",
      "his -> Samson\n",
      "him -> Samson\n",
      "his -> Samson\n",
      "he -> Samson\n",
      "his -> Samson\n",
      "his -> Samson\n",
      "his -> Samson\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 124.98 examples/s]\n",
      "12/15/2023 14:22:14 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 41.58it/s]\n",
      "12/15/2023 14:22:14 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "he -> Fred\n",
      "him -> Fred\n",
      "He -> Fred\n",
      "his -> Fred\n",
      "him -> Fred\n",
      "He -> Fred\n",
      "his -> Fred\n",
      "He -> Fred\n",
      "him -> Fred\n",
      "him -> Fred\n",
      "he -> Fred\n",
      "She -> Pamela\n",
      "her -> Pamela\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 137.28 examples/s]\n",
      "12/15/2023 14:22:14 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 62.48it/s]\n",
      "12/15/2023 14:22:14 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "his -> Yuan\n",
      "he -> Yuan\n",
      "his -> Yuan\n",
      "his -> Yuan\n",
      "his -> Yuan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 124.99 examples/s]\n",
      "12/15/2023 14:22:14 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 41.52it/s]\n",
      "12/15/2023 14:22:14 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "he -> Voss\n",
      "his -> Voss\n",
      "him -> Voss\n",
      "he -> Voss\n",
      "he -> Voss\n",
      "him -> Voss\n",
      "he -> Voss\n",
      "his -> Voss\n",
      "he -> Voss\n",
      "his -> Voss\n",
      "his -> Voss\n",
      "his -> Voss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 125.00 examples/s]\n",
      "12/15/2023 14:22:14 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 51.54it/s]\n",
      "12/15/2023 14:22:14 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "He -> Felix\n",
      "he -> Felix\n",
      "He -> Felix\n",
      "his -> Felix\n",
      "his -> Felix\n",
      "his -> Felix\n",
      "him -> Felix\n",
      "his -> Felix\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 124.09 examples/s]\n",
      "12/15/2023 14:22:14 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 55.53it/s]\n",
      "12/15/2023 14:22:14 - INFO - \t Tokenize 1 inputs...\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 131.37 examples/s]\n",
      "12/15/2023 14:22:14 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "his -> Meredith\n",
      "his -> Meredith\n",
      "she -> Mary\n",
      "she -> Mary\n",
      "she -> Mary\n",
      "she -> Mary\n",
      "her -> Mary\n",
      "she -> Mary\n",
      "her -> Mary\n",
      "her -> Mary\n",
      "her -> Mary\n",
      "She -> Mary,\n",
      "she -> Mary,\n",
      "she -> Mary,\n",
      "she -> Mary,\n",
      "he -> Ballinger\n",
      "he -> Ballinger\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12/15/2023 14:22:14 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "him -> Ballinger\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 108.94 examples/s]\n",
      "12/15/2023 14:22:14 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 22.28it/s]\n",
      "12/15/2023 14:22:14 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "she -> Bunny\n",
      "she -> Bunny\n",
      "she -> Bunny\n",
      "she -> Bunny\n",
      "her -> Bunny\n",
      "her -> Bunny\n",
      "her -> Bunny\n",
      "her -> Bunny\n",
      "her -> Bunny\n",
      "she -> Bunny\n",
      "her -> Bunny\n",
      "he -> Bear\n",
      "he -> Bear\n",
      "he -> Bear\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 64.96 examples/s]\n",
      "12/15/2023 14:22:14 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 54.94it/s]\n",
      "12/15/2023 14:22:14 - INFO - \t Tokenize 1 inputs...\n",
      "Map: 100%|██████████| 1/1 [00:00<?, ? examples/s]\n",
      "12/15/2023 14:22:15 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 60.42it/s]\n",
      "12/15/2023 14:22:15 - INFO - \t Tokenize 1 inputs...\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 99.86 examples/s]\n",
      "12/15/2023 14:22:15 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 60.90it/s]\n",
      "12/15/2023 14:22:15 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "his -> Hache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 138.60 examples/s]\n",
      "12/15/2023 14:22:15 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 60.58it/s]\n",
      "12/15/2023 14:22:15 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "him -> Van Dyke\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 54.99 examples/s]\n",
      "12/15/2023 14:22:15 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.75it/s]\n",
      "12/15/2023 14:22:15 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "his -> Tommy's\n",
      "him -> Tommy's\n",
      "his -> Tommy\n",
      "him -> Tommy\n",
      "his -> Tommy\n",
      "He -> Tommy\n",
      "he -> Tommy\n",
      "his -> Tommy\n",
      "he -> Tommy\n",
      "he -> Tommy\n",
      "his -> Tommy\n",
      "he -> Tommy\n",
      "he -> Tommy\n",
      "he -> Tommy\n",
      "his -> Tommy\n",
      "He -> Tommy\n",
      "he -> Tommy\n",
      "him -> Tommy\n",
      "he -> Tommy\n",
      "He -> Tommy\n",
      "he -> Tommy\n",
      "he -> Tommy\n",
      "he -> Tommy\n",
      "him -> Tommy\n",
      "him -> Tommy's\n",
      "He -> Tommy\n",
      "He -> Tommy\n",
      "him -> Tommy\n",
      "he -> Tommy\n",
      "he -> Tommy\n",
      "he -> Tommy\n",
      "him -> Tommy\n",
      "his -> Tommy\n",
      "he -> Tommy\n",
      "he -> Tommy\n",
      "he -> Tommy\n",
      "His -> Vicky\n",
      "He -> Vicky\n",
      "her -> Vicky\n",
      "her -> his mother\n",
      "Her -> Angela\n",
      "her -> Angela\n",
      "She -> Angela\n",
      "her -> Angela\n",
      "she -> Angela\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<?, ? examples/s]\n",
      "12/15/2023 14:22:15 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 61.60it/s]\n",
      "12/15/2023 14:22:15 - INFO - \t Tokenize 1 inputs...\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 322.54 examples/s]\n",
      "12/15/2023 14:22:15 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 18.26it/s]\n",
      "12/15/2023 14:22:15 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "his -> Kishen\n",
      "his -> Kishen\n",
      "his -> Kishen\n",
      "his -> Kishen\n",
      "his -> Kishen\n",
      "him -> Kishen\n",
      "his -> Kishen\n",
      "He -> Kishen\n",
      "his -> Kishen\n",
      "him -> Bhanwarlal\n",
      "her -> Lachchi\n",
      "her -> Lachchi\n",
      "her -> Lachchi\n",
      "She -> Lachchi\n",
      "she -> Lachchi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 74.30 examples/s]\n",
      "12/15/2023 14:22:15 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 40.75it/s]\n",
      "12/15/2023 14:22:15 - INFO - \t Tokenize 1 inputs...\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 158.80 examples/s]\n",
      "12/15/2023 14:22:15 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 59.99it/s]\n",
      "12/15/2023 14:22:15 - INFO - \t Tokenize 1 inputs...\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 65.99 examples/s]\n",
      "12/15/2023 14:22:15 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 15.17it/s]\n",
      "12/15/2023 14:22:15 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "him -> Arthur\n",
      "his -> Arthur\n",
      "he -> Arthur's\n",
      "He -> Arthur's\n",
      "he -> Arthur's\n",
      "he -> Arthur's\n",
      "his -> Arthur's\n",
      "his -> Arthur\n",
      "He -> Arthur\n",
      "he -> Arthur\n",
      "him -> Arthur\n",
      "he -> Arthur\n",
      "his -> Arthur\n",
      "he -> Arthur\n",
      "his -> Arthur\n",
      "he -> Arthur\n",
      "he -> Arthur\n",
      "she -> Joan\n",
      "her -> Joan\n",
      "her -> Eileen\n",
      "her -> Eileen\n",
      "she -> Eileen\n",
      "she -> Eileen\n",
      "her -> Eileen\n",
      "her -> Eileen\n",
      "her -> Eileen\n",
      "him -> Tom's\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<?, ? examples/s]\n",
      "12/15/2023 14:22:15 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 60.13it/s]\n",
      "12/15/2023 14:22:15 - INFO - \t Tokenize 1 inputs...\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 355.63 examples/s]\n",
      "12/15/2023 14:22:15 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 52.91it/s]\n",
      "12/15/2023 14:22:15 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "him -> Joe\n",
      "he -> Joe\n",
      "his -> Joe\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 74.08 examples/s]\n",
      "12/15/2023 14:22:16 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.98it/s]\n",
      "12/15/2023 14:22:16 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "him -> Bodine\n",
      "his -> Kyle\n",
      "His -> Kyle\n",
      "he -> Kyle's\n",
      "He -> Kyle's\n",
      "his -> Kyle\n",
      "he -> Kyle\n",
      "his -> Kyle\n",
      "his -> Kyle\n",
      "his -> Kyle\n",
      "his -> Kyle\n",
      "him -> Kyle\n",
      "his -> Kyle\n",
      "his -> Kyle\n",
      "him -> Kyle's\n",
      "he -> Kyle's\n",
      "his -> Kyle's\n",
      "his -> Kyle\n",
      "he -> Kyle\n",
      "He -> Kyle\n",
      "He -> Kyle\n",
      "He -> Kyle\n",
      "his -> Kyle\n",
      "he -> Kyle\n",
      "He -> Lamar\n",
      "him -> Lamar\n",
      "he -> Lamar\n",
      "him -> Lamar\n",
      "He -> Lamar\n",
      "he -> Lamar\n",
      "his -> Lamar\n",
      "his -> Lamar\n",
      "his -> Lamar\n",
      "his -> Lamar\n",
      "she -> Rachel\n",
      "she -> Rachel\n",
      "her -> his wife\n",
      "She -> Rachel\n",
      "she -> Rachel\n",
      "She -> Rachel\n",
      "she -> Rachel\n",
      "she -> Rachel\n",
      "her -> Rachel\n",
      "her -> Rachel\n",
      "she -> Rachel\n",
      "her -> Rachel\n",
      "she -> Rachel\n",
      "She -> Rachel\n",
      "her -> Rachel\n",
      "her -> Rachel\n",
      "her -> Rachel\n",
      "she -> Rachel\n",
      "She -> Rachel\n",
      "her -> Rachel\n",
      "She -> Rachel\n",
      "she -> Rachel\n",
      "she -> Rachel\n",
      "her -> Rachel\n",
      "her -> Rachel\n",
      "She -> Rachel\n",
      "she -> Rachel\n",
      "her -> Rachel\n",
      "her -> Rachel\n",
      "her -> Rachel\n",
      "she -> Rachel\n",
      "she -> Rachel\n",
      "her -> Rachel\n",
      "her -> Rachel\n",
      "her -> Rachel\n",
      "she -> Rachel\n",
      "she -> Rachel\n",
      "her -> Rachel\n",
      "her -> Rachel\n",
      "she -> Rachel\n",
      "her -> Rachel's\n",
      "She -> Rachel's\n",
      "her -> Rachel's\n",
      "she -> Rachel's\n",
      "She -> Rachel's\n",
      "she -> Rachel's\n",
      "her -> Rachel's\n",
      "She -> Rachel's\n",
      "his -> Rupert\n",
      "his -> Rupert\n",
      "his -> Rupert\n",
      "he -> Rupert\n",
      "him -> Rupert\n",
      "he -> Rupert's\n",
      "him -> Rupert's\n",
      "his -> Rupert\n",
      "her -> Adele\n",
      "her -> Adele\n",
      "her -> Adele\n",
      "she -> Adele\n",
      "she -> Adele\n",
      "her -> Adele\n",
      "her -> Adele\n",
      "they -> the police\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 224.79 examples/s]\n",
      "12/15/2023 14:22:16 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 53.10it/s]\n",
      "12/15/2023 14:22:16 - INFO - \t Tokenize 1 inputs...\n",
      "Map: 100%|██████████| 1/1 [00:00<?, ? examples/s]\n",
      "12/15/2023 14:22:16 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 66.81it/s]\n",
      "12/15/2023 14:22:16 - INFO - \t Tokenize 1 inputs...\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 124.77 examples/s]\n",
      "12/15/2023 14:22:16 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 30.75it/s]\n",
      "12/15/2023 14:22:16 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "her -> Madhavi\n",
      "she -> Madhavi\n",
      "her -> Madhavi\n",
      "she -> Madhavi\n",
      "her -> Madhavi\n",
      "her -> Madhavi\n",
      "she -> Madhavi\n",
      "She -> Madhavi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 124.76 examples/s]\n",
      "12/15/2023 14:22:16 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 41.68it/s]\n",
      "12/15/2023 14:22:16 - INFO - \t Tokenize 1 inputs...\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 160.55 examples/s]\n",
      "12/15/2023 14:22:16 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 56.23it/s]\n",
      "12/15/2023 14:22:16 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "He -> Michael\n",
      "his -> Michael\n",
      "his -> Michael\n",
      "his -> Michael\n",
      "he -> Michael\n",
      "he -> Michael\n",
      "him -> Michael\n",
      "his -> Michael\n",
      "his -> Mario\n",
      "his -> Mario\n",
      "his -> Mario\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 164.56 examples/s]\n",
      "12/15/2023 14:22:16 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.46it/s]\n",
      "12/15/2023 14:22:16 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "him -> Madhan\n",
      "him -> Madhan\n",
      "he -> Madhan\n",
      "he -> Madhan\n",
      "he -> Madhan\n",
      "his -> Madhan\n",
      "him -> Madhan\n",
      "his -> Madhan\n",
      "He -> Madhan\n",
      "his -> Madhan\n",
      "His -> Madhan\n",
      "his -> Madhan\n",
      "she -> her,\n",
      "her -> her,\n",
      "She -> her,\n",
      "she -> Mythili\n",
      "her -> Vaishnavi\n",
      "her -> Vaishnavi\n",
      "her -> Vaishnavi\n",
      "her -> Vaishnavi\n",
      "her -> Vaishnavi\n",
      "she -> Vaishnavi\n",
      "her -> Vaishnavi\n",
      "she -> her,\n",
      "she -> her,\n",
      "his -> his brother\n",
      "his -> his brother\n",
      "his -> his brother\n",
      "He -> his brother\n",
      "his -> his brother\n",
      "his -> his brother\n",
      "His -> Simbu\n",
      "he -> Simbu\n",
      "he -> Simbu\n",
      "he -> Simbu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 647.97 examples/s]\n",
      "12/15/2023 14:22:16 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 42.87it/s]\n",
      "12/15/2023 14:22:16 - INFO - \t Tokenize 1 inputs...\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 199.43 examples/s]\n",
      "12/15/2023 14:22:16 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 63.87it/s]\n",
      "12/15/2023 14:22:16 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "his -> Hubbell\n",
      "he -> Hubbell\n",
      "he -> Hubbell\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 63.54 examples/s]\n",
      "12/15/2023 14:22:16 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.03it/s]\n",
      "12/15/2023 14:22:17 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "his -> Sean\n",
      "his -> Sean\n",
      "his -> Sean\n",
      "he -> Sean\n",
      "his -> Sean\n",
      "him -> Sean\n",
      "he -> Sean\n",
      "him -> Sean\n",
      "him -> Jason\n",
      "he -> Jason\n",
      "his -> Jason\n",
      "him -> Jason\n",
      "he -> Sean\n",
      "his -> Sean\n",
      "him -> Sean\n",
      "his -> Sean\n",
      "him -> Sean's\n",
      "him -> Sean's\n",
      "He -> Sean's\n",
      "he -> Sean\n",
      "he -> Sean\n",
      "he -> Sean\n",
      "his -> Jason\n",
      "he -> Jason\n",
      "he -> Jason\n",
      "their -> both\n",
      "his -> Mr. Blackwell\n",
      "his -> Mr. Blackwell\n",
      "him -> Mr. Blackwell\n",
      "He -> Nick\n",
      "he -> Nick\n",
      "his -> Nick\n",
      "his -> Jonathan\n",
      "him -> Jonathan\n",
      "his -> Mr. Blackwell\n",
      "she -> Sam,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 643.40 examples/s]\n",
      "12/15/2023 14:22:17 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 46.05it/s]\n",
      "12/15/2023 14:22:17 - INFO - \t Tokenize 1 inputs...\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 63.57 examples/s]\n",
      "12/15/2023 14:22:17 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.05it/s]\n",
      "12/15/2023 14:22:17 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "him -> Walter\n",
      "him -> Walter\n",
      "his -> Walter\n",
      "he -> Walter\n",
      "He -> Walter\n",
      "his -> Walter's\n",
      "his -> Walter\n",
      "He -> Walter\n",
      "his -> Walter\n",
      "his -> Walter\n",
      "he -> Walter's\n",
      "his -> Walter's\n",
      "he -> Walter's\n",
      "he -> Walter\n",
      "He -> Walter\n",
      "his -> Walter\n",
      "his -> Walter\n",
      "He -> Walter\n",
      "he -> Walter\n",
      "he -> Walter\n",
      "his -> Walter\n",
      "he -> Walter\n",
      "his -> Walter\n",
      "he -> Walter\n",
      "his -> Walter\n",
      "he -> Walter\n",
      "his -> Walter\n",
      "his -> Herbert\n",
      "her -> Hannah\n",
      "her -> Hannah\n",
      "his -> Joachim\n",
      "She -> Ivy\n",
      "her -> Sabeth\n",
      "her -> Sabeth\n",
      "she -> Sabeth\n",
      "her -> Sabeth\n",
      "her -> Sabeth\n",
      "her -> Sabeth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 83.88 examples/s]\n",
      "12/15/2023 14:22:17 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.12it/s]\n",
      "12/15/2023 14:22:17 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "her -> Mary\n",
      "her -> Mary\n",
      "him -> Judas\n",
      "he -> Judas\n",
      "He -> Judas\n",
      "his -> Judas\n",
      "he -> Judas\n",
      "he -> Judas\n",
      "He -> Judas\n",
      "He -> Jesus\n",
      "He -> Jesus\n",
      "He -> Jesus\n",
      "He -> Jesus\n",
      "him -> Jesus\n",
      "His -> Jesus\n",
      "Him -> Jesus\n",
      "he -> Jesus\n",
      "he -> Jesus\n",
      "His -> Jesus\n",
      "Him -> Jesus\n",
      "He -> Jesus\n",
      "Him -> Jesus\n",
      "He -> Jesus\n",
      "His -> Jesus\n",
      "He -> Jesus\n",
      "His -> Jesus\n",
      "He -> Jesus\n",
      "His -> Jesus\n",
      "He -> Jesus\n",
      "His -> Jesus\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 189.55 examples/s]\n",
      "12/15/2023 14:22:17 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 59.35it/s]\n",
      "12/15/2023 14:22:17 - INFO - \t Tokenize 1 inputs...\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 158.54 examples/s]\n",
      "12/15/2023 14:22:17 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 43.97it/s]\n",
      "12/15/2023 14:22:17 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "his -> Subba Rao\n",
      "his -> Subba Rao\n",
      "his -> Subba Rao\n",
      "he -> Subba Rao\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 103.39 examples/s]\n",
      "12/15/2023 14:22:17 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.85it/s]\n",
      "12/15/2023 14:22:17 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "his -> Straker\n",
      "his -> Straker\n",
      "his -> Straker\n",
      "her -> the girl\n",
      "her -> the girl\n",
      "her -> the girl\n",
      "she -> the girl\n",
      "she -> the girl\n",
      "her -> the girl\n",
      "him -> the girl\n",
      "her -> the girl\n",
      "her -> the girl\n",
      "her -> the girl\n",
      "her -> the girl\n",
      "his -> Hunter\n",
      "his -> Hunter\n",
      "him -> Hunter\n",
      "him -> Hunter\n",
      "his -> Hunter\n",
      "he -> Hunter\n",
      "He -> Hunter\n",
      "He -> Hunter\n",
      "he -> Hunter\n",
      "his -> Hunter\n",
      "his -> Hunter\n",
      "his -> Hunter\n",
      "him -> the driver\n",
      "he -> The driver\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 310.62 examples/s]\n",
      "12/15/2023 14:22:17 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 30.77it/s]\n",
      "12/15/2023 14:22:17 - INFO - \t Tokenize 1 inputs...\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 60.43 examples/s]\n",
      "12/15/2023 14:22:18 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.12it/s]\n",
      "12/15/2023 14:22:18 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "him -> Butch\n",
      "him -> Butch\n",
      "he -> Spike\n",
      "he -> Spike\n",
      "he -> Lightning\n",
      "his -> Lightning\n",
      "him -> Lightning\n",
      "his -> Lightning\n",
      "him -> Lightning\n",
      "him -> Topsy\n",
      "him -> Topsy\n",
      "he -> Topsy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 72.49 examples/s]\n",
      "12/15/2023 14:22:18 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 15.28it/s]\n",
      "12/15/2023 14:22:18 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "his -> Veer\n",
      "his -> Veer\n",
      "his -> Veer\n",
      "his -> Veer\n",
      "he -> Veer\n",
      "he -> Veer\n",
      "he -> Veer\n",
      "his -> Veer\n",
      "his -> Fraser\n",
      "his -> Gyanendra Singh\n",
      "He -> Gyanendra Singh\n",
      "him -> Gyanendra Singh\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 73.80 examples/s]\n",
      "12/15/2023 14:22:18 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 24.37it/s]\n",
      "12/15/2023 14:22:18 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "his -> Seenu\n",
      "he -> Seenu\n",
      "his -> Seenu\n",
      "he -> Seenu\n",
      "he -> Seenu\n",
      "he -> Raghu\n",
      "her -> Madhavi\n",
      "her -> Madhavi\n",
      "her -> Madhavi\n",
      "her -> her,\n",
      "his -> Manickam\n",
      "his -> Manickam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 56.03 examples/s]\n",
      "12/15/2023 14:22:18 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.27it/s]\n",
      "12/15/2023 14:22:18 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "he -> Frankie Machine\n",
      "him -> Frankie Machine\n",
      "his -> Frankie\n",
      "him -> Frankie\n",
      "his -> Frankie\n",
      "his -> Frankie\n",
      "He -> Frankie\n",
      "he -> Frankie\n",
      "he -> Frankie\n",
      "him -> Frankie\n",
      "he -> Frankie\n",
      "his -> Frankie\n",
      "he -> Frankie\n",
      "him -> Frankie\n",
      "He -> Frankie\n",
      "his -> Frankie\n",
      "him -> Frankie\n",
      "his -> Frankie\n",
      "he -> Frankie\n",
      "he -> Frankie\n",
      "he -> Frankie\n",
      "he -> Frankie\n",
      "his -> Frankie\n",
      "he -> Frankie\n",
      "he -> Frankie\n",
      "He -> Frankie\n",
      "her -> her,\n",
      "She -> her,\n",
      "she -> her,\n",
      "her -> her,\n",
      "his -> Louis\n",
      "his -> Louis\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<?, ? examples/s]\n",
      "12/15/2023 14:22:18 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 65.16it/s]\n",
      "12/15/2023 14:22:18 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "his -> The Lone Ranger\n",
      "He -> The Lone Ranger\n",
      "he -> The Lone Ranger\n",
      "him -> The Lone Ranger\n",
      "his -> The Lone Ranger\n",
      "he -> The Lone Ranger\n",
      "he -> The Lone Ranger\n",
      "he -> The Lone Ranger\n",
      "he -> The Lone Ranger\n",
      "he -> The Lone Ranger\n",
      "he -> The Lone Ranger\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<?, ? examples/s]\n",
      "12/15/2023 14:22:18 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 42.29it/s]\n",
      "12/15/2023 14:22:18 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "His -> Wilbur\n",
      "him -> Wilbur\n",
      "his -> Wilbur\n",
      "he -> Wilbur\n",
      "his -> Wilbur\n",
      "he -> Wilbur\n",
      "he -> Wilbur\n",
      "his -> Wilbur\n",
      "his -> Wilbur\n",
      "him -> Wilbur\n",
      "their -> women\n",
      "his -> McIntosh\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 124.99 examples/s]\n",
      "12/15/2023 14:22:18 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 15.23it/s]\n",
      "12/15/2023 14:22:18 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "his -> Cobb\n",
      "he -> Cobb\n",
      "his -> Cobb\n",
      "his -> Cobb\n",
      "him -> Cobb\n",
      "his -> Cobb\n",
      "He -> Cobb\n",
      "his -> Cobb\n",
      "his -> Cobb\n",
      "he -> Cobb\n",
      "his -> Cobb\n",
      "his -> Cobb\n",
      "his -> Cobb\n",
      "he -> Cobb\n",
      "he -> Cobb\n",
      "he -> Cobb\n",
      "he -> Cobb\n",
      "his -> Cobb\n",
      "his -> Cobb\n",
      "his -> Cobb\n",
      "his -> Cobb\n",
      "his -> Cobb\n",
      "she -> his wife\n",
      "he -> Ben\n",
      "him -> Ben\n",
      "He -> Ben\n",
      "he -> Ben\n",
      "his -> Ben\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 81.64 examples/s]\n",
      "12/15/2023 14:22:18 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 16.79it/s]\n",
      "12/15/2023 14:22:18 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "his -> James Bond\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<?, ? examples/s]\n",
      "12/15/2023 14:22:18 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 44.31it/s]\n",
      "12/15/2023 14:22:19 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "his -> Wishbone\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 629.30 examples/s]\n",
      "12/15/2023 14:22:19 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 30.84it/s]\n",
      "12/15/2023 14:22:19 - INFO - \t Tokenize 1 inputs...\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 1944.51 examples/s]\n",
      "12/15/2023 14:22:19 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.85it/s]\n",
      "12/15/2023 14:22:19 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "his -> Partridge\n",
      "his -> Partridge\n",
      "his -> Partridge\n",
      "his -> Burton\n",
      "he -> Burton\n",
      "his -> Burton\n",
      "he -> Burton\n",
      "he -> Smith\n",
      "his -> Smith\n",
      "he -> Smith\n",
      "his -> Dalton\n",
      "his -> Dalton\n",
      "his -> Dalton\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 117.43 examples/s]\n",
      "12/15/2023 14:22:19 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 52.36it/s]\n",
      "12/15/2023 14:22:19 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "his -> Kishan\n",
      "his -> Kishan\n",
      "his -> Kishan\n",
      "him -> Kishan\n",
      "He -> Kishan\n",
      "she -> Mary\n",
      "he -> Diwan Shamsher Singh\n",
      "his -> Diwan Shamsher Singh\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 119.19 examples/s]\n",
      "12/15/2023 14:22:19 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 52.40it/s]\n",
      "12/15/2023 14:22:19 - INFO - \t Tokenize 1 inputs...\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 153.48 examples/s]\n",
      "12/15/2023 14:22:19 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 18.34it/s]\n",
      "12/15/2023 14:22:19 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "his -> Ganesh\n",
      "he -> Ganesh\n",
      "he -> Ganesh\n",
      "he -> Ganesh\n",
      "he -> Ganesh\n",
      "he -> Ganesh\n",
      "his -> Ganesh\n",
      "him -> Ganesh\n",
      "His -> Ganesh\n",
      "his -> Ganesh\n",
      "his -> Ganesh\n",
      "her -> Anjali\n",
      "she -> Anjali\n",
      "He -> Ganesh's father\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 174.86 examples/s]\n",
      "12/15/2023 14:22:19 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 56.23it/s]\n",
      "12/15/2023 14:22:19 - INFO - \t Tokenize 1 inputs...\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 140.49 examples/s]\n",
      "12/15/2023 14:22:19 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.04it/s]\n",
      "12/15/2023 14:22:19 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "his -> Bob\n",
      "his -> Bob\n",
      "his -> Bob\n",
      "he -> Bob\n",
      "his -> Bob\n",
      "his -> Bob\n",
      "his -> Bob\n",
      "He -> Bob\n",
      "him -> Bob\n",
      "his -> Bob\n",
      "him -> Bob\n",
      "him -> Bob\n",
      "he -> Bob\n",
      "his -> Bob\n",
      "his -> Bob\n",
      "his -> Bob\n",
      "his -> Bob\n",
      "his -> Bob\n",
      "his -> Bob\n",
      "his -> Bob\n",
      "his -> Bob\n",
      "his -> Bob\n",
      "his -> Bob\n",
      "He -> Bob\n",
      "him -> Bob\n",
      "He -> Bob\n",
      "he -> Bob\n",
      "his -> Bob\n",
      "his -> Bob's\n",
      "he -> Bob's\n",
      "him -> Bob's\n",
      "his -> Bob's\n",
      "his -> Bob\n",
      "his -> Bob\n",
      "his -> Bob's\n",
      "he -> Bob\n",
      "his -> Bob\n",
      "he -> Bob\n",
      "his -> Bob\n",
      "he -> Bob\n",
      "his -> Bob\n",
      "his -> Bob\n",
      "his -> Bob\n",
      "him -> Bob\n",
      "his -> Bob\n",
      "He -> Bob Jones\n",
      "she -> Gail's\n",
      "he -> his brother\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 73.90 examples/s]\n",
      "12/15/2023 14:22:19 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.65it/s]\n",
      "12/15/2023 14:22:19 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "he -> Frank Drebin\n",
      "he -> Frank\n",
      "he -> Drebin\n",
      "his -> Frank\n",
      "he -> Frank\n",
      "his -> Frank\n",
      "he -> Frank\n",
      "his -> Frank\n",
      "his -> Frank\n",
      "he -> Vincent Ludwig\n",
      "his -> Vincent Ludwig\n",
      "he -> Ludwig\n",
      "his -> Ludwig\n",
      "his -> Ludwig\n",
      "him -> Ludwig\n",
      "him -> Ludwig\n",
      "his -> Ludwig\n",
      "him -> Nordberg\n",
      "her -> Jane\n",
      "she -> Jane\n",
      "her -> Jane's\n",
      "her -> her,\n",
      "his -> Jackson\n",
      "him -> Jackson\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 86.83 examples/s]\n",
      "12/15/2023 14:22:20 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 58.44it/s]\n",
      "12/15/2023 14:22:20 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "his -> Randy\n",
      "his -> Randy\n",
      "He -> Randy\n",
      "his -> Randy\n",
      "his -> Randy\n",
      "she -> Marti\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 133.05 examples/s]\n",
      "12/15/2023 14:22:20 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 31.04it/s]\n",
      "12/15/2023 14:22:20 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "her -> the girl\n",
      "her -> the girl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 217.75 examples/s]\n",
      "12/15/2023 14:22:20 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 62.47it/s]\n",
      "12/15/2023 14:22:20 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "her -> Wan\n",
      "her -> Wan\n",
      "her -> Wan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 125.01 examples/s]\n",
      "12/15/2023 14:22:20 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 41.63it/s]\n",
      "12/15/2023 14:22:20 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "he -> Rhodes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 257.84 examples/s]\n",
      "12/15/2023 14:22:20 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.32it/s]\n",
      "12/15/2023 14:22:20 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "she -> Georgina Salt\n",
      "her -> Georgina Salt\n",
      "her -> Georgina\n",
      "her -> Georgina\n",
      "her -> Georgina\n",
      "her -> Georgina\n",
      "her -> Georgina\n",
      "her -> Georgina\n",
      "her -> Georgina\n",
      "her -> Georgina\n",
      "her -> Georgina\n",
      "she -> Georgina\n",
      "her -> Georgina\n",
      "her -> Georgina\n",
      "she -> Georgia\n",
      "her -> Georgia\n",
      "her -> Georgia\n",
      "she -> Georgina\n",
      "she -> Georgina\n",
      "her -> Georgina\n",
      "She -> Georgina\n",
      "her -> Georgina\n",
      "she -> Georgina\n",
      "her -> Georgina\n",
      "her -> Georgina\n",
      "she -> Georgina\n",
      "her -> Georgina\n",
      "she -> Georgina\n",
      "she -> Georgina\n",
      "her -> Georgina\n",
      "her -> Georgina\n",
      "her -> Georgina\n",
      "her -> Georgina\n",
      "her -> Georgina\n",
      "she -> Georgina\n",
      "she -> Georgia\n",
      "she -> Georgia\n",
      "she -> Georgia\n",
      "her -> Georgia\n",
      "her -> Georgia\n",
      "She -> Georgia\n",
      "Her -> Georgia\n",
      "She -> Georgina\n",
      "her -> Georgina\n",
      "she -> Georgina\n",
      "her -> Georgina\n",
      "she -> Georgia\n",
      "She -> Georgina\n",
      "her -> Georgina\n",
      "she -> Georgina\n",
      "her -> Georgina\n",
      "She -> Georgina\n",
      "her -> Georgina\n",
      "she -> Georgina\n",
      "his -> Zach\n",
      "him -> Zach\n",
      "he -> Zach\n",
      "he -> Zach\n",
      "he -> Zach\n",
      "he -> Zach\n",
      "his -> Zach\n",
      "He -> Zach's\n",
      "him -> Zach\n",
      "he -> Zach\n",
      "he -> Zach\n",
      "his -> Zach\n",
      "he -> Zach\n",
      "he -> Zach\n",
      "him -> Zach\n",
      "her -> Clem\n",
      "he -> Clem\n",
      "he -> Justin\n",
      "She -> Justin\n",
      "she -> Justin\n",
      "She -> Justin\n",
      "she -> Alexandra\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 109.67 examples/s]\n",
      "12/15/2023 14:22:20 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.56it/s]\n",
      "12/15/2023 14:22:20 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "he -> Nick\n",
      "he -> Nick\n",
      "his -> Nick\n",
      "he -> Nick\n",
      "him -> Nick\n",
      "he -> Nick\n",
      "his -> Nick\n",
      "he -> Tim's\n",
      "he -> Tim's\n",
      "he -> Tim's\n",
      "he -> Tim\n",
      "his -> Tim\n",
      "his -> Tim\n",
      "his -> Tim\n",
      "him -> Tim\n",
      "him -> Tim\n",
      "his -> Tim\n",
      "his -> Tim\n",
      "his -> Tim\n",
      "his -> Tim\n",
      "his -> J-Man\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 298.46 examples/s]\n",
      "12/15/2023 14:22:20 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 17.41it/s]\n",
      "12/15/2023 14:22:20 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "her -> her,\n",
      "she -> her,\n",
      "her -> her,\n",
      "her -> her,\n",
      "his -> Seeta\n",
      "he -> Seeta\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 76.53 examples/s]\n",
      "12/15/2023 14:22:20 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 60.32it/s]\n",
      "12/15/2023 14:22:20 - INFO - \t Tokenize 1 inputs...\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 63.29 examples/s]\n",
      "12/15/2023 14:22:20 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 15.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "his -> Sher Singh\n",
      "his -> Sher Singh\n",
      "he -> Raja\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "12/15/2023 14:22:21 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "her -> Pooja\n",
      "she -> Pooja\n",
      "her -> Pooja\n",
      "she -> Pooja\n",
      "her -> Pooja\n",
      "her -> Pooja\n",
      "her -> Pooja\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 178.63 examples/s]\n",
      "12/15/2023 14:22:21 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 17.76it/s]\n",
      "12/15/2023 14:22:21 - INFO - \t Tokenize 1 inputs...\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 133.05 examples/s]\n",
      "12/15/2023 14:22:21 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.20it/s]\n",
      "12/15/2023 14:22:21 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "she -> her,\n",
      "her -> her,\n",
      "she -> Sunny\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 62.33 examples/s]\n",
      "12/15/2023 14:22:21 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 17.55it/s]\n",
      "12/15/2023 14:22:21 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "his -> Cameron\n",
      "him -> Cameron\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<?, ? examples/s]\n",
      "12/15/2023 14:22:21 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 15.48it/s]\n",
      "12/15/2023 14:22:21 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "her -> Eva\n",
      "her -> her,\n",
      "her -> her,\n",
      "she -> her,\n",
      "she -> Eva\n",
      "she -> Eva\n",
      "she -> Eva\n",
      "She -> Eva\n",
      "she -> Eva\n",
      "her -> Eva\n",
      "She -> Eva\n",
      "her -> Eva\n",
      "her -> Eva\n",
      "She -> Eva\n",
      "her -> Eva\n",
      "he -> The driver\n",
      "he -> The driver\n",
      "he -> The driver\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 131.23 examples/s]\n",
      "12/15/2023 14:22:21 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.89it/s]\n",
      "12/15/2023 14:22:21 - INFO - \t Tokenize 1 inputs...\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 124.80 examples/s]\n",
      "12/15/2023 14:22:21 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 24.94it/s]\n",
      "12/15/2023 14:22:21 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "his -> Foghorn\n",
      "him -> Foghorn\n",
      "his -> Foghorn\n",
      "he -> Foghorn\n",
      "him -> Dawg\n",
      "him -> Dawg\n",
      "he -> Henery Hawk\n",
      "he -> Henery Hawk\n",
      "he -> Henery\n",
      "he -> Henery\n",
      "he -> Henery\n",
      "him -> it\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 65.71 examples/s]\n",
      "12/15/2023 14:22:21 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00,  9.52it/s]\n",
      "12/15/2023 14:22:22 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "he -> No-young\n",
      "his -> No-young\n",
      "he -> No-young\n",
      "his -> No-young\n",
      "him -> No-young\n",
      "him -> No-young\n",
      "he -> No-young\n",
      "he -> No-young\n",
      "He -> No-young\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 58.52 examples/s]\n",
      "12/15/2023 14:22:22 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.74it/s]\n",
      "12/15/2023 14:22:22 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "her -> Melissa\n",
      "her -> Melissa\n",
      "her -> Melissa\n",
      "her -> Melissa\n",
      "her -> Melissa\n",
      "her -> Melissa\n",
      "She -> Melissa\n",
      "her -> Melissa\n",
      "her -> Melissa\n",
      "she -> Melissa\n",
      "her -> Melissa\n",
      "her -> Melissa\n",
      "her -> Melissa\n",
      "she -> Melissa\n",
      "She -> Melissa\n",
      "she -> Melissa\n",
      "her -> Melissa\n",
      "him -> Drew\n",
      "his -> Drew\n",
      "him -> Drew\n",
      "his -> Drew\n",
      "he -> Drew\n",
      "his -> Drew\n",
      "he -> Drew\n",
      "He -> Drew\n",
      "his -> Drew\n",
      "she -> Gabby\n",
      "her -> Gabby\n",
      "her -> Gabby\n",
      "her -> Cara\n",
      "she -> Cara\n",
      "her -> Cara\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 643.30 examples/s]\n",
      "12/15/2023 14:22:22 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 32.45it/s]\n",
      "12/15/2023 14:22:22 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "his -> Tubby\n",
      "his -> Tubby\n",
      "his -> Tubby\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 66.58 examples/s]\n",
      "12/15/2023 14:22:22 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 51.16it/s]\n",
      "12/15/2023 14:22:22 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "she -> Heather Lofton\n",
      "her -> Heather Lofton\n",
      "her -> Heather\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 132.95 examples/s]\n",
      "12/15/2023 14:22:22 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 17.52it/s]\n",
      "12/15/2023 14:22:22 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "her -> Olive Penderghast\n",
      "she -> Olive Penderghast\n",
      "her -> Olive\n",
      "her -> Olive\n",
      "her -> Olive\n",
      "her -> Olive\n",
      "She -> Olive\n",
      "she -> Olive\n",
      "her -> Olive\n",
      "her -> Olive\n",
      "her -> Olive\n",
      "her -> Olive\n",
      "her -> Olive\n",
      "she -> Olive\n",
      "her -> Olive\n",
      "her -> Olive\n",
      "she -> Olive\n",
      "she -> Olive\n",
      "her -> Olive\n",
      "her -> her,\n",
      "her -> her,\n",
      "She -> Olive\n",
      "her -> Olive\n",
      "she -> Olive\n",
      "she -> Olive\n",
      "she -> Olive\n",
      "her -> Olive\n",
      "her -> Olive\n",
      "She -> Olive\n",
      "him -> Brandon\n",
      "he -> Brandon\n",
      "he -> Todd\n",
      "he -> Todd\n",
      "him -> Todd\n",
      "he -> Todd\n",
      "his -> Todd\n",
      "him -> Todd\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 119.69 examples/s]\n",
      "12/15/2023 14:22:22 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "her -> Frida\n",
      "he -> Fry\n",
      "He -> Fry\n",
      "his -> Fry\n",
      "his -> Fry\n",
      "he -> Fry\n",
      "he -> Fry\n",
      "him -> Fry\n",
      "his -> Fry\n",
      "her -> Amy\n",
      "his -> Bender\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12/15/2023 14:22:22 - INFO - \t Tokenize 1 inputs...\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 164.75 examples/s]\n",
      "12/15/2023 14:22:22 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 107.10it/s]\n",
      "12/15/2023 14:22:22 - INFO - \t Tokenize 1 inputs...\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 71.71 examples/s]\n",
      "12/15/2023 14:22:22 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 41.60it/s]\n",
      "12/15/2023 14:22:22 - INFO - \t Tokenize 1 inputs...\n",
      "Map: 100%|██████████| 1/1 [00:00<?, ? examples/s]\n",
      "12/15/2023 14:22:22 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 70.70it/s]\n",
      "12/15/2023 14:22:22 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "his -> Djibril\n",
      "he -> Djibril\n",
      "his -> Djibril\n",
      "he -> Djibril\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 68.09 examples/s]\n",
      "12/15/2023 14:22:22 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 34.13it/s]\n",
      "12/15/2023 14:22:23 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "his -> Porky\n",
      "he -> Porky\n",
      "he -> Porky\n",
      "his -> Porky\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 59.19 examples/s]\n",
      "12/15/2023 14:22:23 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 30.32it/s]\n",
      "12/15/2023 14:22:23 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "He -> Grierson\n",
      "he -> Grierson\n",
      "he -> Grierson\n",
      "her -> Margaret\n",
      "her -> Margaret\n",
      "her -> Margaret\n",
      "her -> Margaret\n",
      "her -> Margaret\n",
      "her -> Margaret\n",
      "his -> Hardwick\n",
      "him -> Hardwick\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 64.90 examples/s]\n",
      "12/15/2023 14:22:23 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 54.52it/s]\n",
      "12/15/2023 14:22:23 - INFO - \t Tokenize 1 inputs...\n",
      "Map: 100%|██████████| 1/1 [00:00<?, ? examples/s]\n",
      "12/15/2023 14:22:23 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 19.28it/s]\n",
      "12/15/2023 14:22:23 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "his -> Pierre\n",
      "his -> Pierre\n",
      "him -> Pierre\n",
      "his -> Pierre\n",
      "he -> Pierre\n",
      "his -> Pierre\n",
      "his -> Pierre\n",
      "he -> Pierre\n",
      "He -> Pierre's\n",
      "his -> Pierre's\n",
      "his -> Pierre\n",
      "him -> Pierre\n",
      "his -> Pierre\n",
      "He -> Pierre\n",
      "him -> Pierre\n",
      "he -> Pierre\n",
      "He -> Pierre\n",
      "him -> Pierre\n",
      "he -> Pierre\n",
      "his -> Paul\n",
      "him -> Paul\n",
      "he -> Paul\n",
      "his -> Paul\n",
      "he -> Paul\n",
      "his -> Paul\n",
      "his -> Paul\n",
      "him -> Paul\n",
      "he -> Paul\n",
      "he -> Paul\n",
      "He -> Paul\n",
      "she -> her,\n",
      "she -> her,\n",
      "her -> her,\n",
      "she -> Joanna\n",
      "her -> Joanna\n",
      "her -> Hazel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 191.65 examples/s]\n",
      "12/15/2023 14:22:23 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 87.02it/s]\n",
      "12/15/2023 14:22:23 - INFO - \t Tokenize 1 inputs...\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 222.16 examples/s]\n",
      "12/15/2023 14:22:23 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 38.83it/s]\n",
      "12/15/2023 14:22:23 - INFO - \t Tokenize 1 inputs...\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 135.03 examples/s]\n",
      "12/15/2023 14:22:23 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.55it/s]\n",
      "12/15/2023 14:22:23 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "he -> Corey Webster\n",
      "his -> Corey Webster\n",
      "he -> Corey Webster\n",
      "his -> Corey\n",
      "He -> Corey\n",
      "he -> Corey\n",
      "he -> Corey\n",
      "him -> Corey\n",
      "his -> Corey\n",
      "him -> Corey\n",
      "him -> Corey\n",
      "him -> Corey\n",
      "him -> Corey\n",
      "his -> Corey\n",
      "he -> Corey\n",
      "He -> Corey\n",
      "he -> Corey\n",
      "him -> Corey\n",
      "He -> Corey\n",
      "his -> Corey\n",
      "her -> Chrissy\n",
      "her -> Chrissy\n",
      "her -> Chrissy\n",
      "she -> Chrissy\n",
      "she -> Chrissy\n",
      "she -> her,\n",
      "her -> her,\n",
      "she -> her,\n",
      "she -> her,\n",
      "she -> Chrissy\n",
      "her -> Chrissy\n",
      "her -> Chrissy\n",
      "her -> Chrissy\n",
      "she -> Chrissy\n",
      "her -> Chrissy\n",
      "he -> Hook\n",
      "his -> Hook\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 133.05 examples/s]\n",
      "12/15/2023 14:22:23 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 31.81it/s]\n",
      "12/15/2023 14:22:23 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "she -> Karen\n",
      "hers -> Karen\n",
      "his -> Tim\n",
      "his -> Phil\n",
      "his -> Matt\n",
      "his -> Matt\n",
      "he -> Matt\n",
      "he -> Matt\n",
      "his -> Matt's\n",
      "his -> Matt\n",
      "his -> Matt\n",
      "he -> Matt\n",
      "he -> Matt\n",
      "him -> Matt\n",
      "her -> Tom\n",
      "he -> Tom\n",
      "He -> Tom\n",
      "she -> his mother\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 660.00 examples/s]\n",
      "12/15/2023 14:22:23 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 31.04it/s]\n",
      "12/15/2023 14:22:23 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "she -> his wife\n",
      "her -> his wife\n",
      "she -> Suhasini\n",
      "her -> Suhasini\n",
      "her -> Suhasini\n",
      "her -> Suhasini\n",
      "her -> Suhasini\n",
      "She -> Suhasini\n",
      "her -> Suhasini\n",
      "her -> Suhasini\n",
      "her -> Suhasini\n",
      "her -> Suhasini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 193.00 examples/s]\n",
      "12/15/2023 14:22:23 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 52.26it/s]\n",
      "12/15/2023 14:22:23 - INFO - \t Tokenize 1 inputs...\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 91.46 examples/s]\n",
      "12/15/2023 14:22:23 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 59.92it/s]\n",
      "12/15/2023 14:22:23 - INFO - \t Tokenize 1 inputs...\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 181.31 examples/s]\n",
      "12/15/2023 14:22:23 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 15.02it/s]\n",
      "12/15/2023 14:22:24 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "he -> the man\n",
      "him -> the man\n",
      "his -> the man\n",
      "him -> the man\n",
      "he -> the man\n",
      "him -> The hunter\n",
      "his -> The hunter\n",
      "his -> The hunter\n",
      "she -> her,\n",
      "his -> Warden\n",
      "he -> Warden\n",
      "his -> Warden\n",
      "his -> Warden\n",
      "he -> Warden\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<?, ? examples/s]\n",
      "12/15/2023 14:22:24 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 59.69it/s]\n",
      "12/15/2023 14:22:24 - INFO - \t Tokenize 1 inputs...\n",
      "Map: 100%|██████████| 1/1 [00:00<?, ? examples/s]\n",
      "12/15/2023 14:22:24 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 23.21it/s]\n",
      "12/15/2023 14:22:24 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "his -> Caine\n",
      "him -> Caine\n",
      "He -> Caine\n",
      "they -> White Boys\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 99.85 examples/s]\n",
      "12/15/2023 14:22:24 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 29.98it/s]\n",
      "12/15/2023 14:22:24 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "her -> Marie\n",
      "her -> Marie\n",
      "her -> Ethel Ann\n",
      "her -> Ethel Ann\n",
      "She -> Ethel Ann\n",
      "her -> Ethel\n",
      "She -> Ethel\n",
      "her -> Ethel\n",
      "he -> Jack\n",
      "he -> Quinlan\n",
      "him -> Quinlan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<?, ? examples/s]\n",
      "12/15/2023 14:22:24 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 73.53it/s]\n",
      "12/15/2023 14:22:24 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "her -> Nina\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 124.74 examples/s]\n",
      "12/15/2023 14:22:24 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 58.06it/s]\n",
      "12/15/2023 14:22:24 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "she -> Anne\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 133.02 examples/s]\n",
      "12/15/2023 14:22:24 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 15.17it/s]\n",
      "12/15/2023 14:22:24 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "He -> Timoteo\n",
      "he -> Timoteo\n",
      "His -> Timoteo\n",
      "him -> Timoteo\n",
      "He -> Timoteo\n",
      "He -> Timoteo\n",
      "his -> Timoteo\n",
      "he -> Timoteo\n",
      "he -> Timoteo\n",
      "his -> Timoteo\n",
      "his -> Timoteo\n",
      "his -> Timoteo\n",
      "him -> Timoteo\n",
      "his -> Timoteo\n",
      "his -> Timoteo\n",
      "he -> Timoteo\n",
      "he -> Timoteo\n",
      "him -> Timoteo\n",
      "he -> Timoteo\n",
      "his -> Timoteo\n",
      "He -> Timoteo\n",
      "his -> Timoteo\n",
      "he -> Timoteo\n",
      "his -> Timoteo\n",
      "he -> Timoteo\n",
      "His -> Timoteo\n",
      "him -> Timoteo\n",
      "his -> Timoteo\n",
      "He -> Timoteo\n",
      "his -> Timoteo\n",
      "he -> Timoteo\n",
      "she -> her,\n",
      "her -> her,\n",
      "her -> Italia\n",
      "she -> Italia\n",
      "she -> Italia\n",
      "her -> Italia\n",
      "her -> her,\n",
      "she -> Italia\n",
      "she -> Italia\n",
      "her -> Italia\n",
      "she -> Italia\n",
      "her -> Italia\n",
      "her -> Italia\n",
      "her -> Italia\n",
      "she -> Italia\n",
      "her -> Italia\n",
      "She -> Italia\n",
      "her -> Italia\n",
      "She -> Italia\n",
      "her -> Italia\n",
      "her -> Elsa\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 60.89 examples/s]\n",
      "12/15/2023 14:22:24 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 48.41it/s]\n",
      "12/15/2023 14:22:24 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "her -> Gigi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 181.30 examples/s]\n",
      "12/15/2023 14:22:24 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 42.11it/s]\n",
      "12/15/2023 14:22:24 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "her -> Deepika\n",
      "her -> Deepika\n",
      "her -> Deepika\n",
      "she -> Deepika\n",
      "her -> Deepika\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 430.85 examples/s]\n",
      "12/15/2023 14:22:24 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 29.95it/s]\n",
      "12/15/2023 14:22:24 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "he -> Cabot\n",
      "He -> Cabot\n",
      "her -> Talena\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 90.78 examples/s]\n",
      "12/15/2023 14:22:24 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 58.39it/s]\n",
      "12/15/2023 14:22:24 - INFO - \t Tokenize 1 inputs...\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 62.48 examples/s]\n",
      "12/15/2023 14:22:25 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 16.96it/s]\n",
      "12/15/2023 14:22:25 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "He -> Akhil\n",
      "him -> Akhil\n",
      "him -> Akhil\n",
      "his -> Akhil\n",
      "He -> Akhil\n",
      "he -> Akhil\n",
      "her -> Siri Valli\n",
      "her -> Sonu\n",
      "his -> Sonu\n",
      "his -> Sonu\n",
      "he -> Sonu\n",
      "he -> Sonu\n",
      "his -> Sonu\n",
      "his -> Sonu\n",
      "her -> Sasha\n",
      "her -> Sasha\n",
      "she -> Sasha\n",
      "she -> Sasha\n",
      "her -> Sasha\n",
      "she -> Sasha\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 123.93 examples/s]\n",
      "12/15/2023 14:22:25 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 48.55it/s]\n",
      "12/15/2023 14:22:25 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "her -> Joy\n",
      "her -> Joy\n",
      "She -> Joy\n",
      "Her -> Joy\n",
      "her -> Joy\n",
      "she -> Joy\n",
      "she -> Joy\n",
      "she -> Joy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<?, ? examples/s]\n",
      "12/15/2023 14:22:25 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 62.48it/s]\n",
      "12/15/2023 14:22:25 - INFO - \t Tokenize 1 inputs...\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 124.96 examples/s]\n",
      "12/15/2023 14:22:25 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 62.54it/s]\n",
      "12/15/2023 14:22:25 - INFO - \t Tokenize 1 inputs...\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 125.00 examples/s]\n",
      "12/15/2023 14:22:25 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 62.54it/s]\n",
      "12/15/2023 14:22:25 - INFO - \t Tokenize 1 inputs...\n",
      "Map: 100%|██████████| 1/1 [00:00<?, ? examples/s]\n",
      "12/15/2023 14:22:25 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 41.68it/s]\n",
      "12/15/2023 14:22:25 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "she -> Mary\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 47.56 examples/s]\n",
      "12/15/2023 14:22:25 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 10.90it/s]\n",
      "12/15/2023 14:22:25 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "He -> Ravi\n",
      "him -> Ravi\n",
      "he -> Ravi\n",
      "he -> Ravi\n",
      "him -> Swaminathan\n",
      "his -> Swaminathan\n",
      "his -> Swaminathan\n",
      "he -> Victor,\n",
      "him -> Kiran\n",
      "his -> Kiran\n",
      "his -> Kiran\n",
      "his -> Bhatta\n",
      "his -> Bhatta\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 124.31 examples/s]\n",
      "12/15/2023 14:22:25 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 38.05it/s]\n",
      "12/15/2023 14:22:25 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "her -> Shelby\n",
      "her -> Shelby\n",
      "she -> Shelby\n",
      "she -> Shelby\n",
      "her -> Shelby\n",
      "her -> Shelby\n",
      "she -> Shelby\n",
      "her -> Shelby\n",
      "his -> Lute\n",
      "his -> Lute\n",
      "him -> Meade\n",
      "her -> Corrine\n",
      "she -> Corrine\n",
      "She -> Corrine\n",
      "her -> Corrine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<?, ? examples/s]\n",
      "12/15/2023 14:22:25 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "his -> Takayama\n",
      "his -> Takayama\n",
      "his -> Takayama\n",
      "her -> Reiko\n",
      "he -> Yoshino\n",
      "He -> Yoshino\n",
      "he -> Yoshino\n",
      "she -> Mai Takano\n",
      "she -> Mai Takano\n",
      "she -> Mai\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12/15/2023 14:22:25 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "she -> Mai\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<?, ? examples/s]\n",
      "12/15/2023 14:22:25 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 60.28it/s]\n",
      "12/15/2023 14:22:26 - INFO - \t Tokenize 1 inputs...\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 154.09 examples/s]\n",
      "12/15/2023 14:22:26 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 42.08it/s]\n",
      "12/15/2023 14:22:26 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "he -> James Parker\n",
      "his -> James Parker\n",
      "her -> her,\n",
      "her -> her,\n",
      "she -> Jane,\n",
      "she -> Jane,\n",
      "her -> Jane,\n",
      "her -> Jane,\n",
      "She -> Jane,\n",
      "her -> Jane,\n",
      "her -> Jane,\n",
      "her -> Jane,\n",
      "her -> Jane,\n",
      "she -> Jane,\n",
      "she -> Jane's\n",
      "he -> Tarzan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 201.64 examples/s]\n",
      "12/15/2023 14:22:26 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 40.12it/s]\n",
      "12/15/2023 14:22:26 - INFO - \t Tokenize 1 inputs...\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 61.25 examples/s]\n",
      "12/15/2023 14:22:26 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.63it/s]\n",
      "12/15/2023 14:22:26 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "his -> Cliff Spab\n",
      "he -> Cliff\n",
      "his -> Cliff\n",
      "his -> Cliff\n",
      "his -> Cliff\n",
      "his -> Cliff\n",
      "He -> Cliff\n",
      "his -> Cliff\n",
      "his -> Cliff\n",
      "him -> Cliff\n",
      "his -> Cliff\n",
      "he -> Cliff\n",
      "he -> Cliff\n",
      "his -> Cliff\n",
      "His -> Cliff\n",
      "he -> Cliff\n",
      "he -> Cliff\n",
      "his -> Cliff\n",
      "his -> Cliff\n",
      "he -> Cliff\n",
      "his -> Cliff\n",
      "his -> Cliff\n",
      "he -> Cliff\n",
      "his -> Cliff\n",
      "He -> Cliff\n",
      "him -> Cliff\n",
      "his -> Cliff\n",
      "his -> Cliff\n",
      "him -> Cliff\n",
      "he -> Cliff\n",
      "his -> Cliff\n",
      "he -> Cliff\n",
      "he -> Cliff\n",
      "he -> Cliff\n",
      "her -> Wendy\n",
      "She -> Babs\n",
      "her -> Babs\n",
      "Her -> Babs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 59.90 examples/s]\n",
      "12/15/2023 14:22:26 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 45.78it/s]\n",
      "12/15/2023 14:22:26 - INFO - \t Tokenize 1 inputs...\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 56.65 examples/s]\n",
      "12/15/2023 14:22:26 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00,  9.99it/s]\n",
      "12/15/2023 14:22:26 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "her -> Mei\n",
      "She -> Mei\n",
      "Her -> Mei\n",
      "her -> Mei\n",
      "she -> Mei\n",
      "her -> Mei\n",
      "her -> Mei\n",
      "her -> Mei,\n",
      "his -> Seng\n",
      "he -> Seng\n",
      "his -> Seng\n",
      "He -> Seng\n",
      "his -> Seng\n",
      "his -> Seng\n",
      "he -> Seng\n",
      "He -> Seng\n",
      "his -> Seng\n",
      "him -> Seng\n",
      "his -> Seng\n",
      "he -> Seng\n",
      "his -> Seng\n",
      "she -> Irene\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 56.92 examples/s]\n",
      "12/15/2023 14:22:26 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 31.27it/s]\n",
      "12/15/2023 14:22:26 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "he -> Laurel\n",
      "he -> Laurel\n",
      "He -> Ollie\n",
      "his -> Ollie\n",
      "he -> Ollie\n",
      "their -> Laurel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<?, ? examples/s]\n",
      "12/15/2023 14:22:26 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 34.19it/s]\n",
      "12/15/2023 14:22:26 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "his -> Kent\n",
      "he -> Destry\n",
      "He -> Destry\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 641.53 examples/s]\n",
      "12/15/2023 14:22:26 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 40.76it/s]\n",
      "12/15/2023 14:22:26 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "her -> Nan Taylor\n",
      "her -> Nan Taylor\n",
      "her -> Nan Taylor\n",
      "she -> Nan Taylor\n",
      "she -> Nan Taylor\n",
      "her -> Nan Taylor\n",
      "she -> Nan Taylor\n",
      "her -> Nan Taylor\n",
      "her -> Nan Taylor\n",
      "she -> Nan Taylor\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 61.05 examples/s]\n",
      "12/15/2023 14:22:26 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.06it/s]\n",
      "12/15/2023 14:22:27 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "she -> the girl\n",
      "she -> Emily\n",
      "her -> Emily\n",
      "her -> Emily\n",
      "she -> Emily\n",
      "her -> Emily\n",
      "her -> Emily\n",
      "her -> Emily\n",
      "her -> Emily\n",
      "her -> Emily\n",
      "her -> Emily\n",
      "her -> Diego\n",
      "he -> Barron\n",
      "his -> Barron\n",
      "He -> Barron\n",
      "he -> Barron\n",
      "him -> Barron\n",
      "he -> Barron\n",
      "his -> Douglas\n",
      "he -> Douglas\n",
      "his -> Douglas\n",
      "his -> Douglas\n",
      "his -> Douglas\n",
      "his -> Douglas\n",
      "her -> Lilith\n",
      "her -> Lilith\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 55.85 examples/s]\n",
      "12/15/2023 14:22:27 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "her -> Kristi\n",
      "she -> Kristi\n",
      "her -> Kristi\n",
      "she -> his wife\n",
      "she -> Kristi\n",
      "her -> Kristi\n",
      "her -> Kristi\n",
      "her -> Kristi\n",
      "him -> Dan\n",
      "he -> Dan\n",
      "him -> Dan\n",
      "he -> Dan\n",
      "he -> Dan\n",
      "him -> Dan\n",
      "his -> Dan\n",
      "him -> Dan\n",
      "he -> Dan\n",
      "He -> Dan\n",
      "his -> Dan\n",
      "her -> Katie\n",
      "her -> Katie\n",
      "her -> Katie\n",
      "She -> Katie\n",
      "she -> Katie\n",
      "She -> Katie,\n",
      "She -> Ali\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12/15/2023 14:22:27 - INFO - \t Tokenize 1 inputs...\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 118.48 examples/s]\n",
      "12/15/2023 14:22:27 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 77.15it/s]\n",
      "12/15/2023 14:22:27 - INFO - \t Tokenize 1 inputs...\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 212.23 examples/s]\n",
      "12/15/2023 14:22:27 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.44it/s]\n",
      "12/15/2023 14:22:27 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "he -> Emery\n",
      "He -> Emery\n",
      "his -> Emery\n",
      "He -> Emery\n",
      "He -> Emery\n",
      "He -> Emery\n",
      "his -> Emery\n",
      "him -> Emery\n",
      "him -> Emery\n",
      "him -> Emery\n",
      "He -> Emery\n",
      "she -> Emery\n",
      "she -> Emery\n",
      "She -> Emery\n",
      "her -> Emery\n",
      "He -> Emery\n",
      "he -> Emery\n",
      "She -> Emery\n",
      "she -> Emery\n",
      "her -> Emery\n",
      "he -> Brandon\n",
      "he -> Brandon\n",
      "he -> Brandon\n",
      "he -> Brandon\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<?, ? examples/s]\n",
      "12/15/2023 14:22:27 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 47.21it/s]\n",
      "12/15/2023 14:22:27 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "his -> Pete\n",
      "his -> Pete\n",
      "he -> Pete\n",
      "his -> Pete\n",
      "his -> Pete\n",
      "he -> Pete\n",
      "he -> Jusa\n",
      "her -> Kata\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 107.08 examples/s]\n",
      "12/15/2023 14:22:27 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 21.11it/s]\n",
      "12/15/2023 14:22:27 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "he -> Barton\n",
      "he -> Barton\n",
      "his -> Barton\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 62.85 examples/s]\n",
      "12/15/2023 14:22:27 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 28.47it/s]\n",
      "12/15/2023 14:22:27 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "his -> Cyrus\n",
      "his -> Cyrus\n",
      "his -> Cyrus\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 35.99 examples/s]\n",
      "12/15/2023 14:22:27 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00,  5.46it/s]\n",
      "12/15/2023 14:22:28 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "he -> it\n",
      "his -> it\n",
      "his -> Sengodan\n",
      "he -> Sengodan\n",
      "he -> Sengodan\n",
      "he -> Sengodan\n",
      "his -> Sengodan\n",
      "he -> Sengodan\n",
      "her -> it\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 76.56 examples/s]\n",
      "12/15/2023 14:22:28 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.54it/s]\n",
      "12/15/2023 14:22:28 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "he -> Shakti\n",
      "his -> Shakti\n",
      "him -> Shakti\n",
      "his -> Shakti\n",
      "he -> Shakti\n",
      "he -> Shakti\n",
      "his -> Shakti\n",
      "him -> Shakti\n",
      "his -> Shakti\n",
      "his -> Shakti\n",
      "his -> Kirikalam\n",
      "her -> Velli\n",
      "her -> Velli\n",
      "his -> Velli\n",
      "his -> Velli\n",
      "her -> her,\n",
      "her -> her,\n",
      "he -> Manivannan\n",
      "He -> Manivannan\n",
      "them -> the police\n",
      "them -> the police\n",
      "He -> Kannan\n",
      "he -> Kannan\n",
      "he -> Kannan\n",
      "him -> Kannan\n",
      "his -> Kannan\n",
      "his -> Kannan\n",
      "he -> Kannan\n",
      "he -> Kannan\n",
      "his -> Kannan\n",
      "his -> Kannan\n",
      "He -> Kannan\n",
      "his -> Kannan\n",
      "his -> Kannan\n",
      "he -> Kannan\n",
      "his -> Kannan\n",
      "she -> Jyoti\n",
      "She -> Jyoti\n",
      "her -> Anna\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 124.09 examples/s]\n",
      "12/15/2023 14:22:28 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 46.61it/s]\n",
      "12/15/2023 14:22:28 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "he -> Karthik\n",
      "him -> Karthik\n",
      "his -> Karthik\n",
      "he -> Karthik\n",
      "him -> Karthik\n",
      "his -> Karthik\n",
      "her -> Bhanumati\n",
      "her -> Bhanumati\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 175.44 examples/s]\n",
      "12/15/2023 14:22:28 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 118.89it/s]\n",
      "12/15/2023 14:22:28 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "her -> Betty\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<?, ? examples/s]\n",
      "12/15/2023 14:22:28 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 64.33it/s]\n",
      "12/15/2023 14:22:28 - INFO - \t Tokenize 1 inputs...\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 195.53 examples/s]\n",
      "12/15/2023 14:22:28 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 60.75it/s]\n",
      "12/15/2023 14:22:28 - INFO - \t Tokenize 1 inputs...\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 54.62 examples/s]\n",
      "12/15/2023 14:22:28 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00,  4.72it/s]\n",
      "12/15/2023 14:22:29 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "he -> Ross\n",
      "He -> Ross\n",
      "he -> Ross\n",
      "he -> Ross\n",
      "he -> Ross\n",
      "him -> Ross\n",
      "they -> people\n",
      "her -> Armitage\n",
      "she -> Armitage\n",
      "She -> Armitage\n",
      "her -> Armitage\n",
      "he -> Armitage\n",
      "he -> Armitage\n",
      "She -> Armitage\n",
      "he -> Armitage\n",
      "her -> Armitage\n",
      "She -> Armitage\n",
      "her -> Armitage\n",
      "She -> Armitage\n",
      "her -> Asakura\n",
      "hers -> Asakura\n",
      "she -> Naomi\n",
      "she -> Naomi\n",
      "she -> Naomi\n",
      "She -> Naomi\n",
      "her -> Naomi\n",
      "her -> Naomi\n",
      "her -> Naomi\n",
      "her -> Naomi\n",
      "she -> Naomi\n",
      "her -> Naomi\n",
      "she -> Naomi\n",
      "She -> Naomi\n",
      "her -> Naomi\n",
      "he -> Mouse\n",
      "he -> Mouse\n",
      "he -> Mouse\n",
      "he -> Mouse\n",
      "He -> Demetrio\n",
      "him -> Demetrio\n",
      "his -> Demetrio\n",
      "him -> Demetrio\n",
      "him -> Demetrio\n",
      "he -> Demetrio\n",
      "him -> Demetrio\n",
      "him -> Demetrio\n",
      "He -> Demetrio\n",
      "him -> Demetrio\n",
      "her -> Yoko\n",
      "her -> Yoko\n",
      "she -> Yoko\n",
      "she -> Yoko\n",
      "she -> Yoko\n",
      "she -> Yoko\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 407.33 examples/s]\n",
      "12/15/2023 14:22:29 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00,  9.44it/s]\n",
      "12/15/2023 14:22:29 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "him -> Govind\n",
      "he -> Govind\n",
      "He -> Govind\n",
      "him -> Govind\n",
      "He -> Govind\n",
      "he -> Govind\n",
      "he -> Govind\n",
      "He -> Govind\n",
      "her -> Jasmine\n",
      "his -> Avatar Singh\n",
      "his -> Avatar Singh\n",
      "he -> Avatar Singh\n",
      "her -> Krishnaveni\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 133.80 examples/s]\n",
      "12/15/2023 14:22:29 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 39.48it/s]\n",
      "12/15/2023 14:22:29 - INFO - \t Tokenize 1 inputs...\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 640.35 examples/s]\n",
      "12/15/2023 14:22:29 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 45.28it/s]\n",
      "12/15/2023 14:22:29 - INFO - \t Tokenize 1 inputs...\n",
      "Map: 100%|██████████| 1/1 [00:00<?, ? examples/s]\n",
      "12/15/2023 14:22:29 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 24.19it/s]\n",
      "12/15/2023 14:22:29 - INFO - \t Tokenize 1 inputs...\n",
      "Map: 100%|██████████| 1/1 [00:00<?, ? examples/s]\n",
      "12/15/2023 14:22:29 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 65.02it/s]\n",
      "12/15/2023 14:22:29 - INFO - \t Tokenize 1 inputs...\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 167.70 examples/s]\n",
      "12/15/2023 14:22:29 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 15.66it/s]\n",
      "12/15/2023 14:22:29 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "her -> Mitchie\n",
      "she -> Mitchie\n",
      "her -> Mitchie\n",
      "She -> Mitchie\n",
      "she -> Mitchie\n",
      "her -> Mitchie\n",
      "her -> Mitchie\n",
      "his -> Shane\n",
      "his -> Shane\n",
      "he -> Shane\n",
      "him -> Shane\n",
      "him -> Shane\n",
      "he -> Shane\n",
      "He -> Shane\n",
      "her -> Tess\n",
      "she -> Tess\n",
      "her -> Tess\n",
      "her -> Tess\n",
      "her -> Tess\n",
      "she -> Tess\n",
      "her -> Tess\n",
      "her -> Tess\n",
      "she -> Caitlyn\n",
      "her -> Caitlyn\n",
      "her -> Caitlyn\n",
      "her -> Caitlyn\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 93.27 examples/s]\n",
      "12/15/2023 14:22:29 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 52.43it/s]\n",
      "12/15/2023 14:22:29 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "her -> Camille\n",
      "She -> Camille\n",
      "her -> Camille\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 115.29 examples/s]\n",
      "12/15/2023 14:22:29 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 52.54it/s]\n",
      "12/15/2023 14:22:29 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "him -> Alberto\n",
      "his -> Alberto\n",
      "his -> Alberto\n",
      "his -> Alberto\n",
      "he -> Alberto\n",
      "his -> Alberto\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 225.73 examples/s]\n",
      "12/15/2023 14:22:29 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 44.46it/s]\n",
      "12/15/2023 14:22:29 - INFO - \t Tokenize 1 inputs...\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 124.99 examples/s]\n",
      "12/15/2023 14:22:29 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 19.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "he -> Dietrich\n",
      "He -> Dietrich\n",
      "He -> Dietrich\n",
      "his -> Dietrich\n",
      "his -> Dietrich\n",
      "he -> Dietrich\n",
      "his -> Dietrich\n",
      "he -> Dietrich\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12/15/2023 14:22:30 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "he -> Briggs\n",
      "He -> Briggs\n",
      "her -> Gebhardt\n",
      "She -> Gebhardt\n",
      "her -> Gebhardt\n",
      "her -> Gebhardt\n",
      "she -> Gebhardt\n",
      "she -> Gebhardt\n",
      "she -> Gebhardt\n",
      "her -> Gebhardt\n",
      "he -> Roper\n",
      "his -> Roper\n",
      "he -> Roper\n",
      "his -> Roper\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 127.13 examples/s]\n",
      "12/15/2023 14:22:30 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00,  9.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "he -> Bibble\n",
      "his -> Bibble\n",
      "him -> Bibble\n",
      "her -> Mariposa\n",
      "she -> Mariposa\n",
      "her -> Mariposa\n",
      "her -> Mariposa\n",
      "she -> Mariposa\n",
      "she -> Mariposa\n",
      "she -> Mariposa\n",
      "her -> Mariposa\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "she -> Mariposa\n",
      "she -> Henna\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12/15/2023 14:22:30 - INFO - \t Tokenize 1 inputs...\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 51.98 examples/s]\n",
      "12/15/2023 14:22:30 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.83it/s]\n",
      "12/15/2023 14:22:30 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "he -> Andrew\n",
      "his -> Andrew\n",
      "him -> Andrew\n",
      "his -> Andrew\n",
      "him -> Andrew's\n",
      "he -> Andrew\n",
      "his -> Andrew\n",
      "him -> Andrew\n",
      "he -> Andrew\n",
      "his -> Andrew's\n",
      "him -> Andrew\n",
      "He -> Andrew\n",
      "his -> Andrew\n",
      "he -> Andrew\n",
      "he -> Andrew\n",
      "he -> Andrew\n",
      "He -> Andrew\n",
      "he -> Andrew\n",
      "he -> Andrew\n",
      "he -> Andrew\n",
      "his -> Andrew\n",
      "his -> Andrew\n",
      "him -> Andrew\n",
      "him -> Andrew\n",
      "he -> Andrew\n",
      "He -> Andrew\n",
      "him -> Andrew\n",
      "his -> Andrew Martin\n",
      "him -> Andrew,\n",
      "he -> The CEO\n",
      "He -> Martin's\n",
      "his -> Martin\n",
      "him -> Martin\n",
      "he -> Martin\n",
      "his -> Martin\n",
      "her -> Little Miss\n",
      "her -> Little Miss\n",
      "she -> Little Miss\n",
      "She -> Little Miss\n",
      "his -> Rupert\n",
      "his -> Rupert\n",
      "him -> Rupert\n",
      "her -> Portia\n",
      "her -> Portia\n",
      "her -> Portia\n",
      "she -> Portia\n",
      "her -> Portia\n",
      "she -> Portia\n",
      "she -> Portia\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 124.78 examples/s]\n",
      "12/15/2023 14:22:30 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 20.61it/s]\n",
      "12/15/2023 14:22:30 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "he -> Daffy Duck\n",
      "his -> Daffy\n",
      "him -> Daffy\n",
      "his -> Daffy\n",
      "him -> Daffy\n",
      "his -> Daffy\n",
      "He -> Daffy\n",
      "he -> Daffy\n",
      "his -> Daffy\n",
      "he -> Daffy\n",
      "he -> Daffy\n",
      "him -> the butler\n",
      "him -> the butler\n",
      "his -> the butler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 68.21 examples/s]\n",
      "12/15/2023 14:22:30 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00,  9.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "his -> Henry\n",
      "him -> Henry\n",
      "He -> Henry\n",
      "he -> Henry\n",
      "his -> Henry\n",
      "him -> Henry\n",
      "he -> Henry\n",
      "his -> Henry\n",
      "He -> Henry\n",
      "He -> Henry\n",
      "he -> Henry\n",
      "He -> Henry\n",
      "his -> Henry\n",
      "He -> Henry\n",
      "her -> Becky\n",
      "her -> Becky\n",
      "her -> Becky\n",
      "her -> Becky\n",
      "her -> Becky\n",
      "she -> Becky\n",
      "her -> Becky\n",
      "she -> Becky\n",
      "her -> Becky\n",
      "her -> Becky\n",
      "she -> Becky\n",
      "her -> Becky\n",
      "her -> Becky\n",
      "her -> Becky\n",
      "she -> Becky\n",
      "her -> Becky\n",
      "he -> Otis\n",
      "He -> Otis\n",
      "him -> Otis\n",
      "he -> Otis\n",
      "him -> Otis\n",
      "his -> Otis\n",
      "she -> his mother\n",
      "they -> police\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12/15/2023 14:22:30 - INFO - \t Tokenize 1 inputs...\n",
      "Map: 100%|██████████| 1/1 [00:00<?, ? examples/s]\n",
      "12/15/2023 14:22:30 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 40.49it/s]\n",
      "12/15/2023 14:22:30 - INFO - \t Tokenize 1 inputs...\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 161.03 examples/s]\n",
      "12/15/2023 14:22:30 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 62.03it/s]\n",
      "12/15/2023 14:22:30 - INFO - \t Tokenize 1 inputs...\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 125.01 examples/s]\n",
      "12/15/2023 14:22:30 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 31.17it/s]\n",
      "12/15/2023 14:22:31 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "His -> Sonny\n",
      "him -> Sonny\n",
      "his -> Sonny\n",
      "his -> Sonny\n",
      "him -> Sonny\n",
      "him -> Sonny\n",
      "his -> Sonny\n",
      "He -> Sonny\n",
      "his -> Sonny\n",
      "his -> Sonny\n",
      "He -> Sonny\n",
      "he -> Sonny\n",
      "him -> Sonny\n",
      "He -> Sonny\n",
      "he -> Sonny\n",
      "his -> Sonny\n",
      "him -> Sonny\n",
      "his -> Sonny\n",
      "he -> Sonny\n",
      "him -> Horace\n",
      "they -> the police\n",
      "they -> the police\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 110.90 examples/s]\n",
      "12/15/2023 14:22:31 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 53.96it/s]\n",
      "12/15/2023 14:22:31 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "she -> Jasmine\n",
      "her -> Jasmine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<?, ? examples/s]\n",
      "12/15/2023 14:22:31 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 35.04it/s]\n",
      "12/15/2023 14:22:31 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "her -> his daughter\n",
      "her -> his daughter\n",
      "her -> his daughter\n",
      "her -> his daughter\n",
      "her -> his daughter\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 135.48 examples/s]\n",
      "12/15/2023 14:22:31 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 15.81it/s]\n",
      "12/15/2023 14:22:31 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "them -> all\n",
      "they -> all\n",
      "her -> Tuffy\n",
      "his -> the boy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 54.37 examples/s]\n",
      "12/15/2023 14:22:31 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.70it/s]\n",
      "12/15/2023 14:22:31 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "their -> its\n",
      "They -> its\n",
      "they -> its\n",
      "They -> its\n",
      "his -> Blake\n",
      "he -> Blake\n",
      "he -> Blake\n",
      "him -> Blake\n",
      "his -> Blake\n",
      "He -> Rig\n",
      "she -> Lucy Draper\n",
      "he -> Gennero\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 43.41 examples/s]\n",
      "12/15/2023 14:22:31 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00,  4.76it/s]\n",
      "12/15/2023 14:22:31 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "he -> Friar\n",
      "He -> Friar\n",
      "he -> Friar\n",
      "he -> Friar\n",
      "He -> Friar\n",
      "he -> Friar\n",
      "he -> Friar\n",
      "he -> Friar\n",
      "he -> Friar\n",
      "his -> Friar\n",
      "him -> Friar\n",
      "he -> Friar\n",
      "him -> Friar\n",
      "his -> Friar\n",
      "his -> Friar\n",
      "his -> Friar\n",
      "his -> Friar\n",
      "his -> Friar\n",
      "him -> Friar\n",
      "his -> Friar\n",
      "he -> Friar\n",
      "his -> Friar\n",
      "he -> Friar\n",
      "his -> Friar\n",
      "him -> Friar\n",
      "him -> Friar\n",
      "he -> Friar\n",
      "he -> Friar\n",
      "He -> Friar\n",
      "He -> Friar\n",
      "him -> Friar\n",
      "his -> Friar\n",
      "him -> Friar\n",
      "he -> Friar\n",
      "his -> Friar\n",
      "his -> Friar\n",
      "he -> Friar\n",
      "He -> Friar\n",
      "He -> Friar\n",
      "his -> Friar\n",
      "him -> Friar\n",
      "him -> Friar\n",
      "he -> Friar\n",
      "his -> Friar\n",
      "he -> Friar\n",
      "her -> her,\n",
      "her -> her,\n",
      "He -> Hoop\n",
      "he -> Hoop\n",
      "he -> Hoop\n",
      "he -> Hoop\n",
      "He -> Tyrone\n",
      "he -> Tyrone\n",
      "he -> Tyrone\n",
      "his -> Tyrone\n",
      "his -> Tyrone\n",
      "his -> Tyrone\n",
      "him -> Tyrone\n",
      "he -> Tyrone\n",
      "She -> Erin\n",
      "her -> Erin\n",
      "She -> Erin\n",
      "she -> Erin\n",
      "She -> Erin\n",
      "her -> Erin\n",
      "she -> Erin\n",
      "she -> Erin\n",
      "she -> Erin\n",
      "she -> Erin\n",
      "her -> Erin\n",
      "her -> Erin\n",
      "she -> Erin\n",
      "she -> Erin\n",
      "she -> Erin\n",
      "she -> Erin\n",
      "she -> Erin\n",
      "She -> Erin\n",
      "her -> Erin\n",
      "her -> Erin\n",
      "she -> Erin\n",
      "her -> Erin\n",
      "She -> Erin\n",
      "her -> Erin\n",
      "her -> Erin\n",
      "her -> Erin\n",
      "her -> Erin\n",
      "she -> Erin\n",
      "she -> Erin\n",
      "her -> Erin\n",
      "her -> Erin\n",
      "her -> Erin's\n",
      "her -> Erin's\n",
      "her -> Erin\n",
      "she -> Erin\n",
      "she -> Erin\n",
      "she -> Erin\n",
      "She -> Erin\n",
      "her -> Erin\n",
      "she -> Erin\n",
      "he -> David\n",
      "his -> David\n",
      "his -> David\n",
      "he -> David\n",
      "he -> David\n",
      "he -> David\n",
      "He -> David\n",
      "he -> David\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 97.93 examples/s]\n",
      "12/15/2023 14:22:31 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 10.74it/s]\n",
      "12/15/2023 14:22:31 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "her -> Lilly\n",
      "her -> Lilly\n",
      "her -> Lilly\n",
      "she -> Lilly\n",
      "she -> Lilly\n",
      "her -> Lilly\n",
      "her -> Lilly\n",
      "her -> Lilly\n",
      "her -> Lilly Wust\n",
      "her -> Felice\n",
      "her -> Felice\n",
      "her -> Felice\n",
      "She -> Felice\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<?, ? examples/s]\n",
      "12/15/2023 14:22:32 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 17.38it/s]\n",
      "12/15/2023 14:22:32 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "her -> Bianca\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 110.08 examples/s]\n",
      "12/15/2023 14:22:32 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 17.31it/s]\n",
      "12/15/2023 14:22:32 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "He -> Adam\n",
      "his -> Adam\n",
      "he -> Adam\n",
      "he -> Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 119.32 examples/s]\n",
      "12/15/2023 14:22:32 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.73it/s]\n",
      "12/15/2023 14:22:32 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "him -> Brewster's\n",
      "he -> Brewster's\n",
      "his -> Brewster\n",
      "his -> Brewster\n",
      "his -> Brewster\n",
      "his -> Brewster\n",
      "his -> Brewster\n",
      "he -> Brewster\n",
      "his -> Brewster\n",
      "his -> Brewster\n",
      "him -> Brewster\n",
      "he -> Brewster\n",
      "his -> Brewster\n",
      "his -> Brewster\n",
      "he -> Brewster's\n",
      "his -> Brewster's\n",
      "him -> Brewster\n",
      "He -> Brewster\n",
      "he -> Brewster\n",
      "his -> Brewster\n",
      "his -> Brewster\n",
      "him -> Brewster\n",
      "his -> Brewster\n",
      "he -> Brewster\n",
      "his -> Brewster\n",
      "her -> Peggy\n",
      "her -> Peggy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 71.54 examples/s]\n",
      "12/15/2023 14:22:32 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.04it/s]\n",
      "12/15/2023 14:22:32 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "she -> Zoe\n",
      "she -> Zoe\n",
      "her -> Zoe\n",
      "her -> Zoe\n",
      "she -> Zoe\n",
      "his -> Danny\n",
      "he -> Danny\n",
      "his -> Danny\n",
      "his -> Danny\n",
      "him -> Danny\n",
      "he -> Danny\n",
      "he -> Danny\n",
      "him -> Danny\n",
      "he -> Danny\n",
      "his -> Danny\n",
      "he -> Danny\n",
      "she -> Anna\n",
      "her -> Anna\n",
      "he -> Bolt\n",
      "his -> Bolt\n",
      "him -> Waldo\n",
      "he -> Waldo\n",
      "he -> Waldo\n",
      "he -> Waldo\n",
      "he -> Waldo\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<?, ? examples/s]\n",
      "12/15/2023 14:22:32 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 17.27it/s]\n",
      "12/15/2023 14:22:32 - INFO - \t Tokenize 1 inputs...\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 60.21 examples/s]\n",
      "12/15/2023 14:22:32 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.10it/s]\n",
      "12/15/2023 14:22:32 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "he -> its\n",
      "He -> its\n",
      "his -> its\n",
      "he -> its\n",
      "He -> its\n",
      "his -> its\n",
      "his -> its\n",
      "He -> Beaumont\n",
      "he -> Beaumont\n",
      "her -> Alexandra\n",
      "his -> Josh\n",
      "his -> Josh\n",
      "He -> Josh\n",
      "her -> Alex\n",
      "her -> Alex\n",
      "She -> Alex\n",
      "her -> Alex\n",
      "her -> Alex\n",
      "she -> Alex\n",
      "He -> Alex\n",
      "her -> Alex\n",
      "her -> Alex\n",
      "He -> Alex\n",
      "her -> Alex\n",
      "She -> Alex\n",
      "her -> Alex\n",
      "her -> Alex\n",
      "her -> Alex\n",
      "she -> Alex\n",
      "her -> Alex\n",
      "She -> Alex\n",
      "she -> Alex\n",
      "their -> people\n",
      "his -> Beaumont\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 134.98 examples/s]\n",
      "12/15/2023 14:22:32 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 16.61it/s]\n",
      "12/15/2023 14:22:32 - INFO - \t Tokenize 1 inputs...\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 64.00 examples/s]\n",
      "12/15/2023 14:22:32 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 41.14it/s]\n",
      "12/15/2023 14:22:33 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "she -> Barbara 'Ching-Ching' Stewart\n",
      "she -> Barbara\n",
      "her -> Barbara\n",
      "her -> Barbara\n",
      "she -> Barbara\n",
      "her -> Susan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 247.09 examples/s]\n",
      "12/15/2023 14:22:33 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.59it/s]\n",
      "12/15/2023 14:22:33 - INFO - \t Tokenize 1 inputs...\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 194.40 examples/s]\n",
      "12/15/2023 14:22:33 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 17.73it/s]\n",
      "12/15/2023 14:22:33 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "he -> Zhu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 301.49 examples/s]\n",
      "12/15/2023 14:22:33 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 15.07it/s]\n",
      "12/15/2023 14:22:33 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "his -> Jaya\n",
      "his -> Jaya\n",
      "He -> Jaya\n",
      "his -> Jaya\n",
      "her -> Noor\n",
      "she -> Noor\n",
      "her -> Noor\n",
      "she -> Noor\n",
      "her -> Noor\n",
      "his -> Madakari Nayaka\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 62.24 examples/s]\n",
      "12/15/2023 14:22:33 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 10.06it/s]\n",
      "12/15/2023 14:22:33 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "him -> Shawn\n",
      "he -> Shawn\n",
      "He -> Shawn\n",
      "he -> Shawn\n",
      "him -> Shawn\n",
      "him -> Shawn\n",
      "her -> Maddy\n",
      "she -> Maddy\n",
      "her -> Maddy\n",
      "she -> Maddy\n",
      "her -> Maddy\n",
      "her -> Maddy\n",
      "she -> Maddy\n",
      "she -> Maddy\n",
      "she -> Maddy\n",
      "her -> Maddy\n",
      "she -> Maddy\n",
      "her -> Maddy\n",
      "her -> Maddy\n",
      "Her -> Maddy\n",
      "she -> Maddy's\n",
      "She -> Maddy\n",
      "she -> Maddy\n",
      "her -> Maddy\n",
      "her -> Maddy\n",
      "her -> Maddy\n",
      "She -> Maddy\n",
      "She -> Maddy\n",
      "She -> Maddy\n",
      "her -> Maddy\n",
      "she -> Maddy\n",
      "She -> Maddy\n",
      "he -> Chris\n",
      "he -> Chris\n",
      "He -> Chris\n",
      "his -> Chris\n",
      "he -> Chris\n",
      "him -> Chris\n",
      "He -> Chris\n",
      "he -> Chris\n",
      "He -> Chris\n",
      "He -> Chris\n",
      "she -> Tillie\n",
      "she -> Tillie\n",
      "her -> Tillie\n",
      "She -> Tillie\n",
      "she -> Tillie\n",
      "she -> Tillie\n",
      "she -> Tillie\n",
      "She -> Tillie\n",
      "She -> Tillie\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 201.62 examples/s]\n",
      "12/15/2023 14:22:33 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 19.66it/s]\n",
      "12/15/2023 14:22:33 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m text_split \u001b[38;5;241m=\u001b[39m text\u001b[38;5;241m.\u001b[39msplit()\n\u001b[0;32m      6\u001b[0m resolved_text \u001b[38;5;241m=\u001b[39m text\u001b[38;5;241m.\u001b[39msplit()\n\u001b[1;32m----> 7\u001b[0m preds \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtexts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_split_into_words\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[0;32m     10\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m clusters \u001b[38;5;241m=\u001b[39m preds\u001b[38;5;241m.\u001b[39mget_clusters(as_strings\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m cluster \u001b[38;5;129;01min\u001b[39;00m clusters:\n",
      "File \u001b[1;32md:\\APPS\\Anaconda\\envs\\ML\\Lib\\site-packages\\fastcoref\\modeling.py:262\u001b[0m, in \u001b[0;36mCorefModel.predict\u001b[1;34m(self, texts, is_split_into_words, max_tokens_in_batch, output_file)\u001b[0m\n\u001b[0;32m    259\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_batched:\n\u001b[0;32m    260\u001b[0m     texts \u001b[38;5;241m=\u001b[39m [texts]\n\u001b[1;32m--> 262\u001b[0m dataset \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_split_into_words\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    263\u001b[0m dataloader \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_batches(dataset, max_tokens_in_batch)\n\u001b[0;32m    265\u001b[0m preds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inference(dataloader)\n",
      "File \u001b[1;32md:\\APPS\\Anaconda\\envs\\ML\\Lib\\site-packages\\fastcoref\\modeling.py:133\u001b[0m, in \u001b[0;36mCorefModel._create_dataset\u001b[1;34m(self, texts, is_split_into_words)\u001b[0m\n\u001b[0;32m    132\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_create_dataset\u001b[39m(\u001b[38;5;28mself\u001b[39m, texts, is_split_into_words):\n\u001b[1;32m--> 133\u001b[0m     \u001b[43mlogger\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minfo\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mTokenize \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m inputs...\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    135\u001b[0m     \u001b[38;5;66;03m# Save original text ordering for later use\u001b[39;00m\n\u001b[0;32m    136\u001b[0m     dataset \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m: texts, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124midx\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(texts))}\n",
      "File \u001b[1;32md:\\APPS\\Anaconda\\envs\\ML\\Lib\\logging\\__init__.py:1489\u001b[0m, in \u001b[0;36mLogger.info\u001b[1;34m(self, msg, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1480\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1481\u001b[0m \u001b[38;5;124;03mLog 'msg % args' with severity 'INFO'.\u001b[39;00m\n\u001b[0;32m   1482\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1486\u001b[0m \u001b[38;5;124;03mlogger.info(\"Houston, we have a %s\", \"interesting problem\", exc_info=1)\u001b[39;00m\n\u001b[0;32m   1487\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1488\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39misEnabledFor(INFO):\n\u001b[1;32m-> 1489\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_log\u001b[49m\u001b[43m(\u001b[49m\u001b[43mINFO\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\APPS\\Anaconda\\envs\\ML\\Lib\\logging\\__init__.py:1634\u001b[0m, in \u001b[0;36mLogger._log\u001b[1;34m(self, level, msg, args, exc_info, extra, stack_info, stacklevel)\u001b[0m\n\u001b[0;32m   1631\u001b[0m         exc_info \u001b[38;5;241m=\u001b[39m sys\u001b[38;5;241m.\u001b[39mexc_info()\n\u001b[0;32m   1632\u001b[0m record \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmakeRecord(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname, level, fn, lno, msg, args,\n\u001b[0;32m   1633\u001b[0m                          exc_info, func, extra, sinfo)\n\u001b[1;32m-> 1634\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrecord\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\APPS\\Anaconda\\envs\\ML\\Lib\\logging\\__init__.py:1644\u001b[0m, in \u001b[0;36mLogger.handle\u001b[1;34m(self, record)\u001b[0m\n\u001b[0;32m   1637\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1638\u001b[0m \u001b[38;5;124;03mCall the handlers for the specified record.\u001b[39;00m\n\u001b[0;32m   1639\u001b[0m \n\u001b[0;32m   1640\u001b[0m \u001b[38;5;124;03mThis method is used for unpickled records received from a socket, as\u001b[39;00m\n\u001b[0;32m   1641\u001b[0m \u001b[38;5;124;03mwell as those created locally. Logger-level filtering is applied.\u001b[39;00m\n\u001b[0;32m   1642\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1643\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdisabled) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilter(record):\n\u001b[1;32m-> 1644\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcallHandlers\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrecord\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\APPS\\Anaconda\\envs\\ML\\Lib\\logging\\__init__.py:1706\u001b[0m, in \u001b[0;36mLogger.callHandlers\u001b[1;34m(self, record)\u001b[0m\n\u001b[0;32m   1704\u001b[0m     found \u001b[38;5;241m=\u001b[39m found \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1705\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m record\u001b[38;5;241m.\u001b[39mlevelno \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m hdlr\u001b[38;5;241m.\u001b[39mlevel:\n\u001b[1;32m-> 1706\u001b[0m         \u001b[43mhdlr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrecord\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1707\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m c\u001b[38;5;241m.\u001b[39mpropagate:\n\u001b[0;32m   1708\u001b[0m     c \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m    \u001b[38;5;66;03m#break out\u001b[39;00m\n",
      "File \u001b[1;32md:\\APPS\\Anaconda\\envs\\ML\\Lib\\logging\\__init__.py:978\u001b[0m, in \u001b[0;36mHandler.handle\u001b[1;34m(self, record)\u001b[0m\n\u001b[0;32m    976\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39macquire()\n\u001b[0;32m    977\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 978\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43memit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrecord\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    979\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    980\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32md:\\APPS\\Anaconda\\envs\\ML\\Lib\\logging\\__init__.py:1114\u001b[0m, in \u001b[0;36mStreamHandler.emit\u001b[1;34m(self, record)\u001b[0m\n\u001b[0;32m   1112\u001b[0m     \u001b[38;5;66;03m# issue 35046: merged two stream.writes into one.\u001b[39;00m\n\u001b[0;32m   1113\u001b[0m     stream\u001b[38;5;241m.\u001b[39mwrite(msg \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mterminator)\n\u001b[1;32m-> 1114\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflush\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1115\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mRecursionError\u001b[39;00m:  \u001b[38;5;66;03m# See issue 36272\u001b[39;00m\n\u001b[0;32m   1116\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "File \u001b[1;32md:\\APPS\\Anaconda\\envs\\ML\\Lib\\logging\\__init__.py:1094\u001b[0m, in \u001b[0;36mStreamHandler.flush\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1092\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1093\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mflush\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m-> 1094\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflush\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1095\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m   1096\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32md:\\APPS\\Anaconda\\envs\\ML\\Lib\\site-packages\\ipykernel\\iostream.py:575\u001b[0m, in \u001b[0;36mOutStream.flush\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    564\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"trigger actual zmq send\u001b[39;00m\n\u001b[0;32m    565\u001b[0m \n\u001b[0;32m    566\u001b[0m \u001b[38;5;124;03msend will happen in the background thread\u001b[39;00m\n\u001b[0;32m    567\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    568\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    569\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpub_thread\n\u001b[0;32m    570\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpub_thread\u001b[38;5;241m.\u001b[39mthread \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    573\u001b[0m ):\n\u001b[0;32m    574\u001b[0m     \u001b[38;5;66;03m# request flush on the background thread\u001b[39;00m\n\u001b[1;32m--> 575\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpub_thread\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mschedule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_flush\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    576\u001b[0m     \u001b[38;5;66;03m# wait for flush to actually get through, if we can.\u001b[39;00m\n\u001b[0;32m    577\u001b[0m     evt \u001b[38;5;241m=\u001b[39m threading\u001b[38;5;241m.\u001b[39mEvent()\n",
      "File \u001b[1;32md:\\APPS\\Anaconda\\envs\\ML\\Lib\\site-packages\\ipykernel\\iostream.py:267\u001b[0m, in \u001b[0;36mIOPubThread.schedule\u001b[1;34m(self, f)\u001b[0m\n\u001b[0;32m    265\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_events\u001b[38;5;241m.\u001b[39mappend(f)\n\u001b[0;32m    266\u001b[0m     \u001b[38;5;66;03m# wake event thread (message content is ignored)\u001b[39;00m\n\u001b[1;32m--> 267\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_event_pipe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    268\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    269\u001b[0m     f()\n",
      "File \u001b[1;32md:\\APPS\\Anaconda\\envs\\ML\\Lib\\site-packages\\zmq\\sugar\\socket.py:696\u001b[0m, in \u001b[0;36mSocket.send\u001b[1;34m(self, data, flags, copy, track, routing_id, group)\u001b[0m\n\u001b[0;32m    689\u001b[0m         data \u001b[38;5;241m=\u001b[39m zmq\u001b[38;5;241m.\u001b[39mFrame(\n\u001b[0;32m    690\u001b[0m             data,\n\u001b[0;32m    691\u001b[0m             track\u001b[38;5;241m=\u001b[39mtrack,\n\u001b[0;32m    692\u001b[0m             copy\u001b[38;5;241m=\u001b[39mcopy \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    693\u001b[0m             copy_threshold\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy_threshold,\n\u001b[0;32m    694\u001b[0m         )\n\u001b[0;32m    695\u001b[0m     data\u001b[38;5;241m.\u001b[39mgroup \u001b[38;5;241m=\u001b[39m group\n\u001b[1;32m--> 696\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mflags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrack\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrack\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mzmq/backend/cython/socket.pyx:742\u001b[0m, in \u001b[0;36mzmq.backend.cython.socket.Socket.send\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mzmq/backend/cython/socket.pyx:789\u001b[0m, in \u001b[0;36mzmq.backend.cython.socket.Socket.send\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mzmq/backend/cython/socket.pyx:250\u001b[0m, in \u001b[0;36mzmq.backend.cython.socket._send_copy\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32md:\\APPS\\Anaconda\\envs\\ML\\Lib\\site-packages\\zmq\\backend\\cython\\checkrc.pxd:13\u001b[0m, in \u001b[0;36mzmq.backend.cython.checkrc._check_rc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "resolved_texts = []\n",
    "\n",
    "for idx, row in plot_summaries.iterrows():\n",
    "    text = row['plot']\n",
    "    text_split = text.split()\n",
    "    resolved_text = text.split()\n",
    "    preds = model.predict(\n",
    "        texts=text.split(),\n",
    "        is_split_into_words=True\n",
    "    )\n",
    "    clusters = preds.get_clusters(as_strings=False)\n",
    "    for cluster in clusters:\n",
    "        character_name = None\n",
    "        for token_offset in cluster:\n",
    "            token = ' '.join(text_split[token_offset[0]:token_offset[1]])\n",
    "            if token in characters and token.lower() not in [\"he\", \"him\", \"his\", \"she\", \"her\", \"hers\", \"they\", \"them\", \"their\"]:\n",
    "                character_name = token\n",
    "            elif token.lower() in [\"he\", \"him\", \"his\", \"she\", \"her\", \"hers\", \"they\", \"them\", \"their\"] and character_name!=None:\n",
    "                resolved_text[token_offset[0]] = character_name\n",
    "    resolved_texts.append(' '.join(resolved_text))\n",
    "\n",
    "wiki_ids = plot_summaries['wiki_id'].tolist()\n",
    "resolved_df = pd.DataFrame({'wiki_id': wiki_ids, 'resolved_text': resolved_texts})\n",
    "resolved_df.to_csv('../data/resolved_texts_fastcoref.csv', index=False)\n",
    "\n",
    "# plot_summaries = plot_sum\n",
    "# display(plot_summaries.head())\n",
    "# plot_summaries.to_csv('../data/plot_summaries_resolved_fastcoref.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
