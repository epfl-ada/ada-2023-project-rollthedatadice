{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "import core2sent\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "FOLDER_PATH = \"../data/corenlp_plot_summaries/\"\n",
    "PLOT_SUMMARY_PATH = \"../data/plot_summaries.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wiki_id</th>\n",
       "      <th>plot</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23890098</td>\n",
       "      <td>Shlykov, a hard-working taxi driver and Lyosha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31186339</td>\n",
       "      <td>The nation of Panem consists of a wealthy Capi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20663735</td>\n",
       "      <td>Poovalli Induchoodan  is sentenced for six yea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2231378</td>\n",
       "      <td>The Lemon Drop Kid , a New York City swindler,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>595909</td>\n",
       "      <td>Seventh-day Adventist Church pastor Michael Ch...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    wiki_id                                               plot\n",
       "0  23890098  Shlykov, a hard-working taxi driver and Lyosha...\n",
       "1  31186339  The nation of Panem consists of a wealthy Capi...\n",
       "2  20663735  Poovalli Induchoodan  is sentenced for six yea...\n",
       "3   2231378  The Lemon Drop Kid , a New York City swindler,...\n",
       "4    595909  Seventh-day Adventist Church pastor Michael Ch..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plot_summaries = pd.read_csv(PLOT_SUMMARY_PATH, sep='\\t', header=None)\n",
    "plot_summaries.columns = ['wiki_id', 'plot']\n",
    "plot_summaries.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_mentions_to_first_mention(coreferences, tokens_per_sentence):\n",
    "    \"\"\"\n",
    "    :param coreferences: dict of coreferences\n",
    "    :param tokens_per_sentence: list of tokens per sentence\n",
    "    return: mapped sentences\n",
    "    \"\"\"\n",
    "    # generate the token dict\n",
    "    token_dict = {}\n",
    "    for sentence_id, sentence in enumerate(tokens_per_sentence):\n",
    "        token_dict[sentence_id] = []\n",
    "        for token in sentence['tokens']:\n",
    "            token_dict[sentence_id].append(token[0])\n",
    "\n",
    "    # map the mentions to the first mention\n",
    "    for mention_replacements in coreferences:\n",
    "        for mention_id, mention in enumerate(mention_replacements['mentions']):\n",
    "            sentence_id = int(mention['sentence'])\n",
    "            start = int(mention['head'])\n",
    "            end = int(mention['end'])\n",
    "            print(sentence_id, start, end, ' '.join(token_dict[sentence_id][start:end]))\n",
    "            if mention_id == 0:\n",
    "                representative_mention_name = token_dict[sentence_id][start:end]\n",
    "            else:\n",
    "                other_mention_name = token_dict[sentence_id][start:end]\n",
    "                token_dict[sentence_id][start:end] = [representative_mention_name, ''*(end-start-1)]\n",
    "        \n",
    "    # concatenate the tokens back to sentences\n",
    "    replaced_sentences = []\n",
    "    for sentence_id, sentence in enumerate(tokens_per_sentence):\n",
    "        replaced_sentences.append(' '.join(token_dict[sentence_id]))\n",
    "    replaced_sentences = ' '.join(replaced_sentences)\n",
    "    return replaced_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 13 41 AD , where he is almost immediately captured by Lord Arthur 's men , who suspect him to be an agent for Duke Henry , with whom Arthur\n",
      "0 13 14 AD\n",
      "0 33 41 an agent for Duke Henry , with whom\n",
      "0 16 17 where\n",
      "0 29 30 who\n",
      "1 0 1 He\n",
      "1 9 10 ,\n",
      "0 23 25 by Lord\n",
      "2 17 19 Arthur 's\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "sequence item 4: expected str instance, list found",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[38], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m parsed_xml \u001b[38;5;241m=\u001b[39m core2sent\u001b[38;5;241m.\u001b[39mconvert_sentences(tree)\n\u001b[0;32m      6\u001b[0m parsed_corref \u001b[38;5;241m=\u001b[39m core2sent\u001b[38;5;241m.\u001b[39mconvert_coref(tree)\n\u001b[1;32m----> 7\u001b[0m mapped_sentences \u001b[38;5;241m=\u001b[39m \u001b[43mmap_mentions_to_first_mention\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparsed_corref\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparsed_xml\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[37], line 20\u001b[0m, in \u001b[0;36mmap_mentions_to_first_mention\u001b[1;34m(coreferences, tokens_per_sentence)\u001b[0m\n\u001b[0;32m     18\u001b[0m start \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(mention[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhead\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     19\u001b[0m end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(mention[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mend\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m---> 20\u001b[0m \u001b[38;5;28mprint\u001b[39m(sentence_id, start, end, \u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m \u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtoken_dict\u001b[49m\u001b[43m[\u001b[49m\u001b[43msentence_id\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mstart\u001b[49m\u001b[43m:\u001b[49m\u001b[43mend\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mention_id \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m     22\u001b[0m     representative_mention_name \u001b[38;5;241m=\u001b[39m token_dict[sentence_id][start:end]\n",
      "\u001b[1;31mTypeError\u001b[0m: sequence item 4: expected str instance, list found"
     ]
    }
   ],
   "source": [
    "for index, row in plot_summaries.iterrows():\n",
    "    if str(row['wiki_id']) == \"3217\":\n",
    "        FILE_PATH = FOLDER_PATH + str(row['wiki_id']) + \".txt.xml\"\n",
    "        tree = ET.parse(FILE_PATH)\n",
    "        parsed_xml = core2sent.convert_sentences(tree)\n",
    "        parsed_corref = core2sent.convert_coref(tree)\n",
    "        mapped_sentences = map_mentions_to_first_mention(parsed_corref, parsed_xml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'mentions': [{'sentence': 0, 'start': 12, 'end': 41, 'head': 13},\n",
       "   {'sentence': 0, 'start': 12, 'end': 14, 'head': 13}],\n",
       "  'first_mention': (0, 13),\n",
       "  'num': 0,\n",
       "  'id': 'E0'},\n",
       " {'mentions': [{'sentence': 0, 'start': 32, 'end': 41, 'head': 33},\n",
       "   {'sentence': 0, 'start': 16, 'end': 17, 'head': 16},\n",
       "   {'sentence': 0, 'start': 29, 'end': 30, 'head': 29},\n",
       "   {'sentence': 1, 'start': 0, 'end': 1, 'head': 0},\n",
       "   {'sentence': 1, 'start': 9, 'end': 10, 'head': 9}],\n",
       "  'first_mention': (0, 16),\n",
       "  'num': 1,\n",
       "  'id': 'E1'},\n",
       " {'mentions': [{'sentence': 0, 'start': 22, 'end': 25, 'head': 23},\n",
       "   {'sentence': 2, 'start': 17, 'end': 19, 'head': 17}],\n",
       "  'first_mention': (0, 23),\n",
       "  'num': 2,\n",
       "  'id': 'E2'},\n",
       " {'mentions': [{'sentence': 0, 'start': 22, 'end': 41, 'head': 25},\n",
       "   {'sentence': 0, 'start': 22, 'end': 26, 'head': 25},\n",
       "   {'sentence': 3, 'start': 4, 'end': 6, 'head': 5}],\n",
       "  'first_mention': (0, 25),\n",
       "  'num': 3,\n",
       "  'id': 'E3'},\n",
       " {'mentions': [{'sentence': 1, 'start': 5, 'end': 14, 'head': 7},\n",
       "   {'sentence': 0, 'start': 35, 'end': 37, 'head': 36},\n",
       "   {'sentence': 1, 'start': 5, 'end': 8, 'head': 7},\n",
       "   {'sentence': 1, 'start': 7, 'end': 8, 'head': 7},\n",
       "   {'sentence': 3, 'start': 2, 'end': 3, 'head': 2},\n",
       "   {'sentence': 3, 'start': 4, 'end': 5, 'head': 4},\n",
       "   {'sentence': 4, 'start': 0, 'end': 1, 'head': 0},\n",
       "   {'sentence': 20, 'start': 20, 'end': 22, 'head': 21}],\n",
       "  'first_mention': (0, 36),\n",
       "  'num': 4,\n",
       "  'id': 'E4'},\n",
       " {'mentions': [{'sentence': 0, 'start': 35, 'end': 41, 'head': 40},\n",
       "   {'sentence': 20, 'start': 44, 'end': 47, 'head': 44}],\n",
       "  'first_mention': (0, 40),\n",
       "  'num': 5,\n",
       "  'id': 'E5'},\n",
       " {'mentions': [{'sentence': 20, 'start': 32, 'end': 37, 'head': 36},\n",
       "   {'sentence': 2, 'start': 0, 'end': 1, 'head': 0},\n",
       "   {'sentence': 2, 'start': 7, 'end': 8, 'head': 7},\n",
       "   {'sentence': 2, 'start': 14, 'end': 15, 'head': 14},\n",
       "   {'sentence': 3, 'start': 19, 'end': 20, 'head': 19},\n",
       "   {'sentence': 5, 'start': 9, 'end': 10, 'head': 9},\n",
       "   {'sentence': 5, 'start': 13, 'end': 14, 'head': 13},\n",
       "   {'sentence': 6, 'start': 6, 'end': 7, 'head': 6},\n",
       "   {'sentence': 7, 'start': 11, 'end': 12, 'head': 11},\n",
       "   {'sentence': 9, 'start': 4, 'end': 5, 'head': 4},\n",
       "   {'sentence': 9, 'start': 13, 'end': 14, 'head': 13},\n",
       "   {'sentence': 10, 'start': 6, 'end': 8, 'head': 6},\n",
       "   {'sentence': 10, 'start': 11, 'end': 12, 'head': 11},\n",
       "   {'sentence': 10, 'start': 19, 'end': 20, 'head': 19},\n",
       "   {'sentence': 10, 'start': 22, 'end': 32, 'head': 22},\n",
       "   {'sentence': 10, 'start': 22, 'end': 23, 'head': 22},\n",
       "   {'sentence': 10, 'start': 26, 'end': 27, 'head': 26},\n",
       "   {'sentence': 11, 'start': 1, 'end': 2, 'head': 1},\n",
       "   {'sentence': 11, 'start': 9, 'end': 10, 'head': 9},\n",
       "   {'sentence': 12, 'start': 0, 'end': 1, 'head': 0},\n",
       "   {'sentence': 12, 'start': 16, 'end': 17, 'head': 16},\n",
       "   {'sentence': 13, 'start': 7, 'end': 8, 'head': 7},\n",
       "   {'sentence': 14, 'start': 0, 'end': 1, 'head': 0},\n",
       "   {'sentence': 15, 'start': 1, 'end': 3, 'head': 1},\n",
       "   {'sentence': 15, 'start': 7, 'end': 8, 'head': 7},\n",
       "   {'sentence': 15, 'start': 12, 'end': 13, 'head': 12},\n",
       "   {'sentence': 16, 'start': 10, 'end': 11, 'head': 10},\n",
       "   {'sentence': 16, 'start': 17, 'end': 18, 'head': 17},\n",
       "   {'sentence': 18, 'start': 0, 'end': 1, 'head': 0},\n",
       "   {'sentence': 19, 'start': 7, 'end': 8, 'head': 7},\n",
       "   {'sentence': 20, 'start': 9, 'end': 10, 'head': 9},\n",
       "   {'sentence': 20, 'start': 23, 'end': 24, 'head': 23},\n",
       "   {'sentence': 21, 'start': 3, 'end': 4, 'head': 3},\n",
       "   {'sentence': 21, 'start': 8, 'end': 9, 'head': 8},\n",
       "   {'sentence': 22, 'start': 2, 'end': 3, 'head': 2},\n",
       "   {'sentence': 23, 'start': 17, 'end': 18, 'head': 17}],\n",
       "  'first_mention': (2, 0),\n",
       "  'num': 6,\n",
       "  'id': 'E6'},\n",
       " {'mentions': [{'sentence': 2, 'start': 10, 'end': 12, 'head': 11},\n",
       "   {'sentence': 17, 'start': 14, 'end': 16, 'head': 15}],\n",
       "  'first_mention': (2, 11),\n",
       "  'num': 7,\n",
       "  'id': 'E7'},\n",
       " {'mentions': [{'sentence': 2, 'start': 17, 'end': 21, 'head': 20},\n",
       "   {'sentence': 5, 'start': 2, 'end': 5, 'head': 4},\n",
       "   {'sentence': 5, 'start': 3, 'end': 5, 'head': 4}],\n",
       "  'first_mention': (2, 20),\n",
       "  'num': 8,\n",
       "  'id': 'E8'},\n",
       " {'mentions': [{'sentence': 4, 'start': 5, 'end': 16, 'head': 5},\n",
       "   {'sentence': 4, 'start': 5, 'end': 6, 'head': 5},\n",
       "   {'sentence': 4, 'start': 7, 'end': 16, 'head': 8},\n",
       "   {'sentence': 6, 'start': 4, 'end': 5, 'head': 4},\n",
       "   {'sentence': 17, 'start': 2, 'end': 3, 'head': 2},\n",
       "   {'sentence': 20, 'start': 39, 'end': 40, 'head': 39}],\n",
       "  'first_mention': (4, 5),\n",
       "  'num': 9,\n",
       "  'id': 'E9'},\n",
       " {'mentions': [{'sentence': 6, 'start': 1, 'end': 5, 'head': 2},\n",
       "   {'sentence': 6, 'start': 8, 'end': 9, 'head': 8},\n",
       "   {'sentence': 7, 'start': 1, 'end': 2, 'head': 1},\n",
       "   {'sentence': 8, 'start': 2, 'end': 3, 'head': 2},\n",
       "   {'sentence': 8, 'start': 8, 'end': 9, 'head': 8}],\n",
       "  'first_mention': (6, 2),\n",
       "  'num': 10,\n",
       "  'id': 'E10'},\n",
       " {'mentions': [{'sentence': 11, 'start': 4, 'end': 7, 'head': 5},\n",
       "   {'sentence': 6, 'start': 11, 'end': 13, 'head': 12},\n",
       "   {'sentence': 21, 'start': 16, 'end': 18, 'head': 17}],\n",
       "  'first_mention': (6, 12),\n",
       "  'num': 11,\n",
       "  'id': 'E11'},\n",
       " {'mentions': [{'sentence': 10, 'start': 15, 'end': 22, 'head': 17},\n",
       "   {'sentence': 10, 'start': 30, 'end': 32, 'head': 31}],\n",
       "  'first_mention': (10, 17),\n",
       "  'num': 12,\n",
       "  'id': 'E12'},\n",
       " {'mentions': [{'sentence': 12, 'start': 19, 'end': 21, 'head': 20},\n",
       "   {'sentence': 13, 'start': 11, 'end': 13, 'head': 12},\n",
       "   {'sentence': 14, 'start': 3, 'end': 5, 'head': 4}],\n",
       "  'first_mention': (12, 20),\n",
       "  'num': 13,\n",
       "  'id': 'E13'},\n",
       " {'mentions': [{'sentence': 14, 'start': 13, 'end': 22, 'head': 14},\n",
       "   {'sentence': 14, 'start': 13, 'end': 15, 'head': 14}],\n",
       "  'first_mention': (14, 14),\n",
       "  'num': 14,\n",
       "  'id': 'E14'},\n",
       " {'mentions': [{'sentence': 15, 'start': 16, 'end': 18, 'head': 17},\n",
       "   {'sentence': 20, 'start': 33, 'end': 34, 'head': 33}],\n",
       "  'first_mention': (15, 17),\n",
       "  'num': 15,\n",
       "  'id': 'E15'},\n",
       " {'mentions': [{'sentence': 16, 'start': 6, 'end': 9, 'head': 8},\n",
       "   {'sentence': 20, 'start': 26, 'end': 29, 'head': 28}],\n",
       "  'first_mention': (16, 8),\n",
       "  'num': 16,\n",
       "  'id': 'E16'},\n",
       " {'mentions': [{'sentence': 16, 'start': 17, 'end': 20, 'head': 19},\n",
       "   {'sentence': 21, 'start': 8, 'end': 11, 'head': 10},\n",
       "   {'sentence': 22, 'start': 18, 'end': 19, 'head': 18}],\n",
       "  'first_mention': (16, 19),\n",
       "  'num': 17,\n",
       "  'id': 'E17'},\n",
       " {'mentions': [{'sentence': 22, 'start': 5, 'end': 8, 'head': 7},\n",
       "   {'sentence': 23, 'start': 13, 'end': 15, 'head': 14}],\n",
       "  'first_mention': (22, 7),\n",
       "  'num': 18,\n",
       "  'id': 'E18'},\n",
       " {'mentions': [{'sentence': 22, 'start': 9, 'end': 12, 'head': 11},\n",
       "   {'sentence': 22, 'start': 14, 'end': 15, 'head': 14},\n",
       "   {'sentence': 22, 'start': 22, 'end': 23, 'head': 22}],\n",
       "  'first_mention': (22, 11),\n",
       "  'num': 19,\n",
       "  'id': 'E19'}]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree = ET.parse('../data/corenlp_plot_summaries/3217.txt.xml')\n",
    "parsed_corref = core2sent.convert_coref(tree)\n",
    "parsed_corref"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ada",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
